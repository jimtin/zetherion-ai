services:
  zetherion-ai-bot:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: zetherion-ai-bot
    restart: unless-stopped
    # Security: read-only filesystem with writable tmpfs for temp files
    read_only: true
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /tmp
      - /home/nonroot/.cache
    depends_on:
      qdrant:
        condition: service_healthy
      zetherion-ai-skills:
        condition: service_healthy
      postgres:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      # Generation container (large model + embeddings)
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
      # Router container (small, fast model for classification)
      - OLLAMA_ROUTER_HOST=ollama-router
      - OLLAMA_ROUTER_PORT=11434
      - SKILLS_SERVICE_URL=http://zetherion-ai-skills:8080
      - POSTGRES_DSN=postgresql://zetherion:password@postgres:5432/zetherion
      - ENVIRONMENT=production
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    networks:
      - zetherion-ai-net
    # Use Dockerfile HEALTHCHECK - distroless can only exec via ENTRYPOINT
    # Resource limits to prevent runaway processes
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Public API server for multi-tenant client websites (Phase 11)
  zetherion-ai-api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: zetherion-ai-api
    restart: unless-stopped
    # Security: read-only filesystem with writable tmpfs for temp files
    read_only: true
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /tmp
      - /home/nonroot/.cache
    depends_on:
      postgres:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - POSTGRES_DSN=postgresql://zetherion:password@postgres:5432/zetherion
      - API_HOST=0.0.0.0
      - API_PORT=8443
      # LLM providers for chat inference
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
      - OLLAMA_ROUTER_HOST=ollama-router
      - OLLAMA_ROUTER_PORT=11434
      - ENVIRONMENT=production
    # No port exposed to host — accessed via Cloudflare Tunnel
    networks:
      - zetherion-ai-net
    # Use Dockerfile HEALTHCHECK - distroless can only exec via ENTRYPOINT
    # Resource limits for API service
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Cloudflare Tunnel — exposes the API to the internet without opening ports
  # Requires a Cloudflare Tunnel token (create at https://one.dash.cloudflare.com)
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: zetherion-ai-cloudflared
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN:-}
    depends_on:
      zetherion-ai-api:
        condition: service_healthy
    networks:
      - zetherion-ai-net
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 32M

  # Traefik reverse proxy for zero-downtime blue-green deployments (Phase 10A)
  traefik:
    image: traefik:v3.3
    container_name: zetherion-ai-traefik
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    command:
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.skills.address=:8080"
      - "--api.insecure=false"
      - "--log.level=WARN"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - zetherion-ai-net
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 32M

  zetherion-ai-skills:
    build:
      context: .
      dockerfile: Dockerfile.skills
    container_name: zetherion-ai-skills
    restart: unless-stopped
    # Security: read-only filesystem with writable tmpfs for temp files
    read_only: true
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /tmp
      - /home/nonroot/.cache
    depends_on:
      qdrant:
        condition: service_healthy
      postgres:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      # Generation container (large model + embeddings)
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
      # Router container (small, fast model for classification)
      - OLLAMA_ROUTER_HOST=ollama-router
      - OLLAMA_ROUTER_PORT=11434
      - POSTGRES_DSN=postgresql://zetherion:password@postgres:5432/zetherion
      - SKILLS_HOST=0.0.0.0
      - SKILLS_PORT=8080
    # Traefik labels for zero-downtime blue-green deployments
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.skills.rule=PathPrefix(`/`)"
      - "traefik.http.routers.skills.entrypoints=skills"
      - "traefik.http.services.skills.loadbalancer.server.port=8080"
      - "traefik.http.services.skills.loadbalancer.healthcheck.path=/health"
      - "traefik.http.services.skills.loadbalancer.healthcheck.interval=5s"
    # No ports exposed to host - only accessible from bot via internal network
    networks:
      - zetherion-ai-net
    # Use Dockerfile HEALTHCHECK - distroless can only exec via ENTRYPOINT
    # Resource limits for skills service
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Ollama Generation Container (large model + embeddings)
  # Handles complex queries and embedding generation
  ollama:
    # Pin image by digest for reproducible builds (Dependabot auto-updates)
    image: ollama/ollama:latest@sha256:37ef34d78a6f4563a11cbbb336bbaa75f01eb19671d639973f98baa58f11a5ed
    container_name: zetherion-ai-ollama
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD-SHELL", "timeout 5 bash -c '</dev/tcp/localhost/11434' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    volumes:
      - ollama_models:/root/.ollama
    networks:
      - zetherion-ai-net
    # Resource limits for LLM inference (generation + embeddings)
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 2G
    # Uncomment for GPU support (NVIDIA)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # Ollama Router Container (small, fast model for routing)
  # Dedicated container for message classification - always loaded
  ollama-router:
    # Pin image by digest for reproducible builds (Dependabot auto-updates)
    image: ollama/ollama:latest@sha256:37ef34d78a6f4563a11cbbb336bbaa75f01eb19671d639973f98baa58f11a5ed
    container_name: zetherion-ai-ollama-router
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    # No port exposure to host - only accessible via internal network
    healthcheck:
      test: ["CMD-SHELL", "timeout 5 bash -c '</dev/tcp/localhost/11434' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s  # Faster startup for small model
    volumes:
      - ollama_router_models:/root/.ollama
    networks:
      - zetherion-ai-net
    # Resource limits for router (3b model needs ~2.5GB + inference overhead)
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 1536M

  postgres:
    image: postgres:17-alpine
    container_name: zetherion-ai-postgres
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    environment:
      POSTGRES_DB: zetherion
      POSTGRES_USER: zetherion
      POSTGRES_PASSWORD: password
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U zetherion"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - zetherion-ai-net
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 64M

  qdrant:
    # Pin image by digest for reproducible builds (Dependabot auto-updates)
    image: qdrant/qdrant:latest@sha256:0425e3e03e7fd9b3dc95c4214546afe19de2eb2e28ca621441a56663ac6e1f46
    container_name: zetherion-ai-qdrant
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    ports:
      - "6333:6333"
    healthcheck:
      # TCP check works for both TLS and non-TLS modes
      test: ["CMD-SHELL", "timeout 5 bash -c '</dev/tcp/localhost/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    volumes:
      - qdrant_storage:/qdrant/storage
      # TLS certificates (Phase 5A) - run scripts/generate-qdrant-certs.sh first
      # Uncomment below when TLS is enabled:
      # - ./data/certs/qdrant:/qdrant/certs:ro
      # - ./config/qdrant.yaml:/qdrant/config/production.yaml:ro
    networks:
      - zetherion-ai-net
    # Resource limits for vector database
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 256M

volumes:
  qdrant_storage:
  ollama_models:
  ollama_router_models:
  postgres_data:

networks:
  zetherion-ai-net:
    driver: bridge
