{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Zetherion AI Documentation","text":"<p>Zetherion AI is a privacy-first personal AI assistant featuring encrypted memory, smart LLM routing, Gmail integration, and deep personal understanding. It runs as a Discord bot backed by 6 Docker services, designed to learn your preferences and adapt over time while keeping your data secure.</p>"},{"location":"#feature-matrix","title":"Feature Matrix","text":"Feature Description Status Smart LLM Routing Routes queries to optimal provider (Claude/OpenAI/Gemini/Ollama) based on task type Production Encrypted Memory AES-256-GCM field-level encryption with PBKDF2 key derivation Production Gmail Integration Check email, auto-draft replies, digests, progressive trust system Production GitHub Integration Manage issues, PRs, repo status through natural language Production Personal Understanding Learns preferences, builds contact graph, adapts communication Production Observation Pipeline Tiered extraction of facts, preferences, and context from conversations Production InferenceBroker Multi-provider routing with fallback chains and cost awareness Production Cost Tracking Per-request logging, budget alerts, daily/monthly reporting Production Skills Framework Extensible skills: task management, calendar, profile management Production Heartbeat Scheduler Proactive reminders, morning briefings, deadline alerts Production User Profiles 8-category learning with confidence scoring and privacy controls Production Distroless Containers Google's distroless base images, non-root, read-only filesystem Production"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>git clone https://github.com/jimtin/zetherion-ai.git\ncd zetherion-ai\n./start.sh\n</code></pre> <p>See Getting Started for detailed setup instructions.</p>"},{"location":"#documentation-sections","title":"Documentation Sections","text":""},{"location":"#for-users","title":"For Users","text":"<p>If you are using Zetherion AI and want to know what it can do:</p> Guide Description Getting Started Prerequisites, setup, first interaction Commands Complete Discord command reference Gmail Email checking, drafts, digests, trust system GitHub Repository management, issues, PRs Tasks &amp; Calendar Task management and scheduling Memory &amp; Profiles How the bot learns and remembers FAQ Frequently asked questions Troubleshooting Common issues and solutions"},{"location":"#for-technical-users","title":"For Technical Users","text":"<p>If you want to understand the internals:</p> Guide Description Architecture System design and component interaction Docker &amp; Services 6-service container architecture Security Encryption, access control, container hardening Configuration All 70+ environment variables Skills Framework Skill lifecycle, permissions, registry Gmail Architecture Trust system, OAuth, reply pipeline Observation Pipeline Tiered fact extraction Personal Understanding PostgreSQL personal model Cost Tracking Budget management and reporting API Reference Skills REST API endpoints"},{"location":"#for-developers","title":"For Developers","text":"<p>If you want to contribute or extend:</p> Guide Description Setup &amp; Contributing Development environment and guidelines Testing 3,000+ tests across 89 files CI/CD Pipeline 10-job CI pipeline and 7-step pre-push GitHub Secrets CI/CD secrets configuration Adding a Skill Tutorial: create a custom skill Changelog Release history"},{"location":"#project","title":"Project","text":"Guide Description Roadmap Completed phases and future plans Design Decisions Architecture decision records"},{"location":"#project-stats","title":"Project Stats","text":"Metric Value Tests 3,000+ Test Coverage 93%+ Test Files 89 Source Files 91 Docker Services 6 Configuration Fields 70+ CI/CD Jobs 10 Skills 7 (task, calendar, profile, gmail, github, personal model, observation)"},{"location":"#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>Report Issues</li> <li>Discussions</li> </ul>"},{"location":"MULTI_TENANT_API_PLAN/","title":"Plan: Multi-Tenant Public API + Client Intelligence Skills","text":""},{"location":"MULTI_TENANT_API_PLAN/#context","title":"Context","text":"<p>Zetherion AI currently runs as a self-hosted Discord bot on a home server. The goal is to expose it as a backend service for multiple client websites (chatbots, CRM, etc.). This involves two parallel workstreams:</p> <ol> <li>Workstream A: Public API Infrastructure \u2014 The plumbing to expose Zetherion to the internet</li> <li>Workstream B: Client Intelligence Skills \u2014 The brains that extract multi-level intelligence from conversations</li> </ol> <p>Key decisions: - Networking: Cloudflare Tunnel (no open ports) - Auth: Per-site API key + lightweight session tokens - Chat UX: Streaming via SSE - Clients have their own backends (API keys stay server-side) - Shared infrastructure, tenant-isolated data via <code>tenant_id</code> - All skills are platform-agnostic (Discord today, Slack/web/etc. tomorrow) - CRM is a separate skill workstream, not part of the API infrastructure</p>"},{"location":"MULTI_TENANT_API_PLAN/#the-multi-level-intelligence-model","title":"The Multi-Level Intelligence Model","text":"<p>When a customer chats on a client's website, Zetherion operates at multiple levels simultaneously:</p> <pre><code>End-user sends message on Bob's Plumbing site\n  \u2192 L1a INLINE: Critical signal detection (urgency, safety, escalation)\n      \u2192 Bot adjusts response if needed (\"I can see this is urgent...\")\n  \u2192 client_chat generates a response for the end-user\n  \u2192 L1b ASYNC: Entity extraction (contact info, intent, sentiment)\n  \u2192 L2  ASYNC: Session summary when conversation ends\n  \u2192 L3  PERIODIC: Daily/weekly tenant aggregation\n  \u2192 L4  PERIODIC: Cross-tenant intelligence (James only)\n  \u2192 L5  CONTINUOUS: Feedback loop (bot improvement suggestions)\n</code></pre> <p>This is the key differentiator from traditional CRMs/chatbot platforms \u2014 Zetherion serves both the tenant AND the owner simultaneously, with different extraction lenses.</p>"},{"location":"MULTI_TENANT_API_PLAN/#intelligence-extraction-matrix","title":"Intelligence Extraction Matrix","text":"<p>Level 1a: Per-Message Critical Signals (INLINE, pre-response) Lightweight detection that runs before the bot responds, so the response can adapt.</p> Signal For Tenant For James Example Urgency detection Bot reacts (\"flagging for callback\") Alert if critical \"My pipe burst and water is flooding\" Safety/harm signals Bot escalates appropriately Immediate alert Self-harm indicators, threats Escalation triggers Route to human if configured Track escalation rate \"I want to speak to a real person\" Returning customer Bot can greet by name -- Session matches previous contact <p>Level 1b: Per-Message Entity Extraction (ASYNC, post-response) Heavier LLM-based extraction that doesn't slow down the response.</p> Signal For Tenant For James Example Contact entities (name, email, phone) Store in tenant CRM -- \"My name is Dave, call me on 07700...\" Intent classification Tag the interaction -- Enquiry / complaint / booking / support Sentiment score Track per-customer Feed into aggregation Frustrated / neutral / happy Product/service mentioned Tag interaction -- \"bathroom renovation\", \"boiler service\" Purchase signals Flag as lead -- \"How much would it cost to...\" Communication preferences CRM enrichment -- \"I prefer email\" / \"Don't call before 10am\" <p>Level 2: Per-Session Summary (ASYNC, on session close/timeout)</p> Signal For Tenant For James Example Conversation outcome Resolved / unresolved / needs followup Track resolution rates Did the chatbot actually help? Customer profile summary CRM enrichment -- \"Price-sensitive homeowner, kitchen refit, prefers weekends\" Unmet needs / opportunities Opportunity alert (\"customers want X, you don't offer it\") -- \"Asked about gas safety certs \u2014 Bob doesn't list this\" Sentiment trajectory Customer satisfaction trend Bot technical performance (did the bot cause frustration? misunderstand? fail to answer?) Started frustrated \u2192 ended satisfied Chatbot effectiveness -- Technical quality signal (response failures, hallucinations, missed intents) Bot couldn't answer 3 questions \u2192 config needs work Topics covered FAQ data + content gap detection (\"customers keep asking about X\") Visibility into tenant content gaps (read-only) Which questions come up repeatedly? Follow-up actions needed Task creation for tenant -- \"Customer wants a callback Tuesday\" <p>Level 3: Per-Tenant Aggregation (PERIODIC, daily/weekly rollup) Tenants can access their own L3 data via API.</p> Signal For Tenant For James Example Volume trends \"45 enquiries this week (+20%)\" Engagement health Is this client's site being used? Top topics / FAQs \"Customers mostly ask about pricing\" Cross-client patterns Common across plumbing clients? Avg sentiment over time Customer satisfaction trend Client health score Sentiment dropping \u2192 something wrong Conversion rate \"12/45 conversations were purchase-intent\" Revenue signal High conversion = valuable client Peak hours \"Most chats happen 6-9pm\" -- Useful for tenant's staffing Unmet needs (aggregated) \"X asked about 15 times \u2014 you don't offer it\" Upsell opportunity \"Suggest Bob adds emergency plumbing\" Repeat visitor rate Loyalty signals -- Returning customers = good sign Escalation rate \"8% needed human handoff\" Bot quality signal High escalation = config needs work Response quality score \"Bot resolved 85% without escalation\" Service quality metric Benchmarkable across clients <p>Level 4: Cross-Tenant Intelligence (PERIODIC, weekly, James only) Privacy boundaries: TBD \u2014 to be decided whether James sees anonymized aggregates or named comparisons.</p> Signal For James Example Industry benchmarks \"Bob converts at 26%, trade avg is 18%\" Best-performing configs \"Formal tone converts better for trade services\" Emerging patterns \"3 clients getting AI-related questions \u2014 new service area?\" Client health dashboard Red/amber/green portfolio overview Churn risk \"Dave's site usage dropped 60% \u2014 check in\" Revenue attribution Which clients generate most value vs effort? <p>Level 5: Feedback Loop (CONTINUOUS, threshold-triggered)</p> Signal For James Example Bot improvement suggestions \"Bob's bot fails on pricing questions \u2014 add FAQ to config\" Knowledge gaps \"Customers ask about X and the bot doesn't know\" Prompt tuning signals \"Sarah's bot is too verbose \u2014 customers drop off mid-response\" Config recommendations \"Based on successful clients, try adjusting tone to...\""},{"location":"MULTI_TENANT_API_PLAN/#extraction-timing-summary","title":"Extraction Timing Summary","text":"Level Trigger Latency Storage Tenant can see? L1a Inline pre-response &lt;100ms In-memory (flags) No (internal) L1b Async post-response Seconds Tenant Postgres Yes L2 Session close/timeout Seconds Tenant Postgres + James's Qdrant Yes L3 Daily/weekly cron Background Aggregation tables Yes (via API) L4 Weekly cron Background James's Qdrant No (James only) L5 Threshold triggers Background Triggers notifications No (James only)"},{"location":"MULTI_TENANT_API_PLAN/#architecture","title":"Architecture","text":"<pre><code>Internet                     Home Server Docker Network\n  |                          +------------------------------------+\n  |   Cloudflare Tunnel      |                                    |\n  +----&gt; cloudflared --------+--&gt; zetherion-api (8443) [NEW]      |\n                             |        |                           |\n                             |        v                           |\n                             |   zetherion-ai-skills (8080)       |\n                             |        |                           |\n                             |   +----+-----+                     |\n                             |   |          |                     |\n                             |  postgres  qdrant   ollama         |\n                             |                                    |\nDiscord/Slack/etc.           |                                    |\n  +----&gt; zetherion-ai-bot ---+--&gt; zetherion-ai-skills (8080)      |\n                             +------------------------------------+\n</code></pre>"},{"location":"MULTI_TENANT_API_PLAN/#auth-flow","title":"Auth Flow","text":"<pre><code>1. Client backend creates a session (server-to-server):\n   POST /api/v1/sessions  [X-API-Key: sk_live_...]\n   \u2192 { session_token: \"zt_sess_...\" }\n\n2. Client passes session_token to their frontend\n\n3. Browser sends chat messages using session token:\n   POST /api/v1/chat  [Authorization: Bearer zt_sess_...]\n   \u2192 SSE stream of AI response tokens\n</code></pre> <p>API keys: <code>sk_live_</code> prefix, bcrypt-hashed. Session tokens: signed JWTs (24hr expiry).</p>"},{"location":"MULTI_TENANT_API_PLAN/#workstream-a-public-api-infrastructure","title":"Workstream A: Public API Infrastructure","text":""},{"location":"MULTI_TENANT_API_PLAN/#phase-a1-foundation-tenant-management-api-skeleton","title":"Phase A1: Foundation \u2014 Tenant Management &amp; API Skeleton","text":"<p>New files: - <code>src/zetherion_ai/api/__init__.py</code> - <code>src/zetherion_ai/api/server.py</code> \u2014 Public aiohttp app (port 8443), modeled on <code>skills/server.py</code> - <code>src/zetherion_ai/api/tenant.py</code> \u2014 <code>TenantManager</code> (CRUD, API key gen/validation), modeled on <code>discord/user_manager.py</code> - <code>src/zetherion_ai/api/auth.py</code> \u2014 API key generation (<code>secrets.token_urlsafe</code> + bcrypt), JWT session tokens (<code>PyJWT</code>) - <code>src/zetherion_ai/api/middleware.py</code> \u2014 CORS, API key validation, rate limiting, tenant context injection - <code>src/zetherion_ai/api/models.py</code> \u2014 Pydantic request/response schemas - <code>src/zetherion_ai/api/routes/__init__.py</code> - <code>src/zetherion_ai/api/routes/health.py</code> \u2014 <code>GET /api/v1/health</code> (no auth) - <code>src/zetherion_ai/api/routes/sessions.py</code> \u2014 Session CRUD (requires API key)</p> <p>Modified files: - <code>src/zetherion_ai/config.py</code> \u2014 Add <code>api_host</code>, <code>api_port</code>, <code>api_jwt_secret</code> - <code>.env.example</code> \u2014 Add new env vars</p> <p>Database (new tables): <pre><code>tenants (id, tenant_id UUID, name, domain, api_key_hash, api_key_prefix,\n         is_active, rate_limit_rpm, allowed_skills[], config JSONB, timestamps)\n\nchat_sessions (id, session_id UUID, tenant_id FK, external_user_id,\n               metadata JSONB, created_at, last_active, expires_at)\n</code></pre></p> <p>Tests: <code>test_api_auth.py</code>, <code>test_api_tenant.py</code>, <code>test_api_http.py</code></p> <p>Deliverable: API starts, health check works, API key auth works, sessions can be created.</p>"},{"location":"MULTI_TENANT_API_PLAN/#phase-a2-chat-endpoint-rest-chat-with-ai","title":"Phase A2: Chat Endpoint \u2014 REST Chat with AI","text":"<p>New files: - <code>src/zetherion_ai/api/routes/chat.py</code> \u2014 <code>POST /api/v1/chat</code>, <code>GET /api/v1/chat/history</code></p> <p>Modified files: - <code>src/zetherion_ai/agent/core.py</code> \u2014 Add <code>generate_response_for_tenant()</code> accepting <code>tenant_id</code> + <code>session_id</code> instead of Discord-specific IDs. Uses tenant config for system prompt overrides. Scopes Qdrant by <code>tenant_id</code>.</p> <p>Database: <pre><code>chat_messages (id, session_id FK, tenant_id, role, content, metadata JSONB, created_at)\n</code></pre></p> <p>Integration: Chat route calls <code>Agent</code> via <code>SkillsClient</code> (internal HTTP to 8080), using <code>user_id=f\"tenant:{tenant_id}:session:{session_id}\"</code> for data isolation.</p> <p>Deliverable: POST a message, get an AI response. History persists.</p>"},{"location":"MULTI_TENANT_API_PLAN/#phase-a3-sse-streaming","title":"Phase A3: SSE Streaming","text":"<p>Modified files: - <code>src/zetherion_ai/api/routes/chat.py</code> \u2014 Add SSE endpoint using <code>aiohttp.web.StreamResponse</code> - <code>src/zetherion_ai/agent/core.py</code> \u2014 Streaming variant that yields tokens</p> <p>SSE format: <pre><code>data: {\"type\": \"token\", \"content\": \"Hello\"}\ndata: {\"type\": \"token\", \"content\": \" there\"}\ndata: {\"type\": \"done\", \"message_id\": \"...\"}\n</code></pre></p> <p>Deliverable: Real-time streaming responses.</p>"},{"location":"MULTI_TENANT_API_PLAN/#phase-a4-cloudflare-tunnel-production-hardening","title":"Phase A4: Cloudflare Tunnel &amp; Production Hardening","text":"<p>New files: - <code>Dockerfile.api</code> \u2014 Multi-stage build (same Chainguard pattern as <code>Dockerfile.skills</code>)</p> <p>Modified files: - <code>docker-compose.yml</code> \u2014 Add <code>zetherion-api</code> + <code>cloudflared</code> services - <code>.env.example</code> \u2014 Add <code>CLOUDFLARE_TUNNEL_TOKEN</code> - <code>scripts/pre-push-tests.sh</code> \u2014 Add API server tests</p> <p>Hardening: Rate limiting, request size limits, audit logging (<code>tenant_audit_log</code>), usage tracking.</p> <p>Deliverable: API accessible via <code>https://api.yourdomain.com</code>.</p>"},{"location":"MULTI_TENANT_API_PLAN/#workstream-b-client-intelligence-skills","title":"Workstream B: Client Intelligence Skills","text":"<p>These are platform-agnostic skills. They can be triggered from Discord, Slack, the public API, or any future interface. Notifications go through a dispatch layer (Discord DM today, Slack/webhook tomorrow).</p>"},{"location":"MULTI_TENANT_API_PLAN/#skill-b1-client_provisioning-setup-lifecycle","title":"Skill B1: <code>client_provisioning</code> \u2014 Setup &amp; Lifecycle","text":"<p>Purpose: Create and manage client tenants. James triggers this from any interface.</p> <p>Intents: - <code>client_create</code> \u2014 \"Set up a new client called Bob's Plumbing for bobsplumbing.com\" - <code>client_configure</code> \u2014 \"Update Bob's chatbot personality to be more formal\" - <code>client_deactivate</code> \u2014 \"Pause Bob's account\" - <code>client_rotate_key</code> \u2014 \"Generate a new API key for Bob\" - <code>client_list</code> \u2014 \"Show me all my clients\"</p> <p>Implementation: - New skill in <code>src/zetherion_ai/skills/client_provisioning.py</code> - Calls <code>TenantManager</code> (from Workstream A) for all CRUD - Registers with <code>SkillRegistry</code> like any other skill - Platform-agnostic: works via Discord command, Slack, or future admin dashboard</p>"},{"location":"MULTI_TENANT_API_PLAN/#skill-b2-client_chat-runtime-conversation-handler","title":"Skill B2: <code>client_chat</code> \u2014 Runtime Conversation Handler","text":"<p>Purpose: The brain behind each client's website chatbot.</p> <p>How it works: 1. Public API receives a chat message \u2192 routes to this skill 2. L1a runs inline: lightweight critical signal detection (urgency, safety, escalation) 3. Loads tenant-specific config (system prompt, personality, allowed topics) 4. Generates response using the Agent with tenant context (adjusting if L1a flagged anything) 5. Returns response (or streams it via SSE) 6. Fires async extraction pipeline: L1b + L2 (on session close)</p> <p>Implementation: - New skill in <code>src/zetherion_ai/skills/client_chat.py</code> - Wraps <code>Agent.generate_response_for_tenant()</code> - Manages conversation context window per session - Applies tenant-specific system prompts from <code>tenants.config</code> - L1a detection as a fast pre-processing step (regex + lightweight classifier, not full LLM)</p>"},{"location":"MULTI_TENANT_API_PLAN/#skill-b3-tenant_intelligence-entity-extraction-for-the-tenant","title":"Skill B3: <code>tenant_intelligence</code> \u2014 Entity Extraction FOR the Tenant","text":"<p>Purpose: Passively extracts information useful to the tenant (L1b + L2 \"For Tenant\" columns).</p> <p>Handles: - L1b (per-message, async): Contact entities, intent, sentiment, purchase signals - L2 (per-session): Customer profile summary, conversation outcome, follow-up actions, topics</p> <p>Storage: Tenant-scoped tables (tenant can access via API): <pre><code>tenant_contacts (id, tenant_id, name, email, phone, source, tags[], custom_fields JSONB)\ntenant_interactions (id, tenant_id, contact_id FK, session_id, type, summary, entities JSONB, sentiment)\n</code></pre></p> <p>Implementation: - New skill in <code>src/zetherion_ai/skills/tenant_intelligence.py</code> - Runs asynchronously after each <code>client_chat</code> response - Uses LLM extraction (similar to Phase 9's personal understanding layer) - Stores in tenant-scoped Postgres tables - Data exposed back to tenant via API endpoints from the start</p>"},{"location":"MULTI_TENANT_API_PLAN/#skill-b4-client_insights-relationship-intelligence-for-james","title":"Skill B4: <code>client_insights</code> \u2014 Relationship Intelligence FOR James","text":"<p>Purpose: Extracts signals useful to James (L1b-L5 \"For James\" columns).</p> <p>Handles: - L1b/L2 (per-message/session): Feeds sentiment + outcome into aggregation - L3 (periodic): Volume trends, conversion rates, unmet needs, escalation rates per tenant - L4 (periodic): Cross-tenant benchmarks, emerging patterns, churn risk - L5 (continuous): Bot improvement suggestions, config recommendations</p> <p>How James consumes it: - On-demand: \"How are my clients doing?\" \u2192 summary from Qdrant + aggregation tables - Proactive alerts: Threshold-based notifications (\"Bob's satisfaction dropped 20%\")</p> <p>Storage: - Per-conversation signals \u2192 James's Qdrant (tagged with <code>client_tenant_id</code>) - Aggregated metrics \u2192 PostgreSQL aggregation table - Alerts \u2192 notification dispatch</p> <p>Implementation: - New skill in <code>src/zetherion_ai/skills/client_insights.py</code> - L1b/L2: Runs async after each response (parallel with B3, different extraction prompt) - L3: Runs on daily/weekly heartbeat schedule - L4: Runs on weekly heartbeat schedule - L5: Triggered when L3/L4 metrics cross thresholds - Stores in Qdrant with <code>owner_id=james</code> + <code>client_tenant_id</code> metadata</p>"},{"location":"MULTI_TENANT_API_PLAN/#notification-dispatch-cross-cutting","title":"Notification Dispatch (Cross-cutting)","text":"<p>Purpose: Route alerts/notifications to whatever platform James is using.</p> <p>Today: Discord DM (existing <code>bot.get_user().send()</code> pattern) Tomorrow: Slack webhook, email, push notification</p> <p>Implementation: - New module <code>src/zetherion_ai/notifications/dispatch.py</code> - Simple interface: <code>await dispatch.notify(user_id, message, priority)</code> - Backend registry: <code>{discord: DiscordNotifier, slack: SlackNotifier, ...}</code> - Skills call <code>dispatch.notify()</code> instead of platform-specific code</p>"},{"location":"MULTI_TENANT_API_PLAN/#key-existing-code-to-reuse","title":"Key Existing Code to Reuse","text":"What Where Reuse for aiohttp server pattern <code>src/zetherion_ai/skills/server.py</code> Public API server PostgreSQL manager pattern <code>src/zetherion_ai/discord/user_manager.py</code> TenantManager Agent inference pipeline <code>src/zetherion_ai/agent/core.py</code> <code>generate_response_for_tenant()</code> Qdrant user scoping <code>src/zetherion_ai/memory/qdrant.py</code> Scope by <code>tenant_id</code> Skill registration <code>src/zetherion_ai/skills/registry.py</code> Register all new skills Personal understanding (Phase 9) <code>src/zetherion_ai/personal/</code> Pattern for entity extraction in B3/B4 Pydantic settings <code>src/zetherion_ai/config.py</code> New config fields TestServer pattern <code>tests/integration/test_skills_http.py</code> API integration tests Docker multi-stage <code>Dockerfile.skills</code> <code>Dockerfile.api</code>"},{"location":"MULTI_TENANT_API_PLAN/#implementation-order","title":"Implementation Order","text":"<p>Recommended sequence (workstreams can partially overlap):</p> <ol> <li>A1 (Foundation) \u2014 Must come first, establishes tenant infrastructure</li> <li>B1 (Provisioning skill) \u2014 Can start as soon as A1's TenantManager exists</li> <li>A2 (Chat endpoint) \u2014 Depends on A1</li> <li>B2 (Chat skill) \u2014 Developed alongside A2</li> <li>A3 (SSE streaming) \u2014 Depends on A2</li> <li>B3 (Tenant intelligence) \u2014 Can start after B2 is working</li> <li>B4 (Client insights) \u2014 Can start after B2 is working, parallel with B3</li> <li>A4 (Cloudflare + hardening) \u2014 Final production step</li> <li>Notification dispatch \u2014 Can be built incrementally alongside B4</li> </ol>"},{"location":"MULTI_TENANT_API_PLAN/#verification","title":"Verification","text":"<p>After each phase: 1. <code>ruff check src/ tests/</code> passes 2. <code>pytest tests/ -m \"not integration and not discord_e2e\"</code> passes 3. In-process integration tests pass 4. Existing Discord bot tests remain green</p> <p>End-to-end (after A4): 1. All services healthy including <code>zetherion-api</code> and <code>cloudflared</code> 2. Health check returns 200 via public URL 3. Create tenant \u2192 get API key \u2192 create session \u2192 chat \u2192 get streaming AI response 4. Tenant intelligence extracts entities into tenant-scoped tables 5. Client insights surface trends to James via Discord 6. Discord bot continues working normally</p>"},{"location":"MULTI_TENANT_API_PLAN/#dependencies-to-add","title":"Dependencies to Add","text":"<ul> <li><code>PyJWT</code> \u2014 Session token signing/verification</li> <li><code>bcrypt</code> \u2014 API key hashing</li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/","title":"Windows Remote Installation Log","text":"<p>Date: 2026-02-10 Source Machine: macOS (192.168.0.168) Target Machine: Windows 11 - \"Computer-of-awesome\" (192.168.0.157) Windows User: james Method: SSH remoting from macOS to Windows PowerShell Result: SUCCESS - All 6 services healthy, bot connected to Discord</p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#prerequisites","title":"Prerequisites","text":""},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#on-windows-one-time-setup-run-as-administrator","title":"On Windows (one-time setup, run as Administrator)","text":"<ol> <li> <p>Enable OpenSSH Server:    <pre><code>Add-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0\nStart-Service sshd\nSet-Service -Name sshd -StartupType Automatic\n</code></pre></p> </li> <li> <p>Set PowerShell as default SSH shell:    <pre><code>New-ItemProperty -Path \"HKLM:\\SOFTWARE\\OpenSSH\" -Name DefaultShell -Value \"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -PropertyType String -Force\n</code></pre></p> </li> <li> <p>Add SSH public key (for admin user):    <pre><code>$authorizedKeysFile = \"$env:ProgramData\\ssh\\administrators_authorized_keys\"\nAdd-Content -Path $authorizedKeysFile -Value \"&lt;your-public-key&gt;\"\nicacls $authorizedKeysFile /inheritance:r /grant \"Administrators:F\" /grant \"SYSTEM:F\"\n</code></pre></p> </li> <li> <p>Restart SSH service:    <pre><code>Restart-Service sshd\n</code></pre></p> </li> <li> <p>Network profile: Ensure Windows network is set to Private (not Public), otherwise firewall blocks inbound SSH.</p> </li> <li> <p>Firewall rule (if SSH still blocked after setting Private):    <pre><code>New-NetFirewallRule -Name \"OpenSSH-Server-In-TCP\" -DisplayName \"OpenSSH Server (sshd)\" -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22\n</code></pre></p> </li> </ol>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#on-macos-one-time-setup","title":"On macOS (one-time setup)","text":"<ol> <li> <p>Generate SSH key:    <pre><code>ssh-keygen -t ed25519 -f ~/.ssh/zetherion_windows -N \"\" -C \"zetherion-remote-install\"\n</code></pre></p> </li> <li> <p>Copy public key to the Windows machine (paste into step 3 above):    <pre><code>cat ~/.ssh/zetherion_windows.pub\n</code></pre></p> </li> <li> <p>Test connection:    <pre><code>ssh -i ~/.ssh/zetherion_windows -o StrictHostKeyChecking=accept-new james@&lt;WINDOWS_IP&gt; \"whoami; hostname\"\n</code></pre></p> </li> </ol>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#verified-prerequisites-on-windows","title":"Verified Prerequisites on Windows","text":"<ul> <li>Docker Desktop 29.2.0</li> <li>Git 2.33.0</li> <li>GitHub CLI 2.86.0</li> <li>63GB RAM</li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#installation-steps","title":"Installation Steps","text":"<p>All commands below use this SSH prefix (abbreviated as <code>SSH</code> in examples): <pre><code>SSH=\"ssh -i ~/.ssh/zetherion_windows -o ConnectTimeout=10 james@192.168.0.157\"\n</code></pre></p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-1-start-docker-desktop-if-not-running","title":"Step 1: Start Docker Desktop (if not running)","text":"<pre><code>$SSH \"Start-Process 'C:\\Program Files\\Docker\\Docker\\Docker Desktop.exe'\"\n# Wait ~60 seconds for Docker to initialize\n$SSH \"docker info | Select-String 'Server Version'\"\n</code></pre>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-2-disable-docker-credential-store-required-for-ssh-sessions","title":"Step 2: Disable Docker Credential Store (required for SSH sessions)","text":"<p>Docker Desktop's credential helper uses Windows Credential Manager, which is not accessible over SSH. Temporarily disable it: <pre><code>$SSH \"Copy-Item ~\\.docker\\config.json ~\\.docker\\config.json.bak\"\n$SSH \"(Get-Content ~\\.docker\\config.json) -replace '\\\"credsStore\\\": \\\"desktop\\\"', '\\\"credsStore\\\": \\\"\\\"' | Set-Content ~\\.docker\\config.json\"\n</code></pre></p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-3-clone-repository","title":"Step 3: Clone Repository","text":"<pre><code>$SSH \"git clone https://github.com/jimtin/zetherion-ai.git C:\\ZetherionAI\"\n</code></pre>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-4-configure-environment","title":"Step 4: Configure Environment","text":"<p>Option A - Copy .env from existing installation: <pre><code>scp -i ~/.ssh/zetherion_windows /path/to/local/.env james@192.168.0.157:C:/ZetherionAI/.env\n</code></pre></p> <p>Option B - Create from template and edit: <pre><code>$SSH \"Copy-Item C:\\ZetherionAI\\.env.example C:\\ZetherionAI\\.env\"\n# Then edit via RDP or use PowerShell to set values\n</code></pre></p> <p>Minimum required keys: <code>DISCORD_TOKEN</code>, <code>GEMINI_API_KEY</code>, <code>ENCRYPTION_PASSPHRASE</code></p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-5-build-and-start-services","title":"Step 5: Build and Start Services","text":"<p><pre><code>$SSH \"cd C:\\ZetherionAI; docker compose up -d --build\"\n</code></pre> This pulls base images (~3.2GB for Ollama x2, ~200MB for Postgres, ~150MB for Qdrant), builds the bot and skills images, and starts all 6 containers.</p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-6-verify-all-services-healthy","title":"Step 6: Verify All Services Healthy","text":"<p><pre><code>$SSH \"cd C:\\ZetherionAI; docker compose ps --format 'table {{.Name}}\\t{{.Status}}'\"\n</code></pre> Expected: All 6 containers show <code>(healthy)</code>.</p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-7-pull-ollama-models","title":"Step 7: Pull Ollama Models","text":"<p>These can be pulled in parallel: <pre><code># Router model (2.0GB)\n$SSH \"docker exec zetherion-ai-ollama-router ollama pull llama3.2:3b\"\n\n# Generation model (4.9GB)\n$SSH \"docker exec zetherion-ai-ollama ollama pull llama3.1:8b\"\n\n# Embedding model (274MB)\n$SSH \"docker exec zetherion-ai-ollama ollama pull nomic-embed-text\"\n</code></pre></p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-7b-warm-up-ollama-models-critical","title":"Step 7b: Warm Up Ollama Models (Critical)","text":"<p>After pulling, models must be loaded into memory before the bot can use them. The first load from disk can take 30-60+ seconds per model, which exceeds the bot's default 30-second timeout. Warm them up explicitly: <pre><code># Warm up router model (loads ~2.0GB into RAM)\n$SSH \"docker exec zetherion-ai-ollama-router ollama run llama3.2:3b 'Say hi'\"\n\n# Warm up generation model (loads ~4.9GB into RAM)\n$SSH \"docker exec zetherion-ai-ollama ollama run llama3.1:8b 'Say hi'\"\n\n# Warm up embedding model (loads ~274MB into RAM)\n$SSH \"docker exec zetherion-ai-ollama ollama run nomic-embed-text 'test'\"\n</code></pre> Why this matters: Without warmup, the first Discord message will trigger a cold model load. With a 30-second Ollama timeout, the router classification times out, then the generation request times out \u2014 resulting in 60 seconds of waiting followed by an error message. The bot's built-in keep-warm task runs every 5 minutes, but only works once models are already loaded.</p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-8-verify-bot-connected-to-discord","title":"Step 8: Verify Bot Connected to Discord","text":"<p><pre><code>$SSH \"cd C:\\ZetherionAI; docker compose logs zetherion-ai-bot --tail 5\"\n</code></pre> Look for: <code>\"event\": \"bot_ready\"</code> with your bot's username and guild count.</p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-9-restore-docker-credential-store","title":"Step 9: Restore Docker Credential Store","text":"<pre><code>$SSH \"Copy-Item ~\\.docker\\config.json.bak ~\\.docker\\config.json -Force\"\n</code></pre>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#step-10-end-to-end-verification","title":"Step 10: End-to-End Verification","text":"<p>Run this from a container to verify all service-to-service communication works:</p> <pre><code>$SSH \"docker exec zetherion-ai-skills python -c \\\"\nimport urllib.request, json, time\n\ntests = [\n    ('Router', 'http://ollama-router:11434/api/generate',\n     json.dumps({'model':'llama3.2:3b','prompt':'Say hi','stream':False}).encode()),\n    ('Generation', 'http://ollama:11434/api/generate',\n     json.dumps({'model':'llama3.1:8b','prompt':'Say hi','stream':False}).encode()),\n    ('Embeddings', 'http://ollama:11434/api/embed',\n     json.dumps({'model':'nomic-embed-text','input':'test'}).encode()),\n    ('Qdrant', 'http://qdrant:6333/collections', None),\n    ('Skills', 'http://zetherion-ai-skills:8080/health', None),\n]\n\nfor name, url, data in tests:\n    start = time.time()\n    req = urllib.request.Request(url, data=data,\n        headers={'Content-Type':'application/json'} if data else {})\n    r = urllib.request.urlopen(req, timeout=30)\n    print(f'  PASS {name}: {time.time()-start:.1f}s')\n\nprint('ALL TESTS PASSED')\n\\\"\"\n</code></pre> <p>Expected: All 5 tests pass. Router and generation should respond in &lt;3 seconds each.</p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issues-encountered-and-fixes","title":"Issues Encountered and Fixes","text":""},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issue-1-ssh-connection-timeout","title":"Issue 1: SSH Connection Timeout","text":"<ul> <li>Symptom: <code>ssh: connect to host 192.168.0.157 port 22: Operation timed out</code></li> <li>Cause: Windows network profile was set to \"Public\", which blocks inbound connections</li> <li>Fix: Changed network profile to \"Private\" in Windows Settings &gt; Network &amp; Internet</li> <li>Note: Even on the same subnet (both <code>192.168.0.x</code>), Public profile blocks all inbound traffic</li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issue-2-powershell-operator-not-supported","title":"Issue 2: PowerShell <code>&amp;&amp;</code> Operator Not Supported","text":"<ul> <li>Symptom: <code>The token '&amp;&amp;' is not a valid statement separator in this version</code></li> <li>Cause: Windows PowerShell (5.x) doesn't support <code>&amp;&amp;</code> chaining (PowerShell 7+ does)</li> <li>Fix: Use <code>;</code> (semicolons) to chain commands. Note: <code>;</code> runs next command regardless of previous exit code, unlike <code>&amp;&amp;</code></li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issue-3-docker-credential-store-fails-over-ssh","title":"Issue 3: Docker Credential Store Fails Over SSH","text":"<ul> <li>Symptom: <code>error getting credentials - err: exit status 1, out: 'A specified logon session does not exist'</code></li> <li>Cause: Docker Desktop uses <code>\"credsStore\": \"desktop\"</code> in <code>~/.docker/config.json</code>, which relies on Windows Credential Manager (not available over SSH)</li> <li>Fix: Temporarily change <code>credsStore</code> to <code>\"\"</code> in config.json before pulling images, then restore afterward</li> <li>Important: Restore the original config.json after installation so Docker Desktop works normally via GUI</li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issue-4-docker-composeyml-version-warning","title":"Issue 4: docker-compose.yml <code>version</code> Warning","text":"<ul> <li>Symptom: <code>the attribute 'version' is obsolete, it will be ignored</code></li> <li>Cause: Docker Compose V2 no longer requires the <code>version</code> field</li> <li>Fix: Removed <code>version: '3.8'</code> from docker-compose.yml and docker-compose.dev.yml</li> <li>Note: This also caused PowerShell to report exit code 1 because it treats stderr output as errors</li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issue-5-not-authorized-on-fresh-install-empty-rbac-table","title":"Issue 5: \"Not Authorized\" on Fresh Install (Empty RBAC Table)","text":"<ul> <li>Symptom: Bot replies \"Sorry, you're not authorized to use this bot.\" to all messages</li> <li>Cause: The bot uses PostgreSQL-backed RBAC. On first start, <code>_bootstrap()</code> seeds users from <code>ALLOWED_USER_IDS</code> and <code>OWNER_USER_ID</code> in <code>.env</code>. If both are empty, the <code>users</code> table is empty and nobody can authenticate.</li> <li>Fix (immediate): Insert the user directly into PostgreSQL:   <pre><code>$SSH \"docker exec zetherion-ai-postgres psql -U zetherion -d zetherion -c \\\"INSERT INTO users (discord_user_id, role, added_by) VALUES (&lt;YOUR_DISCORD_ID&gt;, 'owner', &lt;YOUR_DISCORD_ID&gt;) ON CONFLICT DO NOTHING;\\\"\"\n</code></pre></li> <li>Fix (prevent): Set <code>ALLOWED_USER_IDS=&lt;your_discord_id&gt;</code> in <code>.env</code> BEFORE first <code>docker compose up</code>. The bootstrap only runs when the <code>users</code> table is empty.</li> <li>How to get your Discord User ID: Enable Developer Mode in Discord Settings &gt; Advanced, then right-click your username &gt; \"Copy User ID\"</li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issue-6-ollama-warmup-404-on-first-start","title":"Issue 6: Ollama Warmup 404 on First Start","text":"<ul> <li>Symptom: <code>ollama_warmup_failed</code> with 404 error in bot logs</li> <li>Cause: Ollama containers are running but models haven't been pulled yet</li> <li>Fix: Pull models (Step 7) - the bot continues to function and will use the models once available</li> <li>Note: The bot falls back to cloud providers (Gemini/Claude/OpenAI) until local models are ready</li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issue-7-error-processing-request-after-model-pull-cold-load-timeout","title":"Issue 7: \"Error Processing Request\" After Model Pull (Cold Load Timeout)","text":"<ul> <li>Symptom: Bot replies with an error after ~60 seconds. Logs show <code>ollama_timeout</code> followed by <code>ollama_generation_failed</code></li> <li>Cause: After pulling, the first request triggers a cold load of the model from disk into RAM. For llama3.1:8b (4.9GB) this can take 30-60+ seconds, exceeding the bot's 30-second Ollama timeout. The request chain is: router classification (30s timeout) -&gt; generation (30s timeout) -&gt; both fail -&gt; error</li> <li>Fix: Run explicit warmup commands after pulling models (see Step 7b). Each <code>ollama run</code> forces the model into memory. Once loaded, models stay resident until the container restarts.</li> <li>Log signature:   <pre><code>ollama_timeout \u2192 message_routed (confidence: 0.5, duration_ms: 30003)\nollama_generation_failed \u2192 intent_handled (response_length: 56)\n</code></pre></li> <li>Note: The bot's built-in keep-warm task pings models every 5 minutes, but this only works if the model is already loaded. It cannot trigger the initial disk-to-RAM load within the timeout window.</li> </ul>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#issue-8-router-container-memory-limit-too-low-ollama-oom-stall","title":"Issue 8: Router Container Memory Limit Too Low (Ollama OOM Stall)","text":"<ul> <li>Symptom: Bot timeouts persist even after models are pulled and warmed up via <code>docker exec</code>. Router model appears loaded (<code>ollama ps</code> shows it), but generate requests from other containers hang forever. <code>docker stats</code> shows router at 99.97% memory.</li> <li>Cause: The <code>docker-compose.yml</code> had <code>memory: 1G</code> for the ollama-router container, but llama3.2:3b at Q8_0 quantization requires 2.5 GB just for model weights. With only 1GB available, the container had zero headroom for inference working memory. Ollama could hold the model in memory but couldn't allocate the additional buffers needed to actually run inference, causing requests to stall.</li> <li>Key diagnostic: <code>docker exec ollama run</code> (runs inside the container) appeared to work because Ollama handles internal requests differently, but HTTP API requests from other containers over the Docker network (<code>http://ollama-router:11434/api/generate</code>) hung indefinitely. The <code>/api/tags</code> endpoint (metadata only, no inference) also worked fine, making this look like a networking issue when it was actually a memory issue.</li> <li>Fix: Increased router memory limit in <code>docker-compose.yml</code>:</li> </ul> <pre><code># Before (broken):\nmemory: 1G  # 0.5b model only needs ~500MB  \u2190 wrong comment, wrong limit\n\n# After (working):\nmemory: 3G  # 3b model needs ~2.5GB + inference overhead\n</code></pre> <p>After fix: router uses 1.5 GiB / 3 GiB (50%) and responds in &lt;1 second. - Rule of thumb: Set Ollama container memory limit to at least 2x the model size to ensure adequate inference headroom.</p>"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#final-state","title":"Final State","text":"Service Container Status Notes Bot zetherion-ai-bot healthy Connected to Discord as SecureClaw#7693 Skills zetherion-ai-skills healthy HTTP service on port 8080 (internal) Qdrant zetherion-ai-qdrant healthy Vector DB on port 6333 PostgreSQL zetherion-ai-postgres healthy Relational DB on port 5432 Ollama (Generation) zetherion-ai-ollama healthy llama3.1:8b + nomic-embed-text Ollama (Router) zetherion-ai-ollama-router healthy llama3.2:3b"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#ollama-models-installed","title":"Ollama Models Installed","text":"Container Model Size ollama (generation) llama3.1:8b 4.9 GB ollama (generation) nomic-embed-text 274 MB ollama-router llama3.2:3b 2.0 GB"},{"location":"WINDOWS_REMOTE_INSTALL_LOG/#key-learnings-for-automation","title":"Key Learnings for Automation","text":"<ol> <li>SSH to Windows PowerShell works well for remote deployment, but requires careful handling of:</li> <li>PowerShell syntax differences (<code>;</code> not <code>&amp;&amp;</code>, different string escaping)</li> <li>Credential store limitations (Windows Credential Manager unavailable over SSH)</li> <li> <p>stderr handling (PowerShell treats stderr as errors, causing misleading exit codes)</p> </li> <li> <p>Docker Desktop must be started before SSH deployment - it doesn't auto-start on Windows like a daemon</p> </li> <li> <p>Model pulls are the slowest part (~6.5GB total) - consider pre-pulling or caching</p> </li> <li> <p>The <code>.env</code> file can be SCP'd directly from an existing installation, simplifying key management</p> </li> <li> <p>Network profile matters - Windows Public network blocks all inbound connections; must be set to Private for SSH access</p> </li> <li> <p>Container memory limits must account for inference overhead - Ollama needs ~2x the model file size in RAM (model weights + inference buffers). A 2.0GB model needs ~3GB container limit. Insufficient memory causes silent stalls where the API accepts connections but never returns responses.</p> </li> <li> <p>Always run end-to-end verification (Step 10) after installation. Testing from inside the Docker network catches issues that <code>docker exec</code> tests miss, since <code>docker exec</code> runs inside the container (localhost) while the bot communicates over the Docker bridge network.</p> </li> </ol>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/","title":"YouTube Skill Output Schemas","text":"<p>Reference for website developers consuming the YouTube skills API.</p> <p>All endpoints return JSON. Dates are ISO 8601. UUIDs are v4.</p>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#intelligence-report","title":"Intelligence Report","text":"<p>Returned by <code>GET /api/v1/youtube/channels/{ch}/intelligence</code>.</p> <pre><code>{\n  \"report_id\": \"uuid\",\n  \"channel_id\": \"uuid\",\n  \"generated_at\": \"ISO8601\",\n  \"overview\": {\n    \"channel_name\": \"str\",\n    \"subscriber_count\": 10000,\n    \"total_views\": 500000,\n    \"video_count\": 100,\n    \"growth_trend\": \"increasing|stable|declining\",\n    \"growth_rate_percent\": 5.2,\n    \"period\": { \"from\": \"ISO8601\", \"to\": \"ISO8601\" }\n  },\n  \"content_performance\": {\n    \"top_performing\": [\n      {\n        \"video_id\": \"str\",\n        \"title\": \"str\",\n        \"views\": 15000,\n        \"engagement_rate\": 0.038,\n        \"why\": \"str\"\n      }\n    ],\n    \"underperforming\": [\n      {\n        \"video_id\": \"str\",\n        \"title\": \"str\",\n        \"views\": 200,\n        \"issues\": [\"str\"]\n      }\n    ],\n    \"categories\": [\n      {\n        \"name\": \"tutorials\",\n        \"video_count\": 30,\n        \"avg_views\": 8000,\n        \"trend\": \"growing\"\n      }\n    ],\n    \"optimal_length_minutes\": { \"min\": 8, \"max\": 15, \"sweet_spot\": 12 },\n    \"best_posting_times\": [{ \"day\": \"Tuesday\", \"hour_utc\": 14 }]\n  },\n  \"audience\": {\n    \"sentiment\": { \"positive\": 0.65, \"neutral\": 0.25, \"negative\": 0.10 },\n    \"top_requests\": [\n      { \"topic\": \"str\", \"mentions\": 25, \"sentiment\": \"positive\" }\n    ],\n    \"unanswered_questions\": [{ \"question\": \"str\", \"frequency\": 12 }],\n    \"complaints\": [\n      { \"issue\": \"str\", \"frequency\": 8, \"severity\": \"medium\" }\n    ]\n  },\n  \"recommendations\": [\n    {\n      \"priority\": \"high|medium|low\",\n      \"category\": \"content|engagement|seo|schedule|community\",\n      \"action\": \"str\",\n      \"rationale\": \"str\",\n      \"expected_impact\": \"high|medium|low\",\n      \"effort\": \"low|medium|high\"\n    }\n  ]\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#reply-draft","title":"Reply Draft","text":"<p>Returned by <code>GET /api/v1/youtube/channels/{ch}/management/replies</code>.</p> <pre><code>{\n  \"reply_id\": \"uuid\",\n  \"comment_id\": \"str\",\n  \"video_id\": \"str\",\n  \"original_comment\": \"str\",\n  \"draft_reply\": \"str\",\n  \"confidence\": 0.85,\n  \"category\": \"thank_you|faq|question|feedback|complaint\",\n  \"status\": \"pending|approved|rejected|posted\",\n  \"auto_approved\": false,\n  \"model_used\": \"str\",\n  \"created_at\": \"ISO8601\"\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#updating-a-reply","title":"Updating a Reply","text":"<p><code>PATCH /api/v1/youtube/channels/{ch}/management/replies/{id}</code></p> <p>Body: <pre><code>{ \"action\": \"approve|reject|posted\" }\n</code></pre></p>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#management-state","title":"Management State","text":"<p>Returned by <code>GET /api/v1/youtube/channels/{ch}/management</code>.</p> <pre><code>{\n  \"channel_id\": \"uuid\",\n  \"updated_at\": \"ISO8601\",\n  \"onboarding_complete\": true,\n  \"trust\": {\n    \"level\": 1,\n    \"label\": \"GUIDED\",\n    \"stats\": {\n      \"total\": 150,\n      \"approved\": 145,\n      \"rejected\": 5,\n      \"rate\": 0.967\n    },\n    \"next_level_at\": 200\n  },\n  \"auto_reply\": {\n    \"enabled\": true,\n    \"auto_categories\": [\"thank_you\", \"faq\"],\n    \"review_categories\": [\"complaint\"],\n    \"pending_count\": 3,\n    \"posted_today\": 12\n  },\n  \"health_issues\": [\n    {\n      \"type\": \"str\",\n      \"severity\": \"low|medium|high\",\n      \"suggestion\": \"str\"\n    }\n  ]\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#strategy-document","title":"Strategy Document","text":"<p>Returned by <code>GET /api/v1/youtube/channels/{ch}/strategy</code>.</p> <pre><code>{\n  \"strategy_id\": \"uuid\",\n  \"channel_id\": \"uuid\",\n  \"generated_at\": \"ISO8601\",\n  \"valid_until\": \"ISO8601\",\n  \"executive_summary\": \"str\",\n  \"positioning\": {\n    \"niche\": \"str\",\n    \"target_audience\": \"str\",\n    \"value_proposition\": \"str\",\n    \"tone\": \"str\"\n  },\n  \"content_strategy\": {\n    \"pillars\": [\n      { \"name\": \"str\", \"percentage\": 40, \"rationale\": \"str\" }\n    ],\n    \"calendar\": [\n      {\n        \"week\": 1,\n        \"day\": \"Monday\",\n        \"type\": \"str\",\n        \"topic\": \"str\",\n        \"title\": \"str\",\n        \"tags\": [\"str\"]\n      }\n    ],\n    \"series_ideas\": [\n      {\n        \"name\": \"str\",\n        \"description\": \"str\",\n        \"episodes\": 10,\n        \"frequency\": \"weekly\"\n      }\n    ]\n  },\n  \"growth_tactics\": [\n    {\n      \"tactic\": \"str\",\n      \"priority\": \"high\",\n      \"impact\": \"str\",\n      \"effort\": \"low|medium|high\",\n      \"timeline\": \"str\"\n    }\n  ],\n  \"seo\": {\n    \"title_patterns\": [\"str\"],\n    \"description_template\": \"str\",\n    \"tag_strategy\": \"str\"\n  },\n  \"kpis\": [\n    {\n      \"metric\": \"str\",\n      \"current\": 10000,\n      \"target_30d\": 11000,\n      \"target_90d\": 15000\n    }\n  ]\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#tag-recommendation","title":"Tag Recommendation","text":"<p>Returned by <code>GET /api/v1/youtube/channels/{ch}/management/tags</code>.</p> <pre><code>{\n  \"id\": \"uuid\",\n  \"channel_id\": \"uuid\",\n  \"video_id\": \"str|null\",\n  \"current_tags\": [\"str\"],\n  \"suggested_tags\": [\"str\"],\n  \"reason\": \"str\",\n  \"status\": \"pending|applied|dismissed\",\n  \"created_at\": \"ISO8601\"\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#channel-assumption","title":"Channel Assumption","text":"<p>Returned by <code>GET /api/v1/youtube/channels/{ch}/assumptions</code>.</p> <pre><code>{\n  \"id\": \"uuid\",\n  \"channel_id\": \"uuid\",\n  \"category\": \"audience|content|tone|schedule|topic|competitor|performance\",\n  \"statement\": \"str\",\n  \"evidence\": [\"str\"],\n  \"confidence\": 0.85,\n  \"source\": \"confirmed|inferred|invalidated\",\n  \"confirmed_at\": \"ISO8601|null\",\n  \"last_validated\": \"ISO8601\",\n  \"next_validation\": \"ISO8601\"\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#updating-an-assumption","title":"Updating an Assumption","text":"<p><code>PATCH /api/v1/youtube/channels/{ch}/assumptions/{id}</code></p> <p>Body: <pre><code>{ \"action\": \"confirm|invalidate\" }\n</code></pre></p>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#channel-health-audit","title":"Channel Health Audit","text":"<p>Returned by <code>GET /api/v1/youtube/channels/{ch}/management/health</code>.</p> <pre><code>{\n  \"channel_id\": \"uuid\",\n  \"audit_date\": \"ISO8601\",\n  \"issues\": [\n    {\n      \"type\": \"str\",\n      \"severity\": \"low|medium|high\",\n      \"current_state\": \"str\",\n      \"suggestion\": \"str\"\n    }\n  ],\n  \"score\": 85\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#data-ingestion-endpoints","title":"Data Ingestion Endpoints","text":""},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#push-videos","title":"Push Videos","text":"<p><code>POST /api/v1/youtube/channels/{ch}/videos</code></p> <pre><code>{\n  \"videos\": [\n    {\n      \"video_youtube_id\": \"str\",\n      \"title\": \"str\",\n      \"description\": \"str\",\n      \"tags\": [\"str\"],\n      \"stats\": { \"views\": 1000, \"likes\": 50, \"comments\": 10 },\n      \"published_at\": \"ISO8601\"\n    }\n  ]\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#push-comments","title":"Push Comments","text":"<p><code>POST /api/v1/youtube/channels/{ch}/comments</code></p> <pre><code>{\n  \"comments\": [\n    {\n      \"video_youtube_id\": \"str\",\n      \"comment_youtube_id\": \"str\",\n      \"author\": \"str\",\n      \"text\": \"str\",\n      \"like_count\": 5,\n      \"published_at\": \"ISO8601\",\n      \"parent_comment_id\": \"str|null\"\n    }\n  ]\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#push-stats-snapshot","title":"Push Stats Snapshot","text":"<p><code>POST /api/v1/youtube/channels/{ch}/stats</code></p> <pre><code>{\n  \"snapshot\": {\n    \"subscriber_count\": 10000,\n    \"total_views\": 500000,\n    \"video_count\": 100\n  }\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#push-document","title":"Push Document","text":"<p><code>POST /api/v1/youtube/channels/{ch}/documents</code></p> <pre><code>{\n  \"title\": \"Brand Guidelines\",\n  \"content\": \"Full text content...\",\n  \"doc_type\": \"brand_guide|audience_research|style_guide|other\"\n}\n</code></pre>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#common-patterns","title":"Common Patterns","text":""},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#authentication","title":"Authentication","text":"<p>All endpoints require <code>X-API-Key</code> header with a valid tenant API key.</p>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#error-responses","title":"Error Responses","text":"<pre><code>{\n  \"error\": \"Human-readable error message\"\n}\n</code></pre> <p>HTTP status codes: <code>400</code> (bad request), <code>401</code> (unauthorized), <code>403</code> (forbidden), <code>404</code> (not found), <code>503</code> (service unavailable).</p>"},{"location":"YOUTUBE_SKILL_OUTPUT_SCHEMAS/#trust-levels","title":"Trust Levels","text":"Level Label Behavior 0 SUPERVISED All replies need human approval 1 GUIDED Routine replies auto-approved 2 AUTONOMOUS Most auto-approved; flagged need review 3 FULL_AUTO All auto-approved; retroactive review"},{"location":"development/adding-a-skill/","title":"Adding a Skill","text":"<p>This tutorial walks through creating a custom skill for Zetherion AI, from planning through testing. By the end, you will have a fully functional skill that handles multiple intents, integrates with the skills framework, and includes comprehensive tests.</p> <p>For the skills framework internals, see <code>../technical/skills-framework.md</code>. For the development environment setup, see <code>setup.md</code>.</p>"},{"location":"development/adding-a-skill/#overview","title":"Overview","text":"<p>A skill is a modular capability that the bot can invoke to perform a specific category of tasks. Skills are routed to by intent: when the message router classifies a user message as matching one of a skill's declared intents, the framework dispatches the request to that skill.</p> <p>Each skill:</p> <ul> <li>Declares its metadata (name, version, intents, permissions, Qdrant collections)</li> <li>Implements an initialize method for setup (creating collections, validating config)</li> <li>Implements a handle method that receives a <code>SkillRequest</code> and returns a <code>SkillResponse</code></li> <li>Optionally implements heartbeat behavior for proactive actions (reminders, digests)</li> <li>Optionally contributes a system prompt fragment to inject context into the agent's prompt</li> </ul> <p>Skills run inside the <code>zetherion-ai-skills</code> Docker service and communicate with the bot container over a REST API.</p>"},{"location":"development/adding-a-skill/#prerequisites","title":"Prerequisites","text":"<ul> <li>Working development environment (see <code>setup.md</code>)</li> <li>Familiarity with async Python (<code>async</code>/<code>await</code>, <code>asyncio</code>)</li> <li>Understanding of the skills framework classes (covered below)</li> </ul>"},{"location":"development/adding-a-skill/#key-classes","title":"Key Classes","text":"<p>Before writing code, familiarize yourself with the framework types defined in <code>src/zetherion_ai/skills/base.py</code> and <code>src/zetherion_ai/skills/permissions.py</code>.</p>"},{"location":"development/adding-a-skill/#skill-abstract-base-class","title":"Skill (abstract base class)","text":"<pre><code>class Skill(ABC):\n    def __init__(self, memory: QdrantMemory | None = None): ...\n\n    @property\n    @abstractmethod\n    def metadata(self) -&gt; SkillMetadata: ...\n\n    @abstractmethod\n    async def initialize(self) -&gt; bool: ...\n\n    @abstractmethod\n    async def handle(self, request: SkillRequest) -&gt; SkillResponse: ...\n\n    # Optional overrides\n    async def on_heartbeat(self, user_ids: list[str]) -&gt; list[HeartbeatAction]: ...\n    def get_system_prompt_fragment(self, user_id: str) -&gt; str | None: ...\n    async def cleanup(self) -&gt; None: ...\n</code></pre>"},{"location":"development/adding-a-skill/#skillrequest","title":"SkillRequest","text":"<pre><code>@dataclass\nclass SkillRequest:\n    id: UUID                          # Unique request identifier\n    user_id: str                      # Discord user ID\n    intent: str                       # Classified intent (e.g., \"weather_current\")\n    message: str                      # Original user message\n    context: dict[str, Any]           # Additional context from the router\n    timestamp: datetime               # When the request was created\n</code></pre>"},{"location":"development/adding-a-skill/#skillresponse","title":"SkillResponse","text":"<pre><code>@dataclass\nclass SkillResponse:\n    request_id: UUID                  # Matches the SkillRequest.id\n    success: bool                     # Whether the operation succeeded\n    message: str                      # Human-readable response for the user\n    data: dict[str, Any]              # Structured data (for programmatic use)\n    error: str | None                 # Error message if success is False\n    actions: list[dict[str, Any]]     # Follow-up actions to take\n</code></pre> <p>Use <code>SkillResponse.error_response(request_id, error_message)</code> as a shortcut for error cases.</p>"},{"location":"development/adding-a-skill/#skillmetadata","title":"SkillMetadata","text":"<pre><code>@dataclass\nclass SkillMetadata:\n    name: str                         # Unique skill identifier (snake_case)\n    description: str                  # Human-readable description\n    version: str                      # Semantic version (e.g., \"1.0.0\")\n    author: str                       # Defaults to \"Zetherion AI\"\n    permissions: PermissionSet        # Required permissions\n    collections: list[str]            # Qdrant collections this skill uses\n    intents: list[str]                # Intents this skill handles\n</code></pre>"},{"location":"development/adding-a-skill/#heartbeataction","title":"HeartbeatAction","text":"<pre><code>@dataclass\nclass HeartbeatAction:\n    skill_name: str                   # Which skill generated the action\n    action_type: str                  # \"send_message\", \"update_memory\", etc.\n    user_id: str                      # Target user\n    data: dict[str, Any]              # Payload for the action\n    priority: int                     # Higher values = more important\n</code></pre>"},{"location":"development/adding-a-skill/#permission","title":"Permission","text":"<p>The <code>Permission</code> enum in <code>zetherion_ai.skills.permissions</code> defines what resources a skill can access:</p> Permission Description <code>READ_PROFILE</code> Read user profile entries <code>WRITE_PROFILE</code> Create or update profile entries <code>DELETE_PROFILE</code> Delete profile entries <code>READ_MEMORIES</code> Read from conversation memory <code>WRITE_MEMORIES</code> Store new memories <code>DELETE_MEMORIES</code> Delete memories <code>SEND_MESSAGES</code> Send proactive messages <code>SEND_DM</code> Send direct messages <code>SCHEDULE_TASKS</code> Schedule future actions <code>READ_SCHEDULE</code> Read scheduled events <code>READ_OWN_COLLECTION</code> Read from the skill's Qdrant collection <code>WRITE_OWN_COLLECTION</code> Write to the skill's Qdrant collection <code>INVOKE_OTHER_SKILLS</code> Call other skills <code>READ_CONFIG</code> Read configuration values <code>ADMIN</code> Full administrative access (rarely granted) <p>Pre-built permission sets are available: <code>READONLY_PERMISSIONS</code>, <code>STANDARD_PERMISSIONS</code>, <code>PROACTIVE_PERMISSIONS</code>.</p>"},{"location":"development/adding-a-skill/#step-1-plan-your-skill","title":"Step 1: Plan Your Skill","text":"<p>Before writing code, decide on these three things.</p>"},{"location":"development/adding-a-skill/#choose-intents","title":"Choose Intents","text":"<p>Intents follow the <code>verb_noun</code> naming convention. Each intent maps to one handler method. Pick names that are specific enough to avoid collisions with other skills.</p> <p>For a weather skill, good intents would be:</p> <ul> <li><code>weather_current</code> -- get current weather for a location</li> <li><code>weather_forecast</code> -- get a multi-day forecast</li> </ul> <p>Avoid generic names like <code>get_data</code> or <code>check_status</code> that could conflict.</p>"},{"location":"development/adding-a-skill/#define-permissions","title":"Define Permissions","text":"<p>Choose the minimum set of permissions your skill needs. For a weather skill that stores cached results in its own Qdrant collection and can send proactive weather alerts:</p> <ul> <li><code>READ_OWN_COLLECTION</code> -- read cached weather data</li> <li><code>WRITE_OWN_COLLECTION</code> -- write cached weather data</li> <li><code>SEND_MESSAGES</code> -- send proactive weather alerts</li> </ul>"},{"location":"development/adding-a-skill/#plan-data-storage","title":"Plan Data Storage","text":"<p>If your skill stores data in Qdrant, decide on a collection name. Use the <code>skill_</code> prefix convention:</p> <ul> <li><code>skill_weather</code> -- weather cache collection</li> </ul>"},{"location":"development/adding-a-skill/#step-2-create-the-skill-module","title":"Step 2: Create the Skill Module","text":"<p>Create the directory structure:</p> <pre><code>mkdir -p src/zetherion_ai/skills/weather\ntouch src/zetherion_ai/skills/weather/__init__.py\ntouch src/zetherion_ai/skills/weather/skill.py\n</code></pre> <p>Add the package export in <code>__init__.py</code>:</p> <pre><code>\"\"\"Weather skill for Zetherion AI.\"\"\"\n\nfrom zetherion_ai.skills.weather.skill import WeatherSkill\n\n__all__ = [\"WeatherSkill\"]\n</code></pre>"},{"location":"development/adding-a-skill/#step-3-implement-the-skill-class","title":"Step 3: Implement the Skill Class","text":"<p>This is the full annotated implementation of a weather skill with two intents.</p> <pre><code>\"\"\"Weather Skill for Zetherion AI.\n\nProvides weather information capabilities:\n- Current weather conditions for a location\n- Multi-day weather forecasts\n- Proactive severe weather alerts via heartbeat\n\"\"\"\n\nfrom typing import TYPE_CHECKING, Any\n\nfrom zetherion_ai.logging import get_logger\nfrom zetherion_ai.skills.base import (\n    HeartbeatAction,\n    Skill,\n    SkillMetadata,\n    SkillRequest,\n    SkillResponse,\n)\nfrom zetherion_ai.skills.permissions import Permission, PermissionSet\n\nif TYPE_CHECKING:\n    from zetherion_ai.memory.qdrant import QdrantMemory\n\nlog = get_logger(\"zetherion_ai.skills.weather\")\n\n# ------------------------------------------------------------------\n# Constants\n# ------------------------------------------------------------------\n\nWEATHER_COLLECTION = \"skill_weather\"\n\n# Intent constants -- define these to avoid typos and enable reuse\nINTENT_WEATHER_CURRENT = \"weather_current\"\nINTENT_WEATHER_FORECAST = \"weather_forecast\"\n\n\nclass WeatherSkill(Skill):\n    \"\"\"Skill for providing weather information.\n\n    Intents handled:\n    - weather_current: Get current weather conditions\n    - weather_forecast: Get a multi-day forecast\n\n    Heartbeat actions:\n    - severe_weather_alert: Warn about severe weather conditions\n    \"\"\"\n\n    INTENTS = [INTENT_WEATHER_CURRENT, INTENT_WEATHER_FORECAST]\n\n    def __init__(self, memory: \"QdrantMemory | None\" = None) -&gt; None:\n        \"\"\"Initialize the weather skill.\n\n        Args:\n            memory: Optional Qdrant memory for caching weather data.\n        \"\"\"\n        super().__init__(memory=memory)\n        # Internal cache: user_id -&gt; last known location\n        self._user_locations: dict[str, str] = {}\n\n    # ------------------------------------------------------------------\n    # Metadata\n    # ------------------------------------------------------------------\n\n    @property\n    def metadata(self) -&gt; SkillMetadata:\n        \"\"\"Return skill metadata.\"\"\"\n        return SkillMetadata(\n            name=\"weather\",\n            description=\"Provide current weather and forecasts for any location\",\n            version=\"1.0.0\",\n            author=\"Zetherion AI\",\n            permissions=PermissionSet(\n                {\n                    Permission.READ_OWN_COLLECTION,\n                    Permission.WRITE_OWN_COLLECTION,\n                    Permission.SEND_MESSAGES,\n                }\n            ),\n            collections=[WEATHER_COLLECTION],\n            intents=self.INTENTS,\n        )\n\n    # ------------------------------------------------------------------\n    # Initialization\n    # ------------------------------------------------------------------\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize the skill and create the Qdrant collection if needed.\n\n        Returns:\n            True if initialization succeeded.\n        \"\"\"\n        if not self._memory:\n            log.warning(\"weather_no_memory\", msg=\"No memory provided, using in-memory only\")\n            return True\n\n        try:\n            await self._memory.ensure_collection(\n                WEATHER_COLLECTION,\n                vector_size=768,  # Gemini embedding dimensions\n            )\n            log.info(\"weather_initialized\", collection=WEATHER_COLLECTION)\n            return True\n        except Exception as e:\n            log.error(\"weather_init_failed\", error=str(e))\n            return False\n\n    # ------------------------------------------------------------------\n    # Request handling\n    # ------------------------------------------------------------------\n\n    async def handle(self, request: SkillRequest) -&gt; SkillResponse:\n        \"\"\"Route the request to the appropriate handler.\n\n        Args:\n            request: The incoming skill request.\n\n        Returns:\n            Response from the matched handler.\n        \"\"\"\n        match request.intent:\n            case \"weather_current\":\n                return await self._handle_current(request)\n            case \"weather_forecast\":\n                return await self._handle_forecast(request)\n            case _:\n                return SkillResponse.error_response(\n                    request.id,\n                    f\"Unknown intent: {request.intent}\",\n                )\n\n    async def _handle_current(self, request: SkillRequest) -&gt; SkillResponse:\n        \"\"\"Handle a current weather request.\n\n        Args:\n            request: The incoming skill request.\n                Expected context keys:\n                    - location (str): City name or coordinates.\n\n        Returns:\n            Response with current weather data.\n        \"\"\"\n        location = request.context.get(\"location\", \"\")\n        if not location:\n            return SkillResponse.error_response(\n                request.id,\n                \"No location provided. Please specify a city or address.\",\n            )\n\n        # Remember the user's location for future requests\n        self._user_locations[request.user_id] = location\n\n        # In a real implementation, call a weather API here.\n        # For this example, return placeholder data.\n        weather_data = {\n            \"location\": location,\n            \"temperature_c\": 22,\n            \"condition\": \"Partly cloudy\",\n            \"humidity\": 65,\n            \"wind_kph\": 12,\n        }\n\n        log.info(\n            \"weather_current_fetched\",\n            user_id=request.user_id,\n            location=location,\n        )\n\n        return SkillResponse(\n            request_id=request.id,\n            message=f\"Current weather in {location}: 22C, partly cloudy, 65% humidity.\",\n            data={\"weather\": weather_data},\n        )\n\n    async def _handle_forecast(self, request: SkillRequest) -&gt; SkillResponse:\n        \"\"\"Handle a weather forecast request.\n\n        Args:\n            request: The incoming skill request.\n                Expected context keys:\n                    - location (str): City name or coordinates.\n                    - days (int): Number of forecast days (default 3).\n\n        Returns:\n            Response with forecast data.\n        \"\"\"\n        location = request.context.get(\"location\", \"\")\n        days = request.context.get(\"days\", 3)\n\n        if not location:\n            # Fall back to the user's last known location\n            location = self._user_locations.get(request.user_id, \"\")\n\n        if not location:\n            return SkillResponse.error_response(\n                request.id,\n                \"No location provided and no previous location on record.\",\n            )\n\n        # In a real implementation, call a weather API here.\n        forecast = [\n            {\"day\": i + 1, \"high_c\": 22 + i, \"low_c\": 14 + i, \"condition\": \"Sunny\"}\n            for i in range(days)\n        ]\n\n        log.info(\n            \"weather_forecast_fetched\",\n            user_id=request.user_id,\n            location=location,\n            days=days,\n        )\n\n        return SkillResponse(\n            request_id=request.id,\n            message=f\"{days}-day forecast for {location} retrieved.\",\n            data={\"forecast\": forecast, \"location\": location, \"days\": days},\n        )\n\n    # ------------------------------------------------------------------\n    # Heartbeat (optional)\n    # ------------------------------------------------------------------\n\n    async def on_heartbeat(self, user_ids: list[str]) -&gt; list[HeartbeatAction]:\n        \"\"\"Check for severe weather in users' locations.\n\n        Called periodically by the heartbeat scheduler. Returns actions\n        for any users in locations with severe weather.\n\n        Args:\n            user_ids: List of user IDs to check.\n\n        Returns:\n            List of heartbeat actions for severe weather alerts.\n        \"\"\"\n        actions: list[HeartbeatAction] = []\n\n        for user_id in user_ids:\n            location = self._user_locations.get(user_id)\n            if not location:\n                continue\n\n            # In a real implementation, check a weather API for alerts.\n            # This example shows the structure only.\n            has_severe_weather = False  # Replace with actual API check\n\n            if has_severe_weather:\n                actions.append(\n                    HeartbeatAction(\n                        skill_name=self.name,\n                        action_type=\"severe_weather_alert\",\n                        user_id=user_id,\n                        data={\n                            \"location\": location,\n                            \"alert_type\": \"thunderstorm\",\n                            \"message\": f\"Severe thunderstorm warning for {location}.\",\n                        },\n                        priority=9,\n                    )\n                )\n\n        return actions\n\n    # ------------------------------------------------------------------\n    # System prompt fragment (optional)\n    # ------------------------------------------------------------------\n\n    def get_system_prompt_fragment(self, user_id: str) -&gt; str | None:\n        \"\"\"Inject the user's known location into the agent prompt.\n\n        Args:\n            user_id: The user ID for personalization.\n\n        Returns:\n            A sentence about the user's location, or None.\n        \"\"\"\n        location = self._user_locations.get(user_id)\n        if location:\n            return f\"The user's last known location is {location}.\"\n        return None\n\n    # ------------------------------------------------------------------\n    # Cleanup\n    # ------------------------------------------------------------------\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"Release resources when the skill is shut down.\"\"\"\n        self._user_locations.clear()\n        log.info(\"weather_cleanup_complete\")\n</code></pre>"},{"location":"development/adding-a-skill/#step-4-register-the-skill","title":"Step 4: Register the Skill","text":"<p>Skills are registered in the <code>main()</code> function of <code>src/zetherion_ai/skills/server.py</code>. This is the entry point for the <code>zetherion-ai-skills</code> Docker service.</p> <p>Add your skill's import and registration call:</p> <pre><code># In src/zetherion_ai/skills/server.py, inside the main() function:\n\nfrom zetherion_ai.skills.calendar import CalendarSkill\nfrom zetherion_ai.skills.profile_skill import ProfileSkill\nfrom zetherion_ai.skills.task_manager import TaskManagerSkill\nfrom zetherion_ai.skills.weather import WeatherSkill  # &lt;-- Add import\n\nregistry.register(TaskManagerSkill())\nregistry.register(CalendarSkill())\nregistry.register(ProfileSkill())\nregistry.register(WeatherSkill())  # &lt;-- Add registration\n</code></pre> <p>The <code>SkillRegistry</code> will:</p> <ol> <li>Validate that the skill's permissions do not exceed the maximum allowed set</li> <li>Map each of the skill's declared intents to the skill name</li> <li>Call <code>safe_initialize()</code> during the startup sequence</li> </ol>"},{"location":"development/adding-a-skill/#step-5-add-heartbeat-support-optional","title":"Step 5: Add Heartbeat Support (Optional)","text":"<p>If your skill needs to perform proactive actions (reminders, alerts, periodic checks), override <code>on_heartbeat()</code>. The heartbeat scheduler calls this method periodically for all registered skills that have the <code>SEND_MESSAGES</code> permission.</p> <p>The example in Step 3 already demonstrates this pattern. Key points:</p> <ul> <li>Return an empty list if there is nothing to do</li> <li>Set <code>priority</code> appropriately: 9 for critical alerts, 3 for low-priority background checks</li> <li>The <code>action_type</code> string is freeform but should be descriptive (e.g., <code>\"severe_weather_alert\"</code>, <code>\"deadline_reminder\"</code>, <code>\"stale_task_check\"</code>)</li> <li>The <code>data</code> dictionary carries whatever payload the notification dispatcher needs</li> </ul> <p>The heartbeat scheduler collects actions from all skills, sorts them by priority (highest first), and dispatches them through the notification system.</p>"},{"location":"development/adding-a-skill/#step-6-write-tests","title":"Step 6: Write Tests","text":"<p>Create the test file at <code>tests/unit/test_weather_skill.py</code>. Follow the project's existing test patterns: class-based grouping, <code>pytest.mark.asyncio</code> for async tests, and the Arrange-Act-Assert structure.</p> <pre><code>\"\"\"Tests for the Weather Skill.\"\"\"\n\nfrom uuid import uuid4\n\nimport pytest\n\nfrom zetherion_ai.skills.base import SkillRequest, SkillResponse, SkillStatus\nfrom zetherion_ai.skills.permissions import Permission\nfrom zetherion_ai.skills.weather import WeatherSkill\n\n\nclass TestWeatherSkillMetadata:\n    \"\"\"Tests for WeatherSkill metadata.\"\"\"\n\n    def test_metadata_name(self) -&gt; None:\n        \"\"\"Skill name should be 'weather'.\"\"\"\n        skill = WeatherSkill()\n        assert skill.metadata.name == \"weather\"\n\n    def test_metadata_version(self) -&gt; None:\n        \"\"\"Skill version should be '1.0.0'.\"\"\"\n        skill = WeatherSkill()\n        assert skill.metadata.version == \"1.0.0\"\n\n    def test_metadata_intents(self) -&gt; None:\n        \"\"\"Skill should declare two intents.\"\"\"\n        skill = WeatherSkill()\n        assert \"weather_current\" in skill.metadata.intents\n        assert \"weather_forecast\" in skill.metadata.intents\n        assert len(skill.metadata.intents) == 2\n\n    def test_metadata_permissions(self) -&gt; None:\n        \"\"\"Skill should request expected permissions.\"\"\"\n        skill = WeatherSkill()\n        perms = skill.metadata.permissions\n        assert Permission.READ_OWN_COLLECTION in perms\n        assert Permission.WRITE_OWN_COLLECTION in perms\n        assert Permission.SEND_MESSAGES in perms\n\n    def test_metadata_collections(self) -&gt; None:\n        \"\"\"Skill should declare its Qdrant collection.\"\"\"\n        skill = WeatherSkill()\n        assert \"skill_weather\" in skill.metadata.collections\n\n\nclass TestWeatherSkillInitialization:\n    \"\"\"Tests for WeatherSkill initialization.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_initialize_without_memory(self) -&gt; None:\n        \"\"\"Skill should initialize successfully without Qdrant memory.\"\"\"\n        skill = WeatherSkill()\n        result = await skill.initialize()\n        assert result is True\n\n    @pytest.mark.asyncio\n    async def test_safe_initialize_sets_ready(self) -&gt; None:\n        \"\"\"safe_initialize should set status to READY on success.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n        assert skill.status == SkillStatus.READY\n\n\nclass TestWeatherCurrent:\n    \"\"\"Tests for the weather_current intent handler.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_current_weather_success(self) -&gt; None:\n        \"\"\"Should return weather data for a valid location.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n\n        request = SkillRequest(\n            user_id=\"user123\",\n            intent=\"weather_current\",\n            message=\"What is the weather in London?\",\n            context={\"location\": \"London\"},\n        )\n\n        response = await skill.safe_handle(request)\n\n        assert response.success is True\n        assert \"London\" in response.message\n        assert \"weather\" in response.data\n        assert response.data[\"weather\"][\"location\"] == \"London\"\n\n    @pytest.mark.asyncio\n    async def test_current_weather_no_location(self) -&gt; None:\n        \"\"\"Should return an error when no location is provided.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n\n        request = SkillRequest(\n            user_id=\"user123\",\n            intent=\"weather_current\",\n            message=\"What is the weather?\",\n            context={},\n        )\n\n        response = await skill.safe_handle(request)\n\n        assert response.success is False\n        assert \"No location\" in (response.error or \"\")\n\n    @pytest.mark.asyncio\n    async def test_current_weather_remembers_location(self) -&gt; None:\n        \"\"\"Should remember the user's location for future requests.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n\n        request = SkillRequest(\n            user_id=\"user123\",\n            intent=\"weather_current\",\n            message=\"Weather in Tokyo\",\n            context={\"location\": \"Tokyo\"},\n        )\n\n        await skill.safe_handle(request)\n\n        # The skill should now know this user's location\n        assert skill._user_locations[\"user123\"] == \"Tokyo\"\n\n\nclass TestWeatherForecast:\n    \"\"\"Tests for the weather_forecast intent handler.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_forecast_success(self) -&gt; None:\n        \"\"\"Should return forecast data for a valid location.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n\n        request = SkillRequest(\n            user_id=\"user123\",\n            intent=\"weather_forecast\",\n            message=\"5-day forecast for Paris\",\n            context={\"location\": \"Paris\", \"days\": 5},\n        )\n\n        response = await skill.safe_handle(request)\n\n        assert response.success is True\n        assert len(response.data[\"forecast\"]) == 5\n        assert response.data[\"location\"] == \"Paris\"\n\n    @pytest.mark.asyncio\n    async def test_forecast_uses_remembered_location(self) -&gt; None:\n        \"\"\"Should fall back to the user's last known location.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n\n        # Set a known location\n        skill._user_locations[\"user123\"] = \"Berlin\"\n\n        request = SkillRequest(\n            user_id=\"user123\",\n            intent=\"weather_forecast\",\n            message=\"Give me the forecast\",\n            context={},\n        )\n\n        response = await skill.safe_handle(request)\n\n        assert response.success is True\n        assert response.data[\"location\"] == \"Berlin\"\n\n    @pytest.mark.asyncio\n    async def test_forecast_no_location_at_all(self) -&gt; None:\n        \"\"\"Should return an error when no location is available.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n\n        request = SkillRequest(\n            user_id=\"user999\",\n            intent=\"weather_forecast\",\n            message=\"Give me the forecast\",\n            context={},\n        )\n\n        response = await skill.safe_handle(request)\n\n        assert response.success is False\n        assert \"No location\" in (response.error or \"\")\n\n\nclass TestWeatherUnknownIntent:\n    \"\"\"Tests for unknown intent handling.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_unknown_intent(self) -&gt; None:\n        \"\"\"Should return an error for an unrecognized intent.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n\n        request = SkillRequest(\n            user_id=\"user123\",\n            intent=\"weather_historical\",\n            message=\"What was the weather last week?\",\n            context={},\n        )\n\n        response = await skill.safe_handle(request)\n\n        assert response.success is False\n        assert \"Unknown intent\" in (response.error or \"\")\n\n\nclass TestWeatherHeartbeat:\n    \"\"\"Tests for heartbeat behavior.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_heartbeat_no_users(self) -&gt; None:\n        \"\"\"Should return empty list when no users have locations.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n\n        actions = await skill.on_heartbeat([\"user123\"])\n        assert actions == []\n\n    @pytest.mark.asyncio\n    async def test_heartbeat_with_known_location(self) -&gt; None:\n        \"\"\"Should check weather for users with known locations.\"\"\"\n        skill = WeatherSkill()\n        await skill.safe_initialize()\n        skill._user_locations[\"user123\"] = \"London\"\n\n        # In the stub implementation, no severe weather is reported,\n        # so the result is still empty. In a real test, you would\n        # mock the weather API to return a severe weather response.\n        actions = await skill.on_heartbeat([\"user123\"])\n        assert isinstance(actions, list)\n\n\nclass TestWeatherSystemPrompt:\n    \"\"\"Tests for system prompt fragment generation.\"\"\"\n\n    def test_prompt_fragment_with_location(self) -&gt; None:\n        \"\"\"Should return location info when known.\"\"\"\n        skill = WeatherSkill()\n        skill._user_locations[\"user123\"] = \"Sydney\"\n\n        fragment = skill.get_system_prompt_fragment(\"user123\")\n        assert fragment is not None\n        assert \"Sydney\" in fragment\n\n    def test_prompt_fragment_without_location(self) -&gt; None:\n        \"\"\"Should return None when location is unknown.\"\"\"\n        skill = WeatherSkill()\n\n        fragment = skill.get_system_prompt_fragment(\"user999\")\n        assert fragment is None\n\n\nclass TestWeatherCleanup:\n    \"\"\"Tests for skill cleanup.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_cleanup_clears_locations(self) -&gt; None:\n        \"\"\"Cleanup should clear the location cache.\"\"\"\n        skill = WeatherSkill()\n        skill._user_locations[\"user123\"] = \"London\"\n\n        await skill.cleanup()\n\n        assert len(skill._user_locations) == 0\n</code></pre> <p>Run the tests:</p> <pre><code>pytest tests/unit/test_weather_skill.py -v\n</code></pre>"},{"location":"development/adding-a-skill/#step-7-update-router-prompts","title":"Step 7: Update Router Prompts","text":"<p>For the router to classify user messages as your skill's intents, you need to add examples to the router's classification prompts.</p> <p>The router prompt is built in <code>src/zetherion_ai/agent/prompts.py</code>. Add your intents to the intent classification examples:</p> <pre><code># In the router classification prompt, add examples like:\n\n# Weather intents\n# \"What's the weather in London?\" -&gt; weather_current\n# \"Give me a 5-day forecast for Tokyo\" -&gt; weather_forecast\n# \"Will it rain tomorrow in Berlin?\" -&gt; weather_forecast\n# \"Current temperature in New York\" -&gt; weather_current\n</code></pre> <p>The exact location and format depends on how the router prompt is structured. The key requirement is that the router model (<code>gemini-2.5-flash</code> or <code>llama3.2:3b</code>) sees enough examples to reliably classify weather-related messages to your intents.</p>"},{"location":"development/adding-a-skill/#checklist","title":"Checklist","text":"<p>Before opening a pull request for a new skill, verify that all of the following are complete:</p> <ul> <li>[ ] Skill class extends <code>Skill</code> and implements all three required methods (<code>metadata</code>, <code>initialize</code>, <code>handle</code>)</li> <li>[ ] Intents follow the <code>verb_noun</code> naming convention</li> <li>[ ] Permissions are the minimum required set</li> <li>[ ] Qdrant collection name uses the <code>skill_</code> prefix</li> <li>[ ] Skill is registered in <code>src/zetherion_ai/skills/server.py</code></li> <li>[ ] Router prompts updated with intent classification examples</li> <li>[ ] <code>__init__.py</code> created with proper exports</li> <li>[ ] Tests cover all intents (success and error cases)</li> <li>[ ] Tests cover initialization (with and without memory)</li> <li>[ ] Tests cover heartbeat behavior (if implemented)</li> <li>[ ] Tests cover system prompt fragments (if implemented)</li> <li>[ ] Tests cover cleanup</li> <li>[ ] All tests pass: <code>pytest tests/ -m \"not discord_e2e\"</code></li> <li>[ ] Type checking passes: <code>mypy src/zetherion_ai</code></li> <li>[ ] Pre-commit hooks pass: <code>pre-commit run --all-files</code></li> <li>[ ] Conventional commit message used (e.g., <code>feat: add weather skill</code>)</li> </ul>"},{"location":"development/adding-a-skill/#further-reading","title":"Further Reading","text":"<ul> <li><code>../technical/skills-framework.md</code> -- Skills framework architecture and internals</li> <li><code>../technical/architecture.md</code> -- Overall system architecture</li> <li>Testing -- Testing patterns and strategies</li> <li><code>setup.md</code> -- Development environment setup and contributing guidelines</li> </ul>"},{"location":"development/changelog/","title":"Changelog","text":"<p>All notable changes to Zetherion AI will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"development/changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"development/changelog/#added-phase-9-2026-02-08","title":"Added - Phase 9 (2026-02-08)","text":""},{"location":"development/changelog/#phase-9-personal-understanding-system","title":"Phase 9: Personal Understanding System","text":"<ul> <li>PostgreSQL-backed personal model with 4 data models: <code>PersonalProfile</code>, <code>PersonalContact</code>, <code>PersonalPolicy</code>, <code>PersonalLearning</code></li> <li>asyncpg-based <code>PersonalStorage</code> with full CRUD operations for all models</li> <li>Communication style dimensions (formality, verbosity, directness, proactivity on 0-1 scale)</li> <li>Contact graph with relationship tracking and metadata</li> <li>Policy system with 5 domains and 4 modes (<code>AUTO</code>, <code>DRAFT</code>, <code>ASK</code>, <code>NEVER</code>)</li> <li>Integration with Gmail for contact-aware responses</li> <li>See <code>../technical/personal-understanding.md</code> for data model details</li> </ul>"},{"location":"development/changelog/#added-phase-8-2026-02-07","title":"Added - Phase 8 (2026-02-07)","text":""},{"location":"development/changelog/#phase-8-gmail-integration","title":"Phase 8: Gmail Integration","text":"<ul> <li>12-file Gmail module with complete email management capabilities</li> <li>Two-dimensional trust system (per-contact + per-type)</li> <li>Trust formula: <code>effective_trust = min(type_trust, contact_trust, reply_type_ceiling)</code></li> <li>Progressive autonomy: read-only -&gt; draft with approval -&gt; auto-draft -&gt; auto-send</li> <li>Auto-send threshold: <code>effective_trust &gt;= 0.85 AND confidence &gt;= 0.85</code></li> <li>Reply type ceilings across 8 types from <code>ACKNOWLEDGMENT</code> (0.95) to <code>SENSITIVE</code> (0.30)</li> <li>Trust evolution deltas: +0.05 approval, -0.20 rejection, <code>GLOBAL_CAP</code> 0.95</li> <li>OAuth account management with encrypted token storage (AES-256-GCM)</li> <li>Unified inbox aggregation across multiple accounts</li> <li>Reply draft pipeline (7-step process from classification to send/queue)</li> <li>Digest generation (morning, evening, weekly summaries)</li> <li>Email analytics with relationship scoring</li> <li>See <code>../technical/gmail-architecture.md</code> for full design</li> </ul>"},{"location":"development/changelog/#phase-8a-observation-pipeline","title":"Phase 8A: Observation Pipeline","text":"<ul> <li>Tiered extraction: Tier 1 (regex patterns), Tier 2 (LLM-based)</li> <li>6 learning categories for implicit knowledge extraction</li> <li>5 learning sources with confidence scoring</li> <li>Background profile extraction after responses</li> <li>PostgreSQL storage for personal learnings</li> <li>See <code>../technical/observation-pipeline.md</code> for pipeline details</li> </ul>"},{"location":"development/changelog/#added-phase-7-2026-02-07","title":"Added - Phase 7 (2026-02-07)","text":""},{"location":"development/changelog/#phase-7-github-integration","title":"Phase 7: GitHub Integration","text":"<ul> <li>GitHub skill with 18 intents for full repository management</li> <li>Issue management: list, view, create, close, reopen, label, comment</li> <li>PR management: list, view, diff, merge</li> <li>Workflow and repo info queries</li> <li>3 autonomy levels: <code>Autonomous</code>, <code>Ask</code>, <code>Always Ask</code></li> <li>Per-action autonomy defaults with safety-first design</li> <li>GitHub token management via environment variables</li> <li>See <code>../user/github-integration.md</code> for usage guide</li> </ul>"},{"location":"development/changelog/#added-phase-6-2026-02-07","title":"Added - Phase 6 (2026-02-07)","text":""},{"location":"development/changelog/#phase-6-docker-hardening","title":"Phase 6: Docker Hardening","text":"<ul> <li>Distroless base images for bot and skills containers (~50MB runtime)</li> <li>Read-only root filesystem with tmpfs for <code>/tmp</code></li> <li><code>no-new-privileges</code> security option on ALL containers</li> <li>Resource limits (CPU and memory) for all 6 services</li> <li>Dual Ollama architecture (separate router + generation containers)</li> <li>PostgreSQL 17 Alpine service for personal understanding data</li> <li>Health checks on all 6 services with Python-based probes</li> <li>Network isolation between services</li> <li>See <code>../technical/docker.md</code> for architecture details</li> </ul>"},{"location":"development/changelog/#added-phase-5-2026-02-06","title":"Added - Phase 5 (2026-02-06)","text":""},{"location":"development/changelog/#phase-5a-encryption-layer","title":"Phase 5A: Encryption Layer","text":"<ul> <li>AES-256-GCM field-level encryption for sensitive Qdrant payloads</li> <li>PBKDF2-HMAC-SHA256 key derivation with 600,000 iterations and 32-byte salt</li> <li>TLS support for Qdrant connections (optional)</li> <li><code>FieldEncryptor</code> and <code>KeyManager</code> classes in <code>zetherion_ai.security</code></li> </ul>"},{"location":"development/changelog/#phase-5b-inferencebroker","title":"Phase 5B: InferenceBroker","text":"<ul> <li>Smart multi-provider LLM routing based on task type</li> <li>Provider capability matrix: Claude (code), OpenAI (reasoning), Gemini (long docs), Ollama (lightweight)</li> <li>16 TaskTypes for granular routing decisions</li> <li>Automatic fallback chains when primary provider unavailable</li> <li>See <code>../technical/architecture.md</code> for routing design</li> </ul>"},{"location":"development/changelog/#phase-5b1-model-registry-and-cost-tracking","title":"Phase 5B.1: Model Registry and Cost Tracking","text":"<ul> <li>Dynamic model discovery via provider APIs</li> <li>Tier-based model selection (quality, balanced, fast)</li> <li>SQLite cost tracking with per-request logging</li> <li>Daily and monthly cost aggregation and reporting</li> <li>Discord notifications for budget alerts</li> <li>See <code>../technical/cost-tracking.md</code> for budget management details</li> </ul>"},{"location":"development/changelog/#phase-5c-user-profile-system","title":"Phase 5C: User Profile System","text":"<ul> <li>8 profile categories: identity, preferences, schedule, projects, relationships, skills, goals, habits</li> <li>Tiered inference: Tier 1 (regex), Tier 2 (Ollama), Tier 3 (embeddings), Tier 4 (cloud)</li> <li>5 signal engines for implicit extraction</li> <li>TTL-based caching with confidence scoring</li> <li>Background profile extraction after responses</li> </ul>"},{"location":"development/changelog/#phase-5c1-employment-profile","title":"Phase 5C.1: Employment Profile","text":"<ul> <li>Bot identity and relationship modeling</li> <li>Trust levels: <code>MINIMAL</code> -&gt; <code>BUILDING</code> -&gt; <code>ESTABLISHED</code> -&gt; <code>HIGH</code> -&gt; <code>FULL</code></li> <li>10 relationship milestones tracking</li> <li>Communication style adaptation (formality, verbosity, proactivity)</li> </ul>"},{"location":"development/changelog/#phase-5d-skills-framework","title":"Phase 5D: Skills Framework","text":"<ul> <li>Abstract Skill interface with permission-based access control</li> <li>15 granular permissions (read/write profile, memories, messages, etc.)</li> <li><code>SkillRegistry</code> for intent routing and heartbeat coordination</li> <li>Separate Docker container for skills service isolation</li> <li>REST API with authentication on port 8080 for bot-skills communication</li> <li>See <code>../technical/skills-framework.md</code> for the framework design</li> </ul>"},{"location":"development/changelog/#phase-5e-built-in-skills","title":"Phase 5E: Built-in Skills","text":"<ul> <li>Task Manager: CRUD operations, priority levels, deadlines, heartbeat reminders</li> <li>Calendar Awareness: Event types, recurrence patterns, availability checking</li> <li>Profile Manager: GDPR-style view/update/delete/export, confidence reports</li> </ul>"},{"location":"development/changelog/#phase-5f-heartbeat-scheduler","title":"Phase 5F: Heartbeat Scheduler","text":"<ul> <li>Configurable interval (default 5 min) with quiet hours support</li> <li>Rate limiting (3 messages/hour per user)</li> <li><code>ActionExecutor</code> with handlers for all skill action types</li> <li>Scheduled event handling for one-time triggers</li> </ul>"},{"location":"development/changelog/#phase-5g-router-enhancement","title":"Phase 5G: Router Enhancement","text":"<ul> <li>3 new skill intents: <code>TASK_MANAGEMENT</code>, <code>CALENDAR_QUERY</code>, <code>PROFILE_QUERY</code></li> <li>Skill intent examples in router prompts</li> <li>Agent integration for skill intent handling</li> </ul>"},{"location":"development/changelog/#changed","title":"Changed","text":"<ul> <li>Test suite: Expanded to 3,000+ tests (93%+ coverage) across 89 test files covering 91 source files</li> <li>Docker services: Expanded to 6 services (bot, skills, qdrant, postgres, ollama, ollama-router)</li> <li>Ollama models: Updated from Qwen to Meta Llama (llama3.2:3b for router, llama3.1:8b for generation)</li> <li>Default cloud models: claude-sonnet-4-5-20250929, gpt-5.2, gemini-2.5-flash</li> <li>Project renamed from <code>secureclaw</code> to <code>zetherion-ai</code>; all imports updated to <code>zetherion_ai</code></li> <li>Docker container names now use hyphens (<code>zetherion-ai-*</code>)</li> <li>Integration tests updated for Phase 5-9 features</li> </ul>"},{"location":"development/changelog/#fixed","title":"Fixed","text":"<ul> <li>All test failures resolved across all phases</li> <li>Config tests with environment variable isolation using monkeypatch</li> <li>Docker integration tests with proper service startup</li> <li>Type checking errors in async Qdrant client</li> <li>GitHub push protection issues with example tokens in documentation</li> <li>Chainguard ENTRYPOINT compatibility for CMD and healthchecks</li> <li><code>load_dotenv</code> moved to fixture scope to prevent env pollution in test suite</li> <li>asyncpg mypy import issues resolved</li> <li>Security hardening and cleanup for skills server and Qdrant connections</li> </ul>"},{"location":"development/changelog/#100-initial-release","title":"[1.0.0] - Initial Release","text":""},{"location":"development/changelog/#added","title":"Added","text":"<ul> <li>Discord bot with dual LLM backends (Gemini + Ollama)</li> <li>Message routing with intent classification</li> <li>Claude / OpenAI integration for complex tasks (claude-sonnet-4-5-20250929, gpt-5.2)</li> <li>Gemini / Ollama integration for simple queries (gemini-2.5-flash, llama3.2:3b)</li> <li>Qdrant vector database for long-term memory</li> <li>Google Gemini embeddings for semantic search</li> <li>Docker containerization with Compose orchestration</li> <li>Basic security controls (rate limiting, user allowlist)</li> <li>Comprehensive error handling and retry logic</li> </ul>"},{"location":"development/changelog/#security","title":"Security","text":"<ul> <li>Pydantic <code>SecretStr</code> for all credentials</li> <li>Gitleaks secret scanning in pre-commit hooks</li> <li>Bandit security scanning in CI/CD</li> <li>CodeQL weekly analysis</li> <li>Pinned dependencies with Dependabot</li> <li>Prompt injection detection (17 regex patterns)</li> <li>User allowlist for Discord interactions</li> </ul>"},{"location":"development/changelog/#version-history-details","title":"Version History Details","text":""},{"location":"development/changelog/#phase-1-test-fixes-coverage-42-78","title":"Phase 1: Test Fixes (Coverage: ~42% -&gt; 78%)","text":"<p>Phase 1A: Agent Core Tests -- Fixed 13 test failures</p> <ul> <li>Resolved Docker service dependency issues</li> <li>Fixed async Qdrant client usage</li> <li>Improved retry logic testing</li> <li>Result: 41 tests passing, 94.76% module coverage</li> </ul> <p>Phase 1B: Security Tests -- Fixed 3 test failures</p> <ul> <li>Fixed prompt injection detection tests</li> <li>Corrected allowlist and rate limiter tests</li> <li>Result: 37 tests passing, 94.12% module coverage</li> </ul> <p>Phase 1C: Config Tests -- Fixed 10 test failures</p> <ul> <li>Implemented environment variable isolation with monkeypatch</li> <li>Fixed <code>allowed_user_ids</code> parsing tests</li> <li>Resolved Docker integration test errors (14 tests)</li> <li>Result: All config tests passing, 96.88% module coverage</li> </ul>"},{"location":"development/changelog/#phase-2-coverage-improvements-coverage-78-8758","title":"Phase 2: Coverage Improvements (Coverage: 78% -&gt; 87.58%)","text":"<p>Phase 2A: Router Factory Tests -- 26% -&gt; 100% coverage</p> <ul> <li>Added 12 comprehensive tests for factory functions</li> <li>Tested async/sync router creation, health checks, and fallback logic</li> </ul> <p>Phase 2B: Discord Bot Edge Cases -- 68.55% -&gt; 89.92% coverage</p> <ul> <li>Added 11 edge case tests for uncovered code paths</li> <li><code>/channels</code> command tests (6 tests): unauthorized user handling, DM vs guild context, channel listing, long response splitting</li> <li>Agent readiness tests (1 test)</li> <li><code>_send_long_message</code> helper tests (4 tests)</li> </ul>"},{"location":"development/changelog/#phase-3-4-refactoring-and-ci-hardening","title":"Phase 3-4: Refactoring and CI Hardening","text":"<ul> <li>Project renamed from SecureClaw to Zetherion AI</li> <li>Pre-commit hooks consolidated (Ruff, Mypy, Bandit, Gitleaks, Hadolint)</li> <li>CI/CD pipeline with 6 parallel jobs</li> <li>Windows deployment scripts (PowerShell)</li> <li>MkDocs documentation site with wiki sync</li> </ul>"},{"location":"development/changelog/#phase-5-skills-and-routing-coverage-8758-93","title":"Phase 5: Skills and Routing (Coverage: 87.58% -&gt; 93%+)","text":"<ul> <li>Complete InferenceBroker with multi-provider routing</li> <li>Encryption layer with AES-256-GCM</li> <li>User profile system with tiered inference</li> <li>Skills framework with 3 built-in skills</li> <li>Heartbeat scheduler with quiet hours</li> <li>Router enhancement with skill intents</li> </ul>"},{"location":"development/changelog/#phase-6-docker-hardening_1","title":"Phase 6: Docker Hardening","text":"<ul> <li>Distroless images, read-only filesystems, resource limits</li> <li>Dual Ollama architecture for router and generation separation</li> <li>PostgreSQL 17 Alpine for persistent data</li> <li>Health checks and network isolation across all 6 services</li> </ul>"},{"location":"development/changelog/#phase-7-github-integration_1","title":"Phase 7: GitHub Integration","text":"<ul> <li>18 intents for full repository management</li> <li>3 autonomy levels with safety-first defaults</li> </ul>"},{"location":"development/changelog/#phase-8-gmail-integration_1","title":"Phase 8: Gmail Integration","text":"<ul> <li>12-file module with trust-based progressive autonomy</li> <li>OAuth management, inbox aggregation, reply drafting, digest generation</li> <li>Observation pipeline for implicit knowledge extraction</li> </ul>"},{"location":"development/changelog/#phase-9-personal-understanding","title":"Phase 9: Personal Understanding","text":"<ul> <li>PostgreSQL-backed personal model (4 data models)</li> <li>Communication style dimensions, contact graphs, policy system</li> </ul>"},{"location":"development/changelog/#current-test-statistics","title":"Current Test Statistics","text":"Category Count Status Test Files 89 All passing Source Files 91 Covered Total Tests 3,000+ All passing Overall Coverage 93%+ Target exceeded"},{"location":"development/changelog/#docker-services","title":"Docker Services","text":"Service Image Purpose bot Distroless Discord bot and agent core skills Distroless Skills REST API on port 8080 qdrant qdrant/qdrant Vector memory storage postgres PostgreSQL 17 Alpine Personal understanding data ollama ollama/ollama Generation model (llama3.1:8b) ollama-router ollama/ollama Router model (llama3.2:3b)"},{"location":"development/changelog/#cicd-pipeline","title":"CI/CD Pipeline","text":""},{"location":"development/changelog/#pipeline-stages","title":"Pipeline Stages","text":"<ol> <li>Lint -- Ruff linting and formatting</li> <li>Type Check -- Mypy strict mode type checking</li> <li>Security -- Bandit security scanning</li> <li>Tests -- Unit tests on Python 3.12 and 3.13</li> <li>Docker Build -- Container build verification</li> <li>Integration -- Full integration tests with Docker services</li> </ol>"},{"location":"development/changelog/#pre-commit-hooks","title":"Pre-Commit Hooks","text":"<ul> <li>Ruff (linting and formatting)</li> <li>Mypy (type checking)</li> <li>Gitleaks (secret scanning)</li> <li>Bandit (security scanning)</li> <li>Hadolint (Dockerfile linting)</li> <li>File checks (trailing whitespace, EOF, merge conflicts)</li> </ul>"},{"location":"development/changelog/#breaking-changes","title":"Breaking Changes","text":"<p>None yet. This project has not yet published a stable public API.</p>"},{"location":"development/changelog/#migration-guide","title":"Migration Guide","text":""},{"location":"development/changelog/#from-development-to-production","title":"From Development to Production","text":"<ol> <li>Update <code>.env</code> file:</li> <li>Set <code>ENVIRONMENT=production</code></li> <li>Set <code>LOG_LEVEL=INFO</code></li> <li> <p>Configure <code>ALLOWED_USER_IDS</code> for production users</p> </li> <li> <p>Review Security Settings:</p> </li> <li>Ensure all API keys are properly set</li> <li>Verify user allowlist is configured</li> <li> <p>Check rate limiting settings</p> </li> <li> <p>Deploy with Docker Compose:    <pre><code>docker compose up -d\n</code></pre></p> </li> <li> <p>Monitor Logs:    <pre><code>tail -f logs/zetherion_ai.log | jq .\n</code></pre></p> </li> </ol> <p>See <code>../technical/configuration.md</code> for full configuration reference.</p>"},{"location":"development/changelog/#known-issues","title":"Known Issues","text":"<p>None currently reported. See GitHub Issues for the latest.</p>"},{"location":"development/changelog/#contributors","title":"Contributors","text":"<ul> <li>James Hinton (@jimtin) -- Project creator and maintainer</li> <li>Claude Sonnet 4.5 / Claude Opus 4.6 -- AI pair programming</li> </ul> <p>See Setup and Contributing for contribution guidelines.</p>"},{"location":"development/changelog/#license","title":"License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for details.</p>"},{"location":"development/changelog/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Anthropic for the Claude API</li> <li>Google for the Gemini API</li> <li>OpenAI for GPT models</li> <li>Discord.py community</li> <li>Qdrant team for the vector database</li> <li>Ollama team for the local LLM runtime</li> <li>Meta for the Llama model family</li> </ul>"},{"location":"development/ci-cd/","title":"CI/CD Pipeline","text":"<p>Complete guide to Zetherion AI's three-tier quality gate: pre-commit hooks, pre-push hooks, and GitHub Actions CI/CD.</p>"},{"location":"development/ci-cd/#overview","title":"Overview","text":"<p>Every code change passes through three automated quality tiers before reaching production.</p> <pre><code>+---------------------------------------------------------------+\n|  Tier 1: Pre-Commit Hooks (~10-15s)                           |\n|  Runs: on every git commit                                    |\n|  Checks: Ruff lint + format, file hygiene, Bandit,            |\n|          Gitleaks, Hadolint, Mypy                              |\n|  Effect: blocks commit if any check fails                     |\n+---------------------------------------------------------------+\n                             |\n                             v\n+---------------------------------------------------------------+\n|  Tier 2: Pre-Push Hooks (~30-60s)                             |\n|  Runs: on every git push                                      |\n|  Checks: Ruff lint, Mypy type check, full pytest suite        |\n|          with coverage (unit tests only)                       |\n|  Effect: blocks push if any check fails                       |\n+---------------------------------------------------------------+\n                             |\n                             v\n+---------------------------------------------------------------+\n|  Tier 3: GitHub Actions CI/CD (~5-10 min)                     |\n|  Runs: on push/PR to main or develop                          |\n|  Checks: lint, type-check, security (Bandit + Semgrep),       |\n|          dependency audit, license compliance, pre-commit,     |\n|          tests (Python 3.12 + 3.13 matrix), Docker build +    |\n|          Trivy scan, SBOM generation                           |\n|  Effect: blocks PR merge if any required check fails          |\n+---------------------------------------------------------------+\n</code></pre> <p>Design philosophy:</p> <ul> <li>Fast feedback locally -- pre-commit catches formatting and security issues in seconds.</li> <li>Confidence before push -- pre-push ensures the full test suite (3,000+ tests, 93%+ coverage) passes.</li> <li>Comprehensive CI -- GitHub Actions catches cross-version issues, container problems, and dependency vulnerabilities.</li> </ul>"},{"location":"development/ci-cd/#pre-commit-hooks","title":"Pre-Commit Hooks","text":"<p>Pre-commit hooks run automatically on every <code>git commit</code>. They are defined in <code>.pre-commit-config.yaml</code> and managed by the pre-commit framework.</p>"},{"location":"development/ci-cd/#what-runs-7-checks","title":"What Runs (7 Checks)","text":"# Hook Tool What It Does Auto-Fix 1 Ruff linter <code>ruff check --fix</code> Code style (PEP 8), unused imports, complexity, import sorting Yes 2 Ruff formatter <code>ruff format</code> Consistent code formatting (replaces Black + isort) Yes 3 File checks <code>pre-commit-hooks</code> Trailing whitespace, EOF newlines, large files (&gt;1MB), merge conflicts, case conflicts, YAML/TOML/JSON syntax, private key detection Yes (whitespace, EOF) 4 Bandit <code>bandit -c pyproject.toml</code> Common security issues (SQL injection, hardcoded passwords, eval usage). Excludes <code>tests/</code> and <code>scripts/</code> No 5 Gitleaks <code>gitleaks detect</code> API keys, tokens, passwords, private keys, high-entropy strings. Uses custom rules in <code>.gitleaks.toml</code> No 6 Hadolint <code>hadolint-docker</code> Dockerfile best practices. Ignores DL3007/DL3008/DL3009 (Chainguard-specific) No 7 Mypy <code>mypy --config-file=pyproject.toml</code> Static type checking against Python 3.12 with <code>strict = true</code>. Excludes <code>tests/</code> and <code>scripts/</code> No"},{"location":"development/ci-cd/#setup","title":"Setup","text":"<pre><code># One-time setup using the provided script\n./scripts/setup-git-hooks.sh\n\n# Manual setup if the script fails\npip install pre-commit\npre-commit install --hook-type pre-commit --hook-type pre-push\n</code></pre>"},{"location":"development/ci-cd/#running-manually","title":"Running Manually","text":"<pre><code># Run all hooks on all files\npre-commit run --all-files\n\n# Run on staged files only (same as what happens on commit)\npre-commit run\n\n# Run a specific hook\npre-commit run ruff --all-files\npre-commit run gitleaks --all-files\npre-commit run bandit --all-files\n\n# Update hooks to latest versions\npre-commit autoupdate\n</code></pre>"},{"location":"development/ci-cd/#bypass","title":"Bypass","text":"<pre><code># Skip all pre-commit hooks (not recommended)\ngit commit --no-verify -m \"Emergency fix\"\n\n# Skip a specific hook\nSKIP=ruff git commit -m \"Skip ruff only\"\nSKIP=mypy git commit -m \"Skip type checking\"\n</code></pre> <p>Bypassing hooks is discouraged. If you bypass locally, GitHub Actions CI will still enforce the same checks and block the PR.</p>"},{"location":"development/ci-cd/#pre-push-hooks","title":"Pre-Push Hooks","text":"<p>Pre-push hooks run automatically on every <code>git push</code>. The custom hook lives at <code>.git-hooks/pre-push</code> and is symlinked into <code>.git/hooks/</code> during setup.</p>"},{"location":"development/ci-cd/#what-runs-3-steps","title":"What Runs (3 Steps)","text":"Step Command What It Checks Duration 1 <code>ruff check src/ tests/</code> Linting across all source and test code ~2s 2 <code>mypy src/zetherion_ai --config-file=pyproject.toml</code> Static type checking (strict mode) ~10s 3 <code>pytest tests/ -m \"not integration\" -v --tb=short --cov=src/zetherion_ai --cov-report=term-missing</code> Full unit test suite with coverage report ~45s <p>Total duration: approximately 30-60 seconds.</p> <p>The hook automatically activates <code>.venv</code> if it exists and <code>$VIRTUAL_ENV</code> is not set.</p> <p>Optional integration test step: Set <code>RUN_INTEGRATION_TESTS=1</code> to also run integration tests before push. This adds 2-3 minutes.</p> <pre><code># Push with integration tests\nRUN_INTEGRATION_TESTS=1 git push origin main\n</code></pre>"},{"location":"development/ci-cd/#setup_1","title":"Setup","text":"<p>The pre-push hook is installed as a symlink:</p> <pre><code>ln -sf ../../.git-hooks/pre-push .git/hooks/pre-push\n</code></pre> <p>This is handled automatically by <code>./scripts/setup-git-hooks.sh</code>.</p>"},{"location":"development/ci-cd/#bypass_1","title":"Bypass","text":"<pre><code># Skip pre-push hook (not recommended)\ngit push --no-verify origin main\n</code></pre> <p>If you bypass the pre-push hook, GitHub Actions will still catch failures. However, this means slower feedback -- you will not discover test failures until CI runs 5-10 minutes later.</p>"},{"location":"development/ci-cd/#github-actions","title":"GitHub Actions","text":"<p>The CI/CD pipeline is defined in <code>.github/workflows/ci.yml</code>.</p>"},{"location":"development/ci-cd/#workflow-triggers","title":"Workflow Triggers","text":"Trigger Condition <code>push</code> To <code>main</code> or <code>develop</code> branches <code>pull_request</code> Targeting <code>main</code> or <code>develop</code> branches <code>workflow_dispatch</code> Manual trigger from GitHub UI or <code>gh workflow run ci.yml</code>"},{"location":"development/ci-cd/#jobs","title":"Jobs","text":"<p>The pipeline runs the following jobs. Jobs without dependency arrows run in parallel.</p> <pre><code>+------------------+    +-------------------+    +-------------------+\n|   lint (~5s)     |    | type-check (~10s) |    | security (~10s)   |\n|  Ruff lint +     |    | mypy strict mode  |    | Bandit scan on    |\n|  format check    |    | on src/           |    | src/              |\n+------------------+    +-------------------+    +-------------------+\n\n+------------------+    +-------------------+    +-------------------+\n| semgrep (~30s)   |    | dependency-audit  |    | license-check     |\n| SAST analysis    |    | pip-audit with    |    | pip-licenses       |\n| uploads SARIF    |    | --strict --desc   |    | allow-list check  |\n+------------------+    +-------------------+    +-------------------+\n\n+------------------+    +-------------------------------+\n| pre-commit (~30s)|    | test (~60s)                   |\n| All hooks via    |    | Python 3.12 + 3.13 matrix     |\n| pre-commit/action|    | pytest + coverage + Codecov   |\n+------------------+    +-------------------------------+\n\n+----------------------------------------------+\n| docker-build (~2 min)                        |\n| Build image, Trivy vulnerability scan,       |\n| SBOM generation, docker-compose config check |\n+----------------------------------------------+\n\n            +-------------------------------+\n            | summary (~5s)                 |\n            | Aggregates all job results    |\n            | Posts table to PR summary     |\n            | Fails if any job failed       |\n            +-------------------------------+\n</code></pre>"},{"location":"development/ci-cd/#job-details","title":"Job Details","text":"<p>lint -- Installs <code>ruff==0.8.4</code> and runs <code>ruff check</code> + <code>ruff format --check</code> against <code>src/</code> and <code>tests/</code>.</p> <p>type-check -- Installs full project dependencies, then runs <code>mypy src/zetherion_ai --config-file=pyproject.toml</code> in strict mode.</p> <p>security -- Runs <code>bandit -r src/ -c pyproject.toml</code> to detect common Python security issues.</p> <p>semgrep -- Runs Semgrep with <code>--config auto</code> for static application security testing. Uploads SARIF results to the GitHub Security tab.</p> <p>dependency-audit -- Runs <code>pip-audit -r requirements.txt --strict --desc on</code> to check all dependencies for known CVEs.</p> <p>license-check -- Runs <code>pip-licenses</code> to verify all dependency licenses are in the approved allow-list (MIT, BSD, Apache, ISC, PSF, MPL-2.0, Unlicense, CC0, Zlib).</p> <p>pre-commit -- Runs all pre-commit hooks via the <code>pre-commit/action@v3</code> GitHub Action.</p> <p>test -- Matrix build across Python 3.12 and 3.13. Runs <code>pytest tests/ -m \"not integration\"</code> with coverage. Uploads coverage XML to Codecov (Python 3.12 only). Uploads HTML coverage report as a build artifact (retained 30 days).</p> <p>docker-build -- Builds the Docker image using Buildx with GHA caching. Runs Trivy vulnerability scanner (CRITICAL + HIGH severity). Generates an SPDX SBOM via Anchore. Validates <code>docker-compose.yml</code> syntax. Uploads Trivy SARIF to GitHub Security tab and SBOM as a build artifact (retained 90 days).</p> <p>summary -- Waits for all other jobs. Checks every job result. Posts a markdown results table to the PR summary. Exits with failure if any required job failed.</p>"},{"location":"development/ci-cd/#integration-test-control","title":"Integration Test Control","text":"<p>Integration tests can be skipped by including <code>[skip integration]</code> in the commit message:</p> <pre><code>git commit -m \"docs: Update README [skip integration]\"\n</code></pre> <p>When to skip: - Documentation-only changes - Configuration updates that do not affect runtime behavior - README or comment-only edits</p> <p>When NOT to skip: - Any change under <code>src/</code> - Docker configuration changes - Dependency updates - New or modified test files</p>"},{"location":"development/ci-cd/#coverage-reporting","title":"Coverage Reporting","text":"<p>Coverage is reported through multiple channels:</p> Channel Details Terminal <code>--cov-report=term-missing</code> shows missing lines inline during the test run HTML <code>--cov-report=html</code> generates a browsable report. Uploaded as a GitHub Actions artifact XML <code>--cov-report=xml</code> generates <code>coverage.xml</code>. Uploaded to Codecov Codecov Badge in README shows current coverage percentage. PR comments show coverage delta"},{"location":"development/ci-cd/#secret-scanning","title":"Secret Scanning","text":"<p>Gitleaks runs as a pre-commit hook with custom rules defined in <code>.gitleaks.toml</code>.</p>"},{"location":"development/ci-cd/#what-it-detects","title":"What It Detects","text":"Secret Type Pattern Examples Discord tokens Bot token format <code>MTIzNDU2...</code> Google/Gemini API keys <code>AIza...</code> pattern <code>AIzaSy...</code> Anthropic API keys <code>sk-ant-api03-...</code> pattern Claude API keys OpenAI API keys <code>sk-...</code> pattern GPT API keys AWS access keys <code>AKIA...</code> pattern IAM credentials GitHub tokens <code>ghp_...</code> pattern Personal access tokens Private keys PEM format headers RSA, SSH, PGP, OpenSSH JWT tokens <code>eyJ...</code> pattern Encoded JWTs Slack tokens <code>xox[baprs]-...</code> pattern Bot and user tokens Passwords in URLs <code>proto://user:pass@host</code> Database connection strings High-entropy strings Entropy &gt; 4.5 Potential unclassified secrets"},{"location":"development/ci-cd/#what-is-excluded","title":"What Is Excluded","text":"<p>The <code>.gitleaks.toml</code> allowlist prevents false positives from:</p> <ul> <li><code>.env.example</code> (template file with placeholder values)</li> <li>Test files (<code>tests/**/*.py</code>) containing fake tokens</li> <li>Documentation files with example patterns</li> <li>Generated files (lock files, cache directories, coverage reports)</li> <li>GitHub workflow files with test placeholder secrets</li> <li>Source code calling <code>.get_secret_value()</code> (the method name, not actual secrets)</li> </ul>"},{"location":"development/ci-cd/#response-protocol-for-exposed-secrets","title":"Response Protocol for Exposed Secrets","text":"<p>If a secret is accidentally committed:</p> <ol> <li>Do not push. If the commit is local only, amend it to remove the secret.</li> <li>Rotate the secret immediately. Regenerate the token/key in the provider dashboard (Discord Developer Portal, Google Cloud Console, Anthropic Dashboard, OpenAI Dashboard).</li> <li>If already pushed, use BFG Repo-Cleaner to remove the secret from git history:</li> </ol> <pre><code>git clone --mirror git@github.com:user/repo.git\nbfg --replace-text passwords.txt repo.git\ncd repo.git\ngit reflog expire --expire=now --all\ngit gc --prune=now --aggressive\ngit push\n</code></pre> <ol> <li>Update <code>.env</code> with the new rotated secret.</li> <li>Update GitHub Actions secrets if the exposed key was used in CI.</li> </ol>"},{"location":"development/ci-cd/#configuration-files","title":"Configuration Files","text":"File Purpose <code>.pre-commit-config.yaml</code> Pre-commit hook definitions (7 hooks across 6 tool repositories) <code>.git-hooks/pre-push</code> Custom pre-push hook script (3-step: lint, type-check, test) <code>.github/workflows/ci.yml</code> GitHub Actions CI/CD workflow (9 jobs) <code>.gitleaks.toml</code> Gitleaks secret scanning rules and allowlists <code>pyproject.toml</code> Unified configuration for pytest, mypy, ruff, coverage, and bandit"},{"location":"development/ci-cd/#pyprojecttoml-relevant-sections","title":"pyproject.toml (Relevant Sections)","text":"<p>Pytest: - <code>asyncio_mode = \"auto\"</code> -- async tests run without explicit markers - <code>testpaths = [\"tests\"]</code> -- test discovery root - <code>pythonpath = [\"src\"]</code> -- import resolution - <code>--strict-markers</code> -- typos in marker names cause errors</p> <p>Mypy: - <code>python_version = \"3.12\"</code> -- target version - <code>strict = true</code> -- all strict checks enabled - <code>warn_unused_ignores = false</code> -- suppresses cross-environment false positives</p> <p>Ruff: - <code>target-version = \"py312\"</code> - <code>line-length = 100</code> - Select rules: E, F, I, N, W, UP, B, C4, SIM</p> <p>Coverage: - <code>source = [\"src/zetherion_ai\"]</code> - <code>branch = true</code> -- tracks branch paths - <code>omit</code> excludes tests, pycache, and site-packages</p> <p>Bandit: - Excludes <code>tests/</code> and <code>scripts/</code> - Skips B101 (assert_used) to avoid false positives</p>"},{"location":"development/ci-cd/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/ci-cd/#hook-installation-issues","title":"Hook Installation Issues","text":"<p>Problem: <code>pre-commit: command not found</code></p> <pre><code>pip install pre-commit\npre-commit install\n</code></pre> <p>Problem: Pre-push hook not running</p> <pre><code># Verify the symlink exists\nls -la .git/hooks/pre-push\n\n# Recreate if missing\nln -sf ../../.git-hooks/pre-push .git/hooks/pre-push\n\n# Or re-run setup\n./scripts/setup-git-hooks.sh\n</code></pre> <p>Problem: Hooks installed but not triggering</p> <pre><code># Verify hook types are installed\npre-commit install --hook-type pre-commit --hook-type pre-push\n\n# Test manually\npre-commit run --all-files\n</code></pre>"},{"location":"development/ci-cd/#test-failures-blocking-push","title":"Test Failures Blocking Push","text":"<p>Problem: Tests fail during pre-push and block the push.</p> <pre><code># Run tests manually to see full output\npytest tests/ -m \"not integration\" -v --tb=long\n\n# Run only the failing test with debug output\npytest tests/unit/test_agent_core.py::test_failing_case -s -vv\n\n# If tests pass individually but fail together, check for fixture pollution\npytest tests/ -m \"not integration\" -p no:randomly --tb=short\n</code></pre> <p>Problem: Coverage threshold not met</p> <pre><code># Check current coverage with missing lines\npytest tests/ -m \"not integration\" --cov=src/zetherion_ai --cov-report=term-missing\n\n# Generate HTML report for detailed analysis\npytest tests/ -m \"not integration\" --cov=src/zetherion_ai --cov-report=html\nopen htmlcov/index.html\n</code></pre>"},{"location":"development/ci-cd/#ci-failures","title":"CI Failures","text":"<p>Problem: Tests pass locally but fail on GitHub Actions.</p> <p>Common causes and solutions:</p> Cause Solution Python version difference Test locally with both 3.12 and 3.13 using <code>pyenv</code> Missing environment variable Set secrets in GitHub Settings &gt; Secrets and variables &gt; Actions Dependency version drift Run <code>pip install -r requirements.txt</code> to sync local deps Platform-specific behavior Check for OS-dependent code paths (macOS vs Linux) Stale cache Delete the GitHub Actions cache from the Actions tab <p>Problem: Docker build fails on GitHub Actions</p> <pre><code># Test the Docker build locally\ndocker build -t zetherion_ai:test .\n\n# Validate docker-compose.yml\ndocker compose config\n\n# Check for Dockerfile linting issues\nhadolint Dockerfile\n</code></pre> <p>Problem: Trivy reports CRITICAL vulnerabilities</p> <p>Trivy runs with <code>exit-code: 0</code> (non-blocking) by default. Results appear in the GitHub Security tab. To investigate locally:</p> <pre><code># Install Trivy\nbrew install trivy\n\n# Scan the local image\ndocker build -t zetherion_ai:test .\ntrivy image --severity CRITICAL,HIGH zetherion_ai:test\n</code></pre>"},{"location":"development/ci-cd/#semgrep-or-bandit-false-positives","title":"Semgrep or Bandit False Positives","text":"<p>Problem: Security scanner flags legitimate code.</p> <p>For Bandit, add a <code># nosec</code> comment with justification:</p> <pre><code>subprocess.run(cmd, shell=False)  # nosec B603 -- input is validated above\n</code></pre> <p>For Semgrep, add a <code># nosemgrep</code> comment:</p> <pre><code>eval(trusted_expression)  # nosemgrep: python.lang.security.audit.eval\n</code></pre> <p>For persistent false positives, update the tool configuration in <code>pyproject.toml</code> (Bandit) or add a <code>.semgrepignore</code> file.</p>"},{"location":"development/ci-cd/#related-documentation","title":"Related Documentation","text":"<ul> <li>Testing Guide -- Test suite details, writing tests, coverage strategy</li> <li>Architecture -- System design and 6 Docker services</li> <li>Security -- Encryption, authentication, and threat model</li> <li>Setup and Contributing -- Development workflow and coding standards</li> </ul>"},{"location":"development/github-secrets/","title":"GitHub Secrets Configuration","text":"<p>This document lists all GitHub secrets for Zetherion AI's CI/CD pipeline and local development.</p> <p>Important: All secrets are optional for CI. The GitHub Actions pipeline runs unit tests, linting, type checking, security scans, and Docker builds without any configured secrets.</p>"},{"location":"development/github-secrets/#quick-reference","title":"Quick Reference","text":"Secret Name Required? Purpose Used In <code>DISCORD_TOKEN</code> Optional Production bot token Local integration tests only <code>GEMINI_API_KEY</code> Optional Gemini API for routing and embeddings Local integration tests only <code>ANTHROPIC_API_KEY</code> Optional Claude API for complex tasks Local integration tests only <code>OPENAI_API_KEY</code> Optional OpenAI API for complex tasks Local integration tests only <code>TEST_DISCORD_BOT_TOKEN</code> Optional Test bot token for E2E tests Local Discord E2E tests only <code>TEST_DISCORD_CHANNEL_ID</code> Optional Test channel ID for E2E tests Local Discord E2E tests only <p>All 6 secrets are optional. They are only needed if you want to run integration or E2E tests locally.</p>"},{"location":"development/github-secrets/#cicd-pipeline-no-secrets-required","title":"CI/CD Pipeline (No Secrets Required)","text":"<p>The GitHub Actions CI/CD pipeline runs the following jobs without any secrets:</p> <ul> <li>Linting and formatting (Ruff)</li> <li>Type checking (Mypy strict mode)</li> <li>Security scanning (Bandit)</li> <li>Unit tests (Python 3.12 and 3.13) -- 3,000+ tests, 93%+ coverage</li> <li>Docker build verification (all 6 services)</li> </ul> <p>These will pass out of the box on any fork or clone.</p> <p>See <code>../technical/architecture.md</code> for how these jobs fit into the overall system.</p>"},{"location":"development/github-secrets/#local-integration-testing-optional","title":"Local Integration Testing (Optional)","text":""},{"location":"development/github-secrets/#discord_token","title":"DISCORD_TOKEN","text":"<p>Purpose: Your production Discord bot token for local integration testing.</p> <p>How to get it:</p> <ol> <li>Go to Discord Developer Portal</li> <li>Select your application</li> <li>Go to \"Bot\" section</li> <li>Click \"Reset Token\" or copy existing token</li> <li>Copy the token immediately (it will not be shown again)</li> </ol> <p>Format: Three dot-separated parts totaling 70+ characters.</p> <p>Security notes:</p> <ul> <li>This token grants full access to your bot</li> <li>Never commit this to version control</li> <li>Regenerate immediately if accidentally exposed</li> </ul>"},{"location":"development/github-secrets/#gemini_api_key","title":"GEMINI_API_KEY","text":"<p>Purpose: Google Gemini API key for routing, embeddings, and simple queries. Zetherion AI uses gemini-2.5-flash as one of its default cloud models.</p> <p>How to get it:</p> <ol> <li>Go to Google AI Studio</li> <li>Click \"Create API Key\"</li> <li>Select or create a Google Cloud project</li> <li>Copy the API key</li> </ol> <p>Format: <code>AIzaSy...</code> followed by 33 alphanumeric characters.</p> <p>Free tier:</p> <ul> <li>60 requests per minute</li> <li>1,500 requests per day</li> <li>Sufficient for local testing</li> </ul>"},{"location":"development/github-secrets/#optional-secrets","title":"Optional Secrets","text":""},{"location":"development/github-secrets/#anthropic_api_key","title":"ANTHROPIC_API_KEY","text":"<p>Purpose: Claude API for handling complex tasks, code generation, and high-quality reasoning. Zetherion AI uses claude-sonnet-4-5-20250929 as its primary cloud model.</p> <p>Required for:</p> <ul> <li>Testing Claude-based response generation</li> <li>If not provided, tests will fall back to Gemini or OpenAI</li> </ul> <p>How to get it:</p> <ol> <li>Go to Anthropic Console</li> <li>Navigate to \"API Keys\"</li> <li>Click \"Create Key\"</li> <li>Copy the API key</li> </ol> <p>Format: <code>sk-ant-api03-</code> followed by 95-100 alphanumeric characters.</p> <p>Pricing:</p> <ul> <li>Pay-as-you-go</li> <li>Claude Sonnet 4.5: $3 per million input tokens, $15 per million output tokens</li> <li>Local test usage: approximately $0.10-0.50 per test run</li> </ul>"},{"location":"development/github-secrets/#openai_api_key","title":"OPENAI_API_KEY","text":"<p>Purpose: OpenAI API for alternative complex task handling. Zetherion AI uses gpt-5.2 as one of its default cloud models.</p> <p>Required for:</p> <ul> <li>Testing OpenAI-based response generation</li> <li>If not provided, tests will fall back to Claude or Gemini</li> </ul> <p>How to get it:</p> <ol> <li>Go to OpenAI Platform</li> <li>Click \"Create new secret key\"</li> <li>Name it (e.g., \"Zetherion AI CI\")</li> <li>Copy the API key immediately</li> </ol> <p>Format: <code>sk-proj-</code> followed by approximately 48 alphanumeric characters.</p> <p>Pricing:</p> <ul> <li>Pay-as-you-go</li> <li>gpt-5.2: check OpenAI pricing page for current rates</li> <li>Local test usage: approximately $0.05-0.30 per test run</li> </ul>"},{"location":"development/github-secrets/#test_discord_bot_token","title":"TEST_DISCORD_BOT_TOKEN","text":"<p>Purpose: Separate Discord bot token for end-to-end testing with the real Discord API.</p> <p>Required for:</p> <ul> <li>Discord E2E tests (<code>test_discord_e2e.py</code>)</li> <li>Testing real bot responses, slash commands, and message handling</li> <li>If not provided, Discord E2E tests are skipped automatically</li> </ul> <p>How to get it:</p> <ol> <li>Create a separate Discord application for testing</li> <li>Go to Discord Developer Portal</li> <li>Click \"New Application\"</li> <li>Name it \"Zetherion AI Test Bot\"</li> <li>Go to \"Bot\" section</li> <li>Copy the bot token</li> </ol> <p>Important:</p> <ul> <li>Use a DIFFERENT bot than your production bot</li> <li>Add this test bot to a dedicated test server</li> <li>Give it minimal permissions (Read Messages, Send Messages)</li> </ul> <p>Format: Same as <code>DISCORD_TOKEN</code>.</p>"},{"location":"development/github-secrets/#test_discord_channel_id","title":"TEST_DISCORD_CHANNEL_ID","text":"<p>Purpose: Discord channel ID where the test bot will send messages during E2E testing.</p> <p>Required for:</p> <ul> <li>Discord E2E tests alongside <code>TEST_DISCORD_BOT_TOKEN</code></li> <li>If not provided, Discord E2E tests are skipped automatically</li> </ul> <p>How to get it:</p> <ol> <li>Enable Developer Mode in Discord: User Settings -&gt; Advanced -&gt; Developer Mode (toggle ON)</li> <li>Right-click the test channel</li> <li>Click \"Copy Channel ID\"</li> </ol> <p>Format: <code>1234567890123456789</code> (18-19 digit numeric string).</p> <p>Important:</p> <ul> <li>Use a dedicated test channel</li> <li>The test bot must have access to this channel</li> <li>Messages will be posted during test runs</li> </ul>"},{"location":"development/github-secrets/#quick-setup-guide","title":"Quick Setup Guide","text":""},{"location":"development/github-secrets/#for-cicd-no-setup-needed","title":"For CI/CD (No Setup Needed)","text":"<p>No secrets required. Push your code and the CI pipeline will pass automatically. All 3,000+ unit tests run without any API keys.</p>"},{"location":"development/github-secrets/#for-local-integration-tests","title":"For Local Integration Tests","text":"<p>Add these to your <code>.env</code> file in the project root:</p> <pre><code># Required for local integration tests\nDISCORD_TOKEN=&lt;your-production-bot-token&gt;\nGEMINI_API_KEY=&lt;your-gemini-api-key&gt;\n\n# Optional (improves test coverage of multi-provider routing)\nANTHROPIC_API_KEY=&lt;your-claude-api-key&gt;\nOPENAI_API_KEY=&lt;your-openai-api-key&gt;\n</code></pre> <p>Run with:</p> <pre><code>./scripts/run-integration-tests.sh\n</code></pre>"},{"location":"development/github-secrets/#for-discord-e2e-tests","title":"For Discord E2E Tests","text":"<p>Add these additional variables to your <code>.env</code> file:</p> <pre><code># Required for Discord E2E tests\nTEST_DISCORD_BOT_TOKEN=&lt;your-test-bot-token&gt;\nTEST_DISCORD_CHANNEL_ID=&lt;your-test-channel-id&gt;\n</code></pre> <p>Run with:</p> <pre><code>pytest tests/integration/test_discord_e2e.py -v -s -m discord_e2e\n</code></pre> <p>See <code>../technical/configuration.md</code> for the full list of environment variables.</p>"},{"location":"development/github-secrets/#adding-secrets-to-github","title":"Adding Secrets to GitHub","text":"<p>Note: GitHub secrets are optional since integration tests run locally only. These steps are provided for future use or if your workflow changes.</p>"},{"location":"development/github-secrets/#via-github-web-ui","title":"Via GitHub Web UI","text":"<ol> <li>Go to your repository on GitHub</li> <li>Click Settings (top menu)</li> <li>In the left sidebar, click Secrets and variables -&gt; Actions</li> <li>Click New repository secret</li> <li>Enter the Name (exactly as shown in the Quick Reference table)</li> <li>Enter the Value (your API key or token)</li> <li>Click Add secret</li> </ol>"},{"location":"development/github-secrets/#via-github-cli","title":"Via GitHub CLI","text":"<pre><code>gh secret set DISCORD_TOKEN\ngh secret set GEMINI_API_KEY\ngh secret set ANTHROPIC_API_KEY\ngh secret set OPENAI_API_KEY\ngh secret set TEST_DISCORD_BOT_TOKEN\ngh secret set TEST_DISCORD_CHANNEL_ID\n</code></pre> <p>You will be prompted to paste the value for each secret.</p>"},{"location":"development/github-secrets/#verifying-cicd","title":"Verifying CI/CD","text":"<p>Push a commit and check the GitHub Actions tab. All CI jobs should pass without any secrets configured:</p> <pre><code>Linting and Formatting        PASS\nType Checking                 PASS\nSecurity Scanning             PASS\nUnit Tests (Python 3.12)      PASS\nUnit Tests (Python 3.13)      PASS\nDocker Build                  PASS\nCI Summary                    PASS\n\nNote: Integration tests (E2E) run locally only.\n</code></pre>"},{"location":"development/github-secrets/#security-best-practices","title":"Security Best Practices","text":"<p>DO:</p> <ul> <li>Use separate test bot tokens from production</li> <li>Regenerate tokens immediately if accidentally exposed</li> <li>Use API keys with minimal required permissions</li> <li>Monitor API usage dashboards for unexpected activity</li> <li>Set up billing alerts for paid APIs (Anthropic, OpenAI)</li> <li>Store secrets in <code>.env</code> (which is in <code>.gitignore</code>)</li> </ul> <p>DO NOT:</p> <ul> <li>Commit secrets to version control</li> <li>Share secrets in Discord, Slack, or email</li> <li>Use production bot tokens in public CI</li> <li>Skip secret rotation after team member departures</li> <li>Set secrets as plaintext environment variables in CI config files</li> <li>Use the same API key for production and testing</li> </ul>"},{"location":"development/github-secrets/#cost-estimates","title":"Cost Estimates","text":""},{"location":"development/github-secrets/#cicd-cost-0month","title":"CI/CD Cost: $0/month","text":"<p>GitHub CI/CD requires no API keys. All 3,000+ unit tests, linting, type checking, security scans, and Docker builds run for free.</p>"},{"location":"development/github-secrets/#local-integration-testing-cost","title":"Local Integration Testing Cost","text":"<p>If you run integration tests locally:</p> Service Model Usage Cost Gemini API gemini-2.5-flash 10-20 requests/test run Free (within free tier) Anthropic Claude claude-sonnet-4-5-20250929 5-10 requests/test run ~$0.10-0.50/run OpenAI gpt-5.2 5-10 requests/test run ~$0.05-0.30/run Discord API -- Unlimited Free Ollama (local) llama3.2:3b, llama3.1:8b Unlimited Free (runs locally) <p>Typical cost: $0-1/month for occasional local testing.</p> <p>See <code>../technical/cost-tracking.md</code> for the built-in cost tracking and budget management system.</p>"},{"location":"development/github-secrets/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/github-secrets/#ci-is-failing","title":"CI is failing","text":"<p>Cause: Usually linting, type checking, or unit test failures -- not missing secrets.</p> <p>Solution:</p> <ol> <li>Run locally: <code>pytest tests/ -m \"not integration\"</code></li> <li>Check pre-commit hooks: <code>pre-commit run --all-files</code></li> <li>Review GitHub Actions logs for the specific error message</li> </ol>"},{"location":"development/github-secrets/#local-integration-tests-failing-with-auth-errors","title":"Local integration tests failing with auth errors","text":"<p>Cause: <code>DISCORD_TOKEN</code> or <code>GEMINI_API_KEY</code> invalid or missing in <code>.env</code> file.</p> <p>Solution:</p> <ol> <li>Verify <code>.env</code> file exists in the project root and has the required keys</li> <li>Regenerate tokens if expired</li> <li>Check for typos in environment variable names (they are case-sensitive)</li> </ol>"},{"location":"development/github-secrets/#api-rate-limit-errors-local-testing","title":"API rate limit errors (local testing)","text":"<p>Cause: Too many local test runs hitting API limits.</p> <p>Solution:</p> <ol> <li>Wait for quotas to reset (Gemini: 60 seconds for per-minute limits)</li> <li>Increase API quotas (Gemini: upgrade from free tier)</li> <li>Run fewer tests: <code>pytest tests/integration/test_e2e.py::test_simple_question -v</code></li> </ol>"},{"location":"development/github-secrets/#secret-not-found-errors","title":"\"Secret not found\" errors","text":"<p>Cause: Secret name mismatch or not set at repository level.</p> <p>Solution:</p> <ul> <li>Secret names are case-sensitive</li> <li>Must be set at repository level (not environment level)</li> <li>Use exact names from the Quick Reference table above</li> </ul>"},{"location":"development/github-secrets/#additional-resources","title":"Additional Resources","text":"<ul> <li>GitHub Encrypted Secrets Documentation</li> <li>Discord Developer Portal</li> <li>Google AI Studio</li> <li>Anthropic Console</li> <li>OpenAI Platform</li> </ul>"},{"location":"development/github-secrets/#last-updated","title":"Last Updated","text":"<p>Date: 2026-02-08 Version: 3.0.0 Zetherion AI: Phases 1-9 complete</p>"},{"location":"development/github-secrets/#questions","title":"Questions?","text":"<p>If you have issues with secrets configuration:</p> <ol> <li>Check the Troubleshooting section above</li> <li>Review the CI/CD documentation</li> <li>Open an issue on GitHub</li> </ol>"},{"location":"development/setup/","title":"Setup and Contributing","text":"<p>This guide covers everything you need to start developing Zetherion AI: environment setup, project structure, workflow conventions, and the pull request process. It consolidates information previously spread across multiple documents into one reference.</p> <p>For the overall system architecture, see <code>../technical/architecture.md</code>.</p>"},{"location":"development/setup/#prerequisites","title":"Prerequisites","text":"Requirement Version Notes Python 3.12+ Tested on 3.12 and 3.13 Docker Desktop Latest Required for Qdrant, Ollama, PostgreSQL Git 2.30+ Conventional Commits enforced Code Editor -- VSCode recommended (config included) <p>API keys needed:</p> <ul> <li>Discord Bot Token (required -- first supported input interface)</li> <li>Gemini API Key (optional, free tier available -- enables cloud routing and simple queries)</li> <li>Anthropic API Key (optional, for Claude <code>claude-sonnet-4-5-20250929</code>)</li> <li>OpenAI API Key (optional, for <code>gpt-5.2</code>)</li> </ul> <p>All cloud LLM providers are optional. Ollama provides fully local inference out of the box.</p>"},{"location":"development/setup/#quick-start","title":"Quick Start","text":""},{"location":"development/setup/#macos-linux","title":"macOS / Linux","text":"<pre><code># 1. Clone the repository\ngit clone https://github.com/jimtin/zetherion-ai.git\ncd zetherion-ai\n\n# 2. Create a virtual environment\npython3.12 -m venv venv\nsource venv/bin/activate\n\n# 3. Install dependencies\npip install --upgrade pip\npip install -r requirements.txt\npip install -r requirements-dev.txt\n\n# 4. Install pre-commit and pre-push hooks\npre-commit install\npre-commit install --hook-type pre-push\n\n# 5. Configure environment variables\ncp .env.example .env\n# Edit .env with your API keys\n\n# 6. Verify setup\npython -c \"from zetherion_ai.config import get_settings; print('Config loaded successfully')\"\npytest tests/ -m \"not integration and not discord_e2e\" --maxfail=1\n</code></pre>"},{"location":"development/setup/#windows","title":"Windows","text":"<p>Windows deployment uses a fully automated PowerShell script that handles Docker Desktop, Git, hardware detection, and environment configuration in a single command.</p> <p>Requirements: Administrator PowerShell (press <code>Win + X</code>, select \"Terminal (Admin)\").</p> <pre><code># 1. Clone the repository\ngit clone https://github.com/jimtin/zetherion-ai.git\ncd zetherion-ai\n\n# 2. Run automated deployment\n.\\start.ps1\n</code></pre> <p>The <code>start.ps1</code> script performs the following automatically:</p> <ol> <li>Prerequisites check -- installs Docker Desktop and Git via <code>winget</code> if not present</li> <li>Hardware assessment -- detects CPU, RAM, GPU and recommends an Ollama model</li> <li>Configuration wizard -- interactive <code>.env</code> setup if no config file exists</li> <li>Docker build and deploy -- builds containers, starts 6 Docker services, waits for health checks</li> <li>Model download -- pulls the recommended Ollama model if the Ollama backend is selected</li> <li>Verification -- tests Qdrant and Ollama connectivity, displays container status</li> </ol> <p>First run takes approximately 3--9 minutes depending on the backend choice. Subsequent runs take roughly 30 seconds.</p> <p>Windows management commands:</p> <pre><code>.\\status.ps1          # Service health and container summary\n.\\stop.ps1            # Graceful shutdown (data preserved)\n.\\cleanup.ps1         # Full removal (prompts for confirmation)\n.\\cleanup.ps1 -KeepData   # Remove containers but keep volumes\n</code></pre> <p>Troubleshooting WSL2: If Docker Desktop fails to start, ensure WSL 2 is installed and up to date:</p> <pre><code>wsl --status\nwsl --update\n</code></pre> <p>If the execution policy blocks the script, allow scripts for the current session:</p> <pre><code>Set-ExecutionPolicy -ExecutionPolicy Bypass -Scope Process\n.\\start.ps1\n</code></pre>"},{"location":"development/setup/#project-structure","title":"Project Structure","text":"<pre><code>src/zetherion_ai/                   # 91 source files\n    agent/                          # Agent core, routing, inference\n        core.py                     # Message handling, retry logic, dual generators\n        router.py                   # Gemini router backend\n        router_ollama.py            # Ollama router backend\n        router_factory.py           # Router backend selection, health checks\n        router_base.py              # Abstract router interface\n        inference.py                # Inference broker\n        providers.py                # LLM provider abstraction\n        prompts.py                  # System prompt construction\n    discord/                        # Discord bot\n        bot.py                      # Main bot class, event handling\n        security.py                 # Allowlist, rate limiting, injection detection\n        user_manager.py             # RBAC user management\n    memory/                         # Vector memory layer\n        qdrant.py                   # Async Qdrant client\n        embeddings.py               # Gemini embeddings (768-dim, parallel batch)\n    security/                       # Encryption and key management\n        encryption.py               # AES-256-GCM at-rest encryption\n        keys.py                     # Key derivation and rotation\n    skills/                         # Skills framework\n        base.py                     # Skill abstract base class\n        permissions.py              # Permission enum and PermissionSet\n        registry.py                 # Intent-based skill routing\n        server.py                   # REST API server (aiohttp)\n        client.py                   # HTTP client for bot-to-skills communication\n        task_manager.py             # Task management skill\n        calendar.py                 # Calendar awareness skill\n        profile_skill.py            # Profile management skill\n        personal_model.py           # Personal model skill\n        gmail/                      # Gmail integration (13 files)\n            skill.py, client.py, auth.py, accounts.py,\n            inbox.py, sync.py, digest.py, replies.py,\n            analytics.py, trust.py, conflicts.py,\n            calendar_sync.py\n        github/                     # GitHub integration\n            skill.py, client.py, models.py\n    personal/                       # Personal understanding (PostgreSQL)\n        models.py, actions.py, context.py, storage.py\n    profile/                        # User profile engine\n        models.py, builder.py, storage.py, cache.py,\n        inference.py, relationship.py, employment.py\n    observation/                    # Observation pipeline\n        pipeline.py, dispatcher.py, extractors.py, models.py\n        adapters/                   # Platform-specific adapters\n            discord.py, gmail.py\n    costs/                          # Cost tracking\n        tracker.py, aggregator.py, reports.py, storage.py\n    models/                         # Model registry\n        registry.py, discovery.py, pricing.py, tiers.py\n    notifications/                  # Notification system\n        dispatcher.py, discord.py\n    scheduler/                      # Scheduler\n        heartbeat.py, actions.py\n    config.py                       # Pydantic settings\n    logging.py                      # Structured logging (structlog)\n    main.py                         # Application entry point\n    constants.py                    # Project-wide constants\n    utils.py                        # Shared utilities\n    settings_manager.py             # Runtime settings CRUD\ntests/                              # 89 test files, 3,000+ tests, 93%+ coverage\n    unit/                           # Fast, isolated tests (~24s)\n    integration/                    # Full-stack tests (~2 min)\n    conftest.py                     # Shared fixtures\ndocs/                               # Documentation (MkDocs)\nscripts/                            # Utility scripts\n</code></pre>"},{"location":"development/setup/#llm-models","title":"LLM Models","text":"Role Model Provider Complex generation <code>claude-sonnet-4-5-20250929</code> Anthropic Complex generation <code>gpt-5.2</code> OpenAI Router / simple queries <code>gemini-2.5-flash</code> Google Local router <code>llama3.2:3b</code> Ollama Local generation <code>llama3.1:8b</code> Ollama"},{"location":"development/setup/#docker-services","title":"Docker Services","text":"<p>The production <code>docker-compose.yml</code> defines 6 services:</p> Service Purpose <code>zetherion-ai-bot</code> Agent core -- input gateway, security, routing, inference <code>zetherion-ai-skills</code> Skills REST API server <code>ollama</code> Local LLM inference (generation) <code>ollama-router</code> Local LLM inference (routing) <code>postgres</code> PostgreSQL for structured data <code>qdrant</code> Vector database for semantic memory"},{"location":"development/setup/#development-workflow","title":"Development Workflow","text":""},{"location":"development/setup/#branch-strategy","title":"Branch Strategy","text":"Prefix Purpose <code>main</code> Production-ready code (protected) <code>feature/*</code> New features <code>fix/*</code> Bug fixes <code>docs/*</code> Documentation updates <code>test/*</code> Test improvements <code>refactor/*</code> Code restructuring"},{"location":"development/setup/#tdd-cycle","title":"TDD Cycle","text":"<p>Zetherion AI follows test-driven development. The expected workflow is:</p> <ol> <li>Create a feature branch from <code>main</code></li> <li>Write failing tests that define the expected behavior</li> <li>Implement the feature until the tests pass</li> <li>Refactor if needed while keeping tests green</li> <li>Verify the full suite still passes</li> </ol> <pre><code># Write test first\npytest tests/test_my_feature.py -v          # Should fail\n\n# Implement feature, iterate\npytest tests/test_my_feature.py -v --maxfail=1\n\n# Full suite before committing\npytest tests/ -m \"not discord_e2e\" --cov=src/zetherion_ai\n</code></pre>"},{"location":"development/setup/#pre-commit-hooks-7-steps-10-15s","title":"Pre-Commit Hooks (7 steps, ~10--15s)","text":"<p>When you run <code>git commit</code>, the following hooks execute automatically:</p> Step Tool Time What it does 1 pre-commit-hooks ~100ms Trailing whitespace, end-of-file fixer, merge conflict markers, large file prevention, case conflict check, YAML/TOML/JSON syntax, private key detection 2 Gitleaks 1--2s Secret scanning with 12 custom rules and tuned allowlists 3 Ruff (lint) 1--2s 600+ lint rules with auto-fix, import sorting 4 Ruff (format) ~0.5s PEP 8 formatting, 100-char line length 5 mypy 3--5s Strict type checking on all source files 6 Bandit 2--3s Python security scanning (OWASP top 10) 7 Hadolint ~0.5s Dockerfile best practices"},{"location":"development/setup/#pre-push-hooks-3-steps-30-60s","title":"Pre-Push Hooks (3 steps, ~30--60s)","text":"<p>Before pushing, additional checks run:</p> <ol> <li>Ruff -- full project lint and format check</li> <li>mypy -- full project type check</li> <li>pytest -- entire test suite with coverage</li> </ol> <p>If you need to skip hooks in an emergency (not recommended):</p> <pre><code>git commit --no-verify\n</code></pre>"},{"location":"development/setup/#code-style","title":"Code Style","text":""},{"location":"development/setup/#rules","title":"Rules","text":"<ul> <li>Standard: PEP 8, enforced by Ruff</li> <li>Line length: 100 characters</li> <li>Quotes: Double quotes for all strings</li> <li>Docstrings: Google style for all public functions and classes</li> <li>Type hints: Required everywhere (mypy strict mode)</li> <li>Imports: Sorted by Ruff (isort-compatible)</li> </ul>"},{"location":"development/setup/#example","title":"Example","text":"<pre><code>\"\"\"Module docstring describing the file's purpose.\"\"\"\n\nfrom typing import Any\n\nimport structlog\n\nfrom zetherion_ai.config import get_settings\n\nlog = structlog.get_logger(__name__)\n\n\nasync def process_message(\n    message: str,\n    user_id: str,\n    context: dict[str, Any] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Process an incoming user message and return a response.\n\n    Args:\n        message: The raw message text from the user.\n        user_id: Discord user ID as a string.\n        context: Optional additional context for routing.\n\n    Returns:\n        Dictionary containing the response text and metadata.\n\n    Raises:\n        ValueError: If the message is empty.\n    \"\"\"\n    if not message:\n        raise ValueError(\"message must not be empty\")\n\n    settings = get_settings()\n    log.info(\"processing_message\", user_id=user_id, length=len(message))\n\n    return {\"response\": message, \"model\": settings.claude_model}\n</code></pre>"},{"location":"development/setup/#automated-formatting","title":"Automated Formatting","text":"<p>Ruff handles most formatting automatically. Run it manually before committing if you want to preview changes:</p> <pre><code>ruff check --fix .\nruff format .\n</code></pre>"},{"location":"development/setup/#testing","title":"Testing","text":"<p>Zetherion AI has 89 test files containing 3,000+ tests with 93%+ code coverage across 91 source files.</p> <p>For the full testing guide, patterns, fixtures, and mocking strategies, see Testing.</p>"},{"location":"development/setup/#key-commands","title":"Key Commands","text":"<pre><code># Unit tests only (fast, ~24s)\npytest tests/ -m \"not integration and not discord_e2e\"\n\n# All tests except Discord E2E (includes integration)\npytest tests/ -m \"not discord_e2e\"\n\n# Full suite with coverage\npytest tests/ -m \"not discord_e2e\" --cov=src/zetherion_ai --cov-report=term\n\n# HTML coverage report\npytest tests/ -m \"not discord_e2e\" --cov=src/zetherion_ai --cov-report=html\nopen htmlcov/index.html  # macOS\n\n# Run a single test file\npytest tests/unit/test_agent_core.py -v\n\n# Drop into debugger on first failure\npytest tests/ --pdb --maxfail=1\n\n# Show print output and local variables on failure\npytest tests/ -s -l\n</code></pre>"},{"location":"development/setup/#coverage-standards","title":"Coverage Standards","text":"<ul> <li>New features must include tests</li> <li>Aim for 85%+ coverage on new modules</li> <li>Maintain overall 93%+ coverage across the project</li> <li>Focus coverage on critical paths: security, routing, core agent logic</li> <li>Avoid over-testing trivial code (simple getters, dataclass properties)</li> </ul>"},{"location":"development/setup/#debugging","title":"Debugging","text":""},{"location":"development/setup/#logging-levels","title":"Logging Levels","text":"<p>Zetherion AI uses <code>structlog</code> for structured logging. All modules should use the project logger:</p> <pre><code>from zetherion_ai.logging import get_logger\n\nlog = get_logger(__name__)\n\n# Usage\nlog.debug(\"detailed_debug_info\", variable=value)\nlog.info(\"normal_operation\", event=\"message_received\")\nlog.warning(\"potential_issue\", error=str(e))\nlog.error(\"error_occurred\", exc_info=True)\nlog.critical(\"system_failure\", reason=\"Out of memory\")\n</code></pre>"},{"location":"development/setup/#debug-configuration","title":"Debug Configuration","text":"<p>Enable debug logging in your <code>.env</code>:</p> <pre><code>LOG_LEVEL=DEBUG\nENVIRONMENT=development\n</code></pre> <p>In development, structlog renders colored console output with pretty-printed key-value pairs. In production, it writes JSON to rotating log files (10MB per file, 6 files) at <code>logs/zetherion_ai.log</code>.</p>"},{"location":"development/setup/#docker-debugging","title":"Docker Debugging","text":"<pre><code># Container logs (follow mode)\ndocker compose logs zetherion-ai-bot -f\ndocker compose logs qdrant -f\ndocker compose logs ollama -f\n\n# Exec into a running container\ndocker exec -it zetherion-ai-bot bash\ndocker exec -it zetherion-ai-qdrant bash\n\n# Container health status\ndocker compose ps\ndocker inspect zetherion-ai-bot | jq '.[0].State.Health'\n\n# Network connectivity\ndocker exec zetherion-ai-bot ping qdrant\ndocker exec zetherion-ai-bot nc -zv qdrant 6333\ndocker exec zetherion-ai-bot nc -zv ollama 11434\n\n# Resource usage\ndocker stats\n</code></pre>"},{"location":"development/setup/#common-debugging-tasks","title":"Common Debugging Tasks","text":"<p>Filter logs by subsystem (production JSON format):</p> <pre><code># Routing decisions\njq 'select(.event == \"message_routed\")' logs/zetherion_ai.log\n\n# Memory and embedding operations\njq 'select(.event | contains(\"memory\") or contains(\"embedding\"))' logs/zetherion_ai.log\n\n# Discord events\ntail -f logs/zetherion_ai.log | jq 'select(.event | contains(\"discord\"))'\n\n# LLM API calls (requires LOG_LEVEL=DEBUG)\njq 'select(.event | contains(\"api\"))' logs/zetherion_ai.log\n</code></pre> <p>Interactive debugging with pytest:</p> <pre><code>pytest tests/ --pdb            # Drop into pdb on first failure\npytest tests/ -s               # Show print statements\npytest tests/ -vv              # Extra verbose output\npytest tests/ -l               # Show local variables on failure\n</code></pre> <p>Ollama model issues:</p> <pre><code>docker exec zetherion-ai-ollama ollama list\ndocker exec zetherion-ai-ollama ollama pull llama3.1:8b\ndocker exec zetherion-ai-ollama-router ollama pull llama3.2:3b\n</code></pre>"},{"location":"development/setup/#commit-messages","title":"Commit Messages","text":""},{"location":"development/setup/#format","title":"Format","text":"<p>Zetherion AI follows the Conventional Commits specification:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre>"},{"location":"development/setup/#types","title":"Types","text":"Type Purpose <code>feat</code> New feature <code>fix</code> Bug fix <code>docs</code> Documentation changes <code>test</code> Adding or updating tests <code>refactor</code> Code restructuring (no behavior change) <code>perf</code> Performance improvements <code>style</code> Formatting, whitespace (no logic change) <code>chore</code> Maintenance tasks, dependency updates <code>ci</code> CI/CD pipeline changes <code>security</code> Security improvements"},{"location":"development/setup/#examples","title":"Examples","text":"<pre><code># Simple feature\ngit commit -m \"feat: add /status command to show bot statistics\"\n\n# Bug fix with scope\ngit commit -m \"fix(router): handle timeout errors gracefully\"\n\n# Breaking change\ngit commit -m \"feat!: change router interface to async-only\n\nBREAKING CHANGE: RouterBackend.classify() is now async.\nMigration: add 'await' to all classify() calls.\"\n\n# Multi-line with body\ngit commit -m \"test: improve Discord bot coverage to 93%\n\n- Add /channels command tests (6 tests)\n- Add message splitting edge cases (4 tests)\n- Add agent not ready scenario (1 test)\n\nCloses #123\"\n</code></pre>"},{"location":"development/setup/#co-authored-commits","title":"Co-Authored Commits","text":"<p>When working with AI-assisted tools:</p> <pre><code>git commit -m \"feat: implement weather skill\n\nCo-Authored-By: Claude Sonnet 4.5 &lt;noreply@anthropic.com&gt;\"\n</code></pre>"},{"location":"development/setup/#pull-request-process","title":"Pull Request Process","text":""},{"location":"development/setup/#before-submitting","title":"Before Submitting","text":"<p>Run through this checklist:</p> <ul> <li>[ ] All tests pass: <code>pytest tests/ -m \"not discord_e2e\"</code></li> <li>[ ] Coverage maintained at 93%+ (or improved)</li> <li>[ ] Pre-commit hooks pass: <code>pre-commit run --all-files</code></li> <li>[ ] Type checking passes: <code>mypy src/zetherion_ai</code></li> <li>[ ] Code formatted: <code>ruff check --fix . &amp;&amp; ruff format .</code></li> <li>[ ] Documentation updated for any user-facing changes</li> <li>[ ] Conventional commit messages used throughout the branch</li> </ul> <p>Sync your branch with upstream before opening the PR:</p> <pre><code>git fetch upstream\ngit rebase upstream/main\n</code></pre>"},{"location":"development/setup/#pr-description-template","title":"PR Description Template","text":"<pre><code>## Summary\nBrief description of what this PR does and why.\n\n## Changes\n- Added X feature\n- Fixed Y bug\n- Updated Z documentation\n\n## Testing\n- [ ] Unit tests added/updated\n- [ ] Integration tests pass\n- [ ] Manual testing completed\n\n## Screenshots (if UI changes)\n[Add screenshots if applicable]\n\n## Related Issues\nCloses #123\nFixes #456\n</code></pre>"},{"location":"development/setup/#review-criteria","title":"Review Criteria","text":"<p>Pull requests are evaluated on:</p> <ul> <li>Functionality -- Does it work as intended?</li> <li>Tests -- Are there adequate tests? Do they pass?</li> <li>Code quality -- Follows the style guide, no code smells</li> <li>Documentation -- Updated docs, clear docstrings</li> <li>Security -- No vulnerabilities introduced, secrets scanning clean</li> <li>Performance -- No significant performance degradation</li> </ul>"},{"location":"development/setup/#ci-pipeline","title":"CI Pipeline","text":"<p>All of the following must pass before merge:</p> <ol> <li>Ruff linting and formatting</li> <li>mypy type checking</li> <li>Bandit security scan</li> <li>Unit tests (Python 3.12 and 3.13)</li> <li>Docker build</li> <li>Integration tests</li> </ol>"},{"location":"development/setup/#contributing-guidelines","title":"Contributing Guidelines","text":""},{"location":"development/setup/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Welcome newcomers and help them get started</li> <li>Focus on what is best for the community</li> <li>Show empathy towards other community members</li> <li>No harassment, trolling, or derogatory comments</li> <li>Do not publish others' private information</li> </ul>"},{"location":"development/setup/#fork-and-clone-workflow","title":"Fork and Clone Workflow","text":"<p>If you are an external contributor:</p> <pre><code># 1. Fork the repository on GitHub\n\n# 2. Clone your fork\ngit clone https://github.com/YOUR_USERNAME/zetherion-ai.git\ncd zetherion-ai\n\n# 3. Add upstream remote\ngit remote add upstream https://github.com/jimtin/zetherion-ai.git\n\n# 4. Create a feature branch\ngit checkout -b feature/your-feature-name\n\n# 5. Follow the Quick Start instructions above to set up your environment\n\n# 6. Make changes, commit, push to your fork\ngit push origin feature/your-feature-name\n\n# 7. Open a Pull Request on GitHub against upstream/main\n</code></pre>"},{"location":"development/setup/#getting-help","title":"Getting Help","text":"<ul> <li>Issues: github.com/jimtin/zetherion-ai/issues -- bug reports and feature requests</li> <li>Discussions: github.com/jimtin/zetherion-ai/discussions -- questions and general discussion</li> </ul> <p>When reporting issues, include:</p> <ul> <li>Your OS and Python version</li> <li>Docker Desktop version (<code>docker --version</code>)</li> <li>The output of <code>docker compose ps</code></li> <li>Relevant error messages or log output</li> </ul>"},{"location":"development/setup/#vscode-configuration","title":"VSCode Configuration","text":""},{"location":"development/setup/#recommended-extensions","title":"Recommended Extensions","text":"<p>These are defined in <code>.vscode/extensions.json</code>:</p> <ul> <li>Python (<code>ms-python.python</code>) -- language support</li> <li>Pylance (<code>ms-python.vscode-pylance</code>) -- type checking and IntelliSense</li> <li>Ruff (<code>charliermarsh.ruff</code>) -- linting and formatting</li> <li>Docker (<code>ms-azuretools.vscode-docker</code>) -- container management</li> <li>GitLens (<code>eamodio.gitlens</code>) -- git blame and history</li> </ul>"},{"location":"development/setup/#settings","title":"Settings","text":"<p>Add the following to <code>.vscode/settings.json</code> (or use the provided config):</p> <pre><code>{\n  \"python.linting.enabled\": true,\n  \"python.linting.mypyEnabled\": true,\n  \"python.formatting.provider\": \"none\",\n  \"[python]\": {\n    \"editor.defaultFormatter\": \"charliermarsh.ruff\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"source.fixAll\": \"explicit\",\n      \"source.organizeImports\": \"explicit\"\n    }\n  },\n  \"editor.rulers\": [100],\n  \"files.trimTrailingWhitespace\": true,\n  \"files.insertFinalNewline\": true\n}\n</code></pre>"},{"location":"development/testing/","title":"Testing Guide","text":"<p>Comprehensive guide to Zetherion AI's test suite, testing patterns, and coverage strategy.</p>"},{"location":"development/testing/#overview","title":"Overview","text":"<p>Zetherion AI maintains a rigorous testing discipline across the entire codebase:</p> <ul> <li>3,000+ tests across 89 test files covering 91 source files</li> <li>93%+ code coverage with branch coverage enabled</li> <li>Three-layer testing pyramid: Unit, Integration, and Discord E2E</li> <li>Async-first test design using <code>pytest-asyncio</code> with <code>asyncio_mode = \"auto\"</code></li> </ul> <pre><code>                     /\\\n                    /  \\\n                   / E2E\\\n                  / Discord\\\n                 /  (Real API) \\\n                /________________\\\n               /                  \\\n              /   Integration       \\\n             / (Docker + Services)   \\\n            /     ~2-3 minutes        \\\n           /___________________________\\\n          /                              \\\n         /         Unit Tests              \\\n        /    (Mocked, Fast Feedback)        \\\n       /         ~60 seconds                 \\\n      /___________________________________________\\\n       Fastest | Most Isolated | Largest Volume\n</code></pre>"},{"location":"development/testing/#test-organization","title":"Test Organization","text":"<p>Tests are organized into three directories reflecting the testing pyramid.</p>"},{"location":"development/testing/#directory-structure","title":"Directory Structure","text":"<pre><code>tests/\n  conftest.py                      # Shared fixtures (settings, mocks, sample data)\n  __init__.py\n  test_agent_core.py               # Root-level: agent core (legacy location)\n  test_bot.py                      # Root-level: Discord bot\n  test_config.py                   # Root-level: configuration\n  test_embeddings.py               # Root-level: embedding generation\n  test_qdrant.py                   # Root-level: vector database\n  test_router.py                   # Root-level: intent routing\n  test_router_factory.py           # Root-level: router factory\n  test_router_ollama.py            # Root-level: Ollama router\n  test_security.py                 # Root-level: security module\n  unit/\n    test_agent_core.py             # Agent core logic\n    test_config.py                 # Settings validation\n    test_constants.py              # Constants and enums\n    test_costs.py                  # Cost tracking\n    test_discord_bot.py            # Discord bot handlers\n    test_discord_notifier.py       # Discord notifications\n    test_discovery.py              # Service discovery\n    test_embeddings.py             # Embedding generation\n    test_employment_profile.py     # Employment profile model\n    test_encryption.py             # AES-GCM encryption\n    test_github_client.py          # GitHub API client\n    test_github_models.py          # GitHub data models\n    test_github_skill.py           # GitHub skill logic\n    test_gmail_accounts.py         # Gmail account management\n    test_gmail_analytics.py        # Gmail analytics\n    test_gmail_auth.py             # Gmail OAuth\n    test_gmail_calendar_sync.py    # Calendar synchronization\n    test_gmail_client.py           # Gmail API client\n    test_gmail_conflicts.py        # Gmail conflict resolution\n    test_gmail_digest.py           # Daily email digest\n    test_gmail_inbox.py            # Inbox operations\n    test_gmail_replies.py          # Email reply handling\n    test_gmail_skill.py            # Gmail skill logic\n    test_gmail_sync.py             # Gmail sync operations\n    test_gmail_trust.py            # Gmail trust scoring\n    test_inference_broker.py       # Multi-provider LLM broker\n    test_interactive_setup.py      # Interactive setup wizard\n    test_logging.py                # Structured logging\n    test_main_startup.py           # Application startup\n    test_models.py                 # Data models\n    test_notifications.py          # Notification system\n    test_observation_discord_adapter.py\n    test_observation_dispatcher.py\n    test_observation_extractors.py\n    test_observation_gmail_adapter.py\n    test_observation_models.py\n    test_observation_pipeline.py\n    test_personal_actions.py       # Personal action system\n    test_personal_context.py       # Personal context engine\n    test_personal_models.py        # Personal data models\n    test_personal_storage.py       # Personal data storage\n    test_profile_builder.py        # Profile construction\n    test_profile_cache.py          # Profile caching\n    test_profile_inference.py      # Profile inference engine\n    test_profile_models.py         # Profile data models\n    test_profile_storage.py        # Profile persistence\n    test_providers.py              # LLM provider abstraction\n    test_pyproject_sync.py         # pyproject.toml synchronization\n    test_qdrant.py                 # Vector database operations\n    test_registry.py               # Service registry\n    test_relationship_tracker.py   # Relationship tracking\n    test_router.py                 # Intent router\n    test_router_factory.py         # Router factory pattern\n    test_router_ollama.py          # Ollama-backed router\n    test_scheduler_actions.py      # Scheduled task actions\n    test_scheduler_heartbeat.py    # Scheduler heartbeat\n    test_security.py               # Security module\n    test_settings_manager.py       # Runtime settings\n    test_skill_calendar.py         # Calendar skill\n    test_skill_personal_model.py   # Personal model skill\n    test_skill_profile.py          # Profile skill\n    test_skill_task_manager.py     # Task manager skill\n    test_skills_base.py            # Skill base class\n    test_skills_client.py          # Skills HTTP client\n    test_skills_permissions.py     # Skill permission system\n    test_skills_registry.py        # Skill registry\n    test_skills_server.py          # Skills HTTP server\n    test_skills_server_main.py     # Skills server entrypoint\n    test_task_classification.py    # Task classification\n    test_user_manager.py           # User management\n    test_utils.py                  # Utility functions\n  integration/\n    __init__.py\n    test_agent_skills_http.py      # Agent-to-skills HTTP communication\n    test_discord_e2e.py            # Real Discord API end-to-end\n    test_e2e.py                    # Full stack end-to-end\n    test_encryption_at_rest.py     # Encryption at rest verification\n    test_heartbeat_cycle.py        # Scheduler heartbeat cycle\n    test_profile_pipeline.py       # Full profile pipeline\n    test_skills_e2e.py             # Skills system end-to-end\n    test_skills_http.py            # Skills HTTP layer\n    test_user_isolation.py         # Multi-user data isolation\n</code></pre>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":"Category Location Count Speed Dependencies Unit tests <code>tests/unit/</code> ~70 files Fast (~60s total) Mocked Root-level tests <code>tests/test_*.py</code> 9 files Fast (~10s) Mocked Integration tests <code>tests/integration/</code> 9 files Slow (~2-3 min) Docker services Discord E2E <code>tests/integration/test_discord_e2e.py</code> 1 file Slow (~1 min) Real Discord API"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#quick-commands","title":"Quick Commands","text":"<pre><code># All unit tests (fast, ~60s) -- excludes integration and Discord E2E\npytest tests/ -m \"not integration and not discord_e2e\"\n\n# Specific test file\npytest tests/unit/test_agent_core.py -v\n\n# Specific test class\npytest tests/unit/test_config.py::TestSettingsValidation -v\n\n# Specific test function\npytest tests/unit/test_encryption.py::test_encrypt_decrypt_roundtrip -v\n\n# Pattern matching\npytest tests/ -k \"test_gmail\" -v\n\n# With coverage (HTML + terminal)\npytest tests/ -m \"not discord_e2e\" --cov=src/zetherion_ai --cov-report=html --cov-report=term-missing\n\n# Integration tests only (requires Docker)\npytest tests/integration/ -m integration -v -s\n\n# Full suite (everything except Discord E2E)\npytest tests/ -m \"not discord_e2e\" -v\n</code></pre>"},{"location":"development/testing/#test-markers","title":"Test Markers","text":"<p>Zetherion AI defines three custom markers in <code>pyproject.toml</code>:</p> Marker Description Usage <code>integration</code> Tests requiring Docker services (Qdrant, Ollama, PostgreSQL) <code>pytest -m integration</code> <code>discord_e2e</code> True end-to-end tests hitting the real Discord API <code>pytest -m discord_e2e</code> <code>slow</code> Tests exceeding 5 seconds <code>pytest -m \"not slow\"</code> <p>Common marker combinations:</p> <pre><code># Only fast unit tests\npytest tests/ -m \"not integration and not discord_e2e and not slow\"\n\n# Integration but not Discord E2E\npytest tests/ -m \"integration and not discord_e2e\"\n\n# Everything except integration\npytest tests/ -m \"not integration\"\n</code></pre>"},{"location":"development/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"development/testing/#unit-test-patterns","title":"Unit Test Patterns","text":"<p>Unit tests follow the Arrange-Act-Assert pattern with mocked external dependencies.</p> <p>Basic synchronous test:</p> <pre><code>\"\"\"Tests for the encryption module.\"\"\"\n\nimport pytest\nfrom zetherion_ai.security import EncryptionManager\n\n\ndef test_encrypt_decrypt_roundtrip():\n    \"\"\"Plaintext survives an encrypt-then-decrypt cycle.\"\"\"\n    # Arrange\n    manager = EncryptionManager(passphrase=\"test-passphrase\")\n    plaintext = \"sensitive user data\"\n\n    # Act\n    ciphertext = manager.encrypt(plaintext)\n    result = manager.decrypt(ciphertext)\n\n    # Assert\n    assert result == plaintext\n    assert ciphertext != plaintext\n</code></pre> <p>Async test (no decorator needed with <code>asyncio_mode = \"auto\"</code>):</p> <pre><code>import pytest\nfrom unittest.mock import AsyncMock, patch\n\n\nasync def test_agent_processes_message(mock_settings):\n    \"\"\"Agent generates a response for a simple user message.\"\"\"\n    mock_provider = AsyncMock()\n    mock_provider.generate.return_value = \"Hello! How can I help?\"\n\n    with patch(\"zetherion_ai.agent.core.get_provider\", return_value=mock_provider):\n        from zetherion_ai.agent.core import Agent\n\n        agent = Agent(settings=mock_settings)\n        response = await agent.process(\"Hi there\", user_id=123)\n\n    assert response is not None\n    assert len(response) &gt; 0\n</code></pre> <p>Parametrized test:</p> <pre><code>import pytest\n\n\n@pytest.mark.parametrize(\n    \"input_text, expected_intent\",\n    [\n        (\"hello\", \"simple_query\"),\n        (\"remember that I like Python\", \"memory_store\"),\n        (\"what do you know about me?\", \"memory_recall\"),\n        (\"search my emails for invoices\", \"skill_gmail\"),\n    ],\n)\nasync def test_router_classifies_intent(input_text, expected_intent, mock_settings):\n    \"\"\"Router correctly classifies user intent for common message types.\"\"\"\n    router = Router(settings=mock_settings)\n    result = await router.classify(input_text)\n    assert result.intent == expected_intent\n</code></pre>"},{"location":"development/testing/#integration-test-patterns","title":"Integration Test Patterns","text":"<p>Integration tests use the <code>@pytest.mark.integration</code> marker and typically require Docker services.</p> <pre><code>\"\"\"Integration test for the full profile pipeline.\"\"\"\n\nimport pytest\n\n\n@pytest.mark.asyncio\n@pytest.mark.integration\nasync def test_profile_pipeline_stores_and_retrieves(mock_bot):\n    \"\"\"Profile pipeline stores observations and retrieves a coherent profile.\"\"\"\n    # Store an observation through the full pipeline\n    await mock_bot.simulate_message(\"I am a senior Python developer at Acme Corp\")\n\n    # Retrieve the profile\n    response = await mock_bot.simulate_message(\"What do you know about my career?\")\n\n    assert \"python\" in response.lower()\n    assert response is not None\n</code></pre> <p>MockDiscordBot usage -- integration tests bypass the real Discord API by using <code>MockDiscordBot</code>, which injects messages directly into the agent pipeline:</p> <pre><code>@pytest.mark.integration\nasync def test_memory_roundtrip(mock_bot):\n    \"\"\"Data stored in memory can be recalled in a later turn.\"\"\"\n    await mock_bot.simulate_message(\"Remember that my favorite color is blue\")\n    response = await mock_bot.simulate_message(\"What is my favorite color?\")\n    assert \"blue\" in response.lower()\n</code></pre>"},{"location":"development/testing/#fixture-patterns","title":"Fixture Patterns","text":"<p>The root <code>tests/conftest.py</code> provides shared fixtures used across all test layers.</p> <p>Key fixtures:</p> Fixture Scope Description <code>setup_test_environment</code> session (autouse) Sets <code>DISCORD_TOKEN</code>, <code>GEMINI_API_KEY</code>, <code>ENCRYPTION_PASSPHRASE</code> as test placeholders <code>clear_settings_cache</code> function (autouse) Clears the <code>get_settings</code> LRU cache before and after each test <code>mock_settings</code> function A fully configured <code>Settings</code> instance with test values <code>mock_qdrant_client</code> function <code>AsyncMock</code> of <code>AsyncQdrantClient</code> with stubbed CRUD methods <code>mock_embeddings_client</code> function Mock Gemini embeddings client returning 768-dim vectors <code>mock_gemini_client</code> function Mock Gemini generative client returning JSON routing responses <code>mock_claude_client</code> function Mock Anthropic client (<code>claude-sonnet-4-5-20250929</code>) <code>mock_openai_client</code> function Mock OpenAI client (<code>gpt-5.2</code>) <code>mock_discord_message</code> function Mock <code>discord.Message</code> with <code>author</code>, <code>content</code>, <code>channel</code>, <code>reply</code> <code>mock_discord_interaction</code> function Mock <code>discord.Interaction</code> with <code>defer</code> and <code>followup.send</code> <code>sample_vector</code> function 768-dimensional float vector for embedding tests <code>sample_conversation_messages</code> function Two-message conversation history (user + assistant) <code>sample_memories</code> function Two sample long-term memories (preference + fact) <p>Custom fixture example:</p> <pre><code>@pytest.fixture\ndef gmail_client(mock_settings):\n    \"\"\"Gmail client with mocked OAuth credentials.\"\"\"\n    with patch(\"zetherion_ai.skills.gmail.client.get_credentials\") as mock_creds:\n        mock_creds.return_value = Mock(valid=True, token=\"test-token\")\n        client = GmailClient(settings=mock_settings)\n        yield client\n</code></pre>"},{"location":"development/testing/#coverage","title":"Coverage","text":""},{"location":"development/testing/#current-state","title":"Current State","text":"Metric Value Overall coverage 93%+ Total tests 3,000+ Test files 89 Source files 91 Branch coverage Enabled"},{"location":"development/testing/#coverage-targets","title":"Coverage Targets","text":"Scope Target Rationale New modules 85%+ Maintain overall quality Security paths (encryption, auth, permissions) 95%+ Critical user data protection Core agent loop 90%+ Primary user-facing path Skills and integrations 85%+ External API interaction Overall project 93%+ Do not regress"},{"location":"development/testing/#coverage-by-module-approximate","title":"Coverage by Module (Approximate)","text":"Module Coverage Notes <code>security/</code> 97% Encryption, user auth, permissions <code>agent/</code> 95% Core agent, router, providers <code>memory/</code> 94% Qdrant, embeddings <code>config.py</code> 96% Settings validation <code>discord/</code> 92% Bot handlers, user manager <code>skills/</code> 91% Gmail, GitHub, calendar, tasks <code>observation/</code> 93% Pipeline, extractors, adapters <code>personal/</code> 92% Context, actions, storage <code>profile/</code> 93% Builder, cache, inference <code>models/</code> 95% Pydantic data models <code>costs/</code> 94% Usage tracking <code>scheduler/</code> 90% Heartbeat, actions <code>notifications/</code> 91% Discord notifier"},{"location":"development/testing/#generating-reports","title":"Generating Reports","text":"<pre><code># HTML report (opens in browser)\npytest tests/ -m \"not discord_e2e\" --cov=src/zetherion_ai --cov-report=html\nopen htmlcov/index.html\n\n# Terminal report with missing lines\npytest tests/ -m \"not discord_e2e\" --cov=src/zetherion_ai --cov-report=term-missing\n\n# XML report (for CI / Codecov)\npytest tests/ -m \"not discord_e2e\" --cov=src/zetherion_ai --cov-report=xml\n\n# Combined (all three at once -- this is the default via pyproject.toml addopts)\npytest tests/ -m \"not discord_e2e\"\n</code></pre>"},{"location":"development/testing/#test-configuration","title":"Test Configuration","text":"<p>All test configuration lives in <code>pyproject.toml</code>:</p> <pre><code>[tool.pytest.ini_options]\nasyncio_mode = \"auto\"\ntestpaths = [\"tests\"]\npythonpath = [\"src\"]\naddopts = [\n    \"-v\",\n    \"--strict-markers\",\n    \"--tb=short\",\n    \"--cov=src/zetherion_ai\",\n    \"--cov-report=term-missing\",\n    \"--cov-report=html\",\n    \"--cov-report=xml\",\n]\nmarkers = [\n    \"integration: marks tests as integration tests (deselect with '-m \\\"not integration\\\"')\",\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n    \"discord_e2e: marks tests as Discord end-to-end tests (deselect with '-m \\\"not discord_e2e\\\"')\",\n]\n\n[tool.coverage.run]\nsource = [\"src/zetherion_ai\"]\nomit = [\"*/tests/*\", \"*/__pycache__/*\", \"*/site-packages/*\"]\nbranch = true\n\n[tool.coverage.report]\nprecision = 2\nshow_missing = true\nskip_covered = false\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n    \"if __name__ == .__main__.:\",\n    \"if TYPE_CHECKING:\",\n    \"@abstractmethod\",\n]\n</code></pre> <p>Key settings:</p> <ul> <li><code>asyncio_mode = \"auto\"</code> -- async test functions are detected and run automatically without needing <code>@pytest.mark.asyncio</code> on every test.</li> <li><code>--strict-markers</code> -- unregistered markers cause an error, preventing typos like <code>@pytest.mark.intgration</code>.</li> <li><code>pythonpath = [\"src\"]</code> -- allows <code>from zetherion_ai.x import y</code> without installing the package.</li> <li><code>branch = true</code> -- coverage tracks branch paths, not just line execution.</li> </ul>"},{"location":"development/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"development/testing/#common-debugging-flags","title":"Common Debugging Flags","text":"<pre><code># Show print statements and log output (pytest normally captures stdout)\npytest tests/unit/test_agent_core.py -s\n\n# Drop into the Python debugger on first failure\npytest tests/unit/test_agent_core.py --pdb\n\n# Stop on first failure (do not run remaining tests)\npytest tests/ -x\n\n# Stop after N failures\npytest tests/ --maxfail=3\n\n# Extra-verbose output (shows full assertion diffs)\npytest tests/ -vv\n\n# Full traceback on failure (default is --tb=short)\npytest tests/ --tb=long\n\n# Show slowest 10 tests\npytest tests/ --durations=10\n\n# Run last-failed tests only\npytest tests/ --lf\n\n# Run failed-first, then the rest\npytest tests/ --ff\n</code></pre>"},{"location":"development/testing/#inspecting-docker-logs-integration-tests","title":"Inspecting Docker Logs (Integration Tests)","text":"<p>When integration tests fail, inspect the service logs:</p> <pre><code># View Zetherion AI bot logs\ndocker compose -p zetherion_ai-test logs zetherion-ai-bot\n\n# View Qdrant logs\ndocker compose -p zetherion_ai-test logs qdrant\n\n# View Ollama generation container logs\ndocker compose -p zetherion_ai-test logs ollama\n\n# View Ollama router container logs\ndocker compose -p zetherion_ai-test logs ollama-router\n\n# View PostgreSQL logs\ndocker compose -p zetherion_ai-test logs postgres\n\n# Follow all logs in real time\ndocker compose -p zetherion_ai-test logs -f\n</code></pre>"},{"location":"development/testing/#debugging-async-tests","title":"Debugging Async Tests","text":"<p>Async tests can be tricky. Common patterns:</p> <pre><code># Run a single async test with full output\npytest tests/unit/test_inference_broker.py::test_broker_retries_on_failure -s -vv\n\n# If you see \"RuntimeError: Event loop is closed\", ensure asyncio_mode = \"auto\"\n# in pyproject.toml and that you are not manually creating event loops.\n</code></pre>"},{"location":"development/testing/#best-practices","title":"Best Practices","text":""},{"location":"development/testing/#test-naming","title":"Test Naming","text":"<ul> <li>File: <code>test_&lt;module_name&gt;.py</code> (mirrors the source file name)</li> <li>Class: <code>Test&lt;ClassName&gt;</code> (optional -- flat functions are preferred)</li> <li>Function: <code>test_&lt;what_it_does&gt;</code> using plain English, not method names</li> <li>Good: <code>test_encryption_rejects_empty_passphrase</code></li> <li>Bad: <code>test_encrypt_1</code>, <code>test_it_works</code></li> </ul>"},{"location":"development/testing/#test-design","title":"Test Design","text":"<ul> <li>One assertion per concept. A test can have multiple <code>assert</code> statements, but they should all verify a single logical behavior.</li> <li>Mock external services. LLM APIs (<code>claude-sonnet-4-5-20250929</code>, <code>gpt-5.2</code>, <code>gemini-2.5-flash</code>), Discord, Qdrant, PostgreSQL, and Ollama (<code>llama3.2:3b</code>, <code>llama3.1:8b</code>) should all be mocked in unit tests.</li> <li>Do not test implementation details. Test the public interface, not internal method calls.</li> <li>Clean up resources. Use <code>yield</code> fixtures to guarantee teardown, especially for async clients and temporary files.</li> <li>Keep tests deterministic. Avoid random data, time-dependent assertions, or network calls in unit tests.</li> <li>Use parametrize for variants. If you are writing 5 tests that differ only by input, use <code>@pytest.mark.parametrize</code>.</li> </ul>"},{"location":"development/testing/#test-organization_1","title":"Test Organization","text":"<ul> <li>Each source module in <code>src/zetherion_ai/</code> should have a corresponding test file in <code>tests/unit/</code>.</li> <li>Integration tests live in <code>tests/integration/</code> and require the <code>@pytest.mark.integration</code> marker.</li> <li>Shared fixtures go in <code>tests/conftest.py</code>. Module-specific fixtures go in the test file itself.</li> </ul>"},{"location":"development/testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/testing/#import-errors","title":"Import Errors","text":"<p>Symptom: <code>ModuleNotFoundError: No module named 'zetherion_ai'</code></p> <pre><code># Ensure the package is installed in editable mode\npip install -e \".[dev]\"\n\n# Or verify pythonpath is set in pyproject.toml\n# [tool.pytest.ini_options]\n# pythonpath = [\"src\"]\n</code></pre>"},{"location":"development/testing/#docker-service-issues","title":"Docker Service Issues","text":"<p>Symptom: Integration tests fail with connection errors.</p> <pre><code># Verify Docker is running\ndocker info\n\n# Check that test containers are healthy\ndocker compose -p zetherion_ai-test ps\n\n# Verify no port conflicts (Qdrant: 6333, Ollama: 11434, PostgreSQL: 5432)\nlsof -i :6333\nlsof -i :11434\nlsof -i :5432\n\n# Clean up stale test containers\ndocker compose -p zetherion_ai-test down -v\n</code></pre>"},{"location":"development/testing/#async-test-pitfalls","title":"Async Test Pitfalls","text":"<p>Symptom: <code>RuntimeError: Event loop is closed</code> or <code>PytestUnraisableExceptionWarning</code></p> <ul> <li>Ensure <code>asyncio_mode = \"auto\"</code> is set in <code>pyproject.toml</code>.</li> <li>Do not use <code>asyncio.run()</code> inside test functions. Let pytest-asyncio manage the event loop.</li> <li>Use <code>AsyncMock</code> (not <code>Mock</code>) for coroutine return values.</li> </ul> <p>Symptom: <code>ScopeMismatch</code> when using session-scoped async fixtures</p> <ul> <li>Session-scoped async fixtures require <code>pytest-asyncio &gt;= 0.23</code> and <code>scope=\"session\"</code> on the fixture.</li> </ul>"},{"location":"development/testing/#coverage-gaps","title":"Coverage Gaps","text":"<p>Symptom: Coverage is lower than expected on a module you tested.</p> <pre><code># Check which lines are missing\npytest tests/unit/test_encryption.py --cov=src/zetherion_ai/security --cov-report=term-missing\n\n# Check if the coverage source is correct\n# Ensure [tool.coverage.run] source = [\"src/zetherion_ai\"]\n</code></pre> <p>Common causes: - Lines inside <code>if TYPE_CHECKING:</code> blocks (excluded by default). - Exception handlers that are hard to trigger. - Platform-specific code paths.</p>"},{"location":"development/testing/#settings-cache-interference","title":"Settings Cache Interference","text":"<p>Symptom: Tests pass individually but fail when run together.</p> <p>The <code>get_settings()</code> function uses <code>@lru_cache</code>. The <code>clear_settings_cache</code> autouse fixture clears it before and after each test, but if you import <code>get_settings</code> at module level, the cache may persist.</p> <pre><code># Bad: module-level import triggers caching\nfrom zetherion_ai.config import get_settings\nsettings = get_settings()  # Cached at import time\n\n# Good: call inside the test or fixture\ndef test_something():\n    from zetherion_ai.config import get_settings\n    settings = get_settings()\n</code></pre>"},{"location":"development/testing/#related-documentation","title":"Related Documentation","text":"<ul> <li>CI/CD Pipeline -- Pre-commit hooks, pre-push hooks, and GitHub Actions</li> <li>Architecture -- System design and component interactions</li> <li>Security -- Encryption, authentication, and threat model</li> </ul>"},{"location":"project/design-decisions/","title":"Design Decisions","text":"<p>Architecture decision records (ADRs) documenting key technical choices in Zetherion AI.</p>"},{"location":"project/design-decisions/#adr-001-postgresql-for-personal-understanding","title":"ADR-001: PostgreSQL for Personal Understanding","text":"<p>Date: 2026-02-07 Status: Accepted</p>"},{"location":"project/design-decisions/#context","title":"Context","text":"<p>Phase 9 introduced a personal understanding layer that stores structured user data: profiles, contacts, policies, and learnings. This data is relational (contacts relate to users, policies reference domains) and requires ACID transactions for consistency.</p>"},{"location":"project/design-decisions/#decision","title":"Decision","text":"<p>Use PostgreSQL 17 (Alpine) as a dedicated service for personal understanding data, alongside the existing Qdrant vector database.</p>"},{"location":"project/design-decisions/#alternatives-considered","title":"Alternatives Considered","text":"Option Pros Cons SQLite Simple, no service needed No concurrent writes, file locking issues in Docker Qdrant only Already deployed Poor fit for relational data, no transactions PostgreSQL ACID, relational, concurrent, mature Additional Docker service, more memory"},{"location":"project/design-decisions/#consequences","title":"Consequences","text":"<ul> <li>Added a 6th Docker service (postgres)</li> <li>asyncpg for non-blocking database access</li> <li>RBAC support (owner, admin, user roles) with proper foreign keys</li> <li>Clear separation: Qdrant for vectors/semantic search, PostgreSQL for structured relational data</li> </ul>"},{"location":"project/design-decisions/#adr-002-progressive-trust-system-for-gmail","title":"ADR-002: Progressive Trust System for Gmail","text":"<p>Date: 2026-02-07 Status: Accepted</p>"},{"location":"project/design-decisions/#context_1","title":"Context","text":"<p>Gmail integration requires sending emails on behalf of users. Blindly auto-sending could cause embarrassment or damage. Users need to build confidence in the system before granting autonomy.</p>"},{"location":"project/design-decisions/#decision_1","title":"Decision","text":"<p>Implement a two-dimensional trust system:</p> <ol> <li>Per-contact trust: How much the user trusts the bot with a specific contact</li> <li>Per-type trust: How much the user trusts the bot with a type of reply (acknowledgment vs. sensitive)</li> </ol> <p>The effective trust is: <code>min(type_trust, contact_trust, reply_type_ceiling)</code></p> <p>Auto-send only occurs when effective trust &gt;= 0.85 AND confidence &gt;= 0.85.</p>"},{"location":"project/design-decisions/#alternatives-considered_1","title":"Alternatives Considered","text":"Option Pros Cons Binary on/off Simple Too coarse, all-or-nothing Single trust score Moderate complexity Cannot distinguish \"safe to auto-ack\" from \"safe to negotiate\" Two-dimensional trust Granular control More complex, requires ceiling system"},{"location":"project/design-decisions/#consequences_1","title":"Consequences","text":"<ul> <li>Trust evolves gradually: +0.05 per approval, -0.20 per rejection</li> <li>Global cap of 0.95 (never fully autonomous)</li> <li>8 reply type ceilings (ACKNOWLEDGMENT 0.95 down to SENSITIVE 0.30)</li> <li>Users naturally progress: read-only -&gt; draft with approval -&gt; auto-draft -&gt; auto-send</li> </ul>"},{"location":"project/design-decisions/#adr-003-distroless-container-images","title":"ADR-003: Distroless Container Images","text":"<p>Date: 2026-02-07 Status: Accepted</p>"},{"location":"project/design-decisions/#context_2","title":"Context","text":"<p>The bot and skills containers need to be secure by default. Traditional Python images include shells, package managers, and utilities that expand the attack surface.</p>"},{"location":"project/design-decisions/#decision_2","title":"Decision","text":"<p>Use distroless base images (Chainguard Python) for the bot and skills service containers.</p>"},{"location":"project/design-decisions/#alternatives-considered_2","title":"Alternatives Considered","text":"Option Pros Cons python:3.12-slim Familiar, debuggable Includes shell, package manager, ~150MB Alpine-based Small (~50MB) musl libc compatibility issues with some Python packages Distroless Minimal attack surface, ~50MB, 0 CVEs No shell for debugging, harder to inspect"},{"location":"project/design-decisions/#consequences_2","title":"Consequences","text":"<ul> <li>Runtime images contain only Python interpreter and application code</li> <li>No shell access in production (use <code>docker cp</code> + external tools for debugging)</li> <li>Read-only root filesystem with tmpfs for <code>/tmp</code></li> <li>Combined with <code>no-new-privileges</code> and resource limits</li> </ul>"},{"location":"project/design-decisions/#adr-004-dual-ollama-architecture","title":"ADR-004: Dual Ollama Architecture","text":"<p>Date: 2026-02-07 Status: Accepted</p>"},{"location":"project/design-decisions/#context_3","title":"Context","text":"<p>Ollama supports only one loaded model at a time efficiently. The system needs two models: a small router model (llama3.2:3b) for fast intent classification and a larger generation model (llama3.1:8b) for responses. Model swapping between requests causes delays.</p>"},{"location":"project/design-decisions/#decision_3","title":"Decision","text":"<p>Run two separate Ollama containers, each dedicated to one model.</p>"},{"location":"project/design-decisions/#alternatives-considered_3","title":"Alternatives Considered","text":"Option Pros Cons Single Ollama (swap models) Less resources 5-15s delay per model swap Single Ollama (both loaded) No swap delay Requires 2x memory, Ollama manages poorly Two Ollama containers Dedicated resources, no swapping More Docker services, more memory"},{"location":"project/design-decisions/#consequences_3","title":"Consequences","text":"<ul> <li><code>zetherion-ai-ollama</code>: Generation model (llama3.1:8b) on port 11434</li> <li><code>zetherion-ai-ollama-router</code>: Router model (llama3.2:3b) on port 11435</li> <li>Each container has dedicated memory limits</li> <li>Zero model-swap latency</li> <li>Total memory: ~6.7GB for both (4.7GB generation + 2.0GB router)</li> </ul>"},{"location":"project/design-decisions/#adr-005-skills-framework-with-rest-api","title":"ADR-005: Skills Framework with REST API","text":"<p>Date: 2026-02-06 Status: Accepted</p>"},{"location":"project/design-decisions/#context_4","title":"Context","text":"<p>Skills (tasks, calendar, Gmail, GitHub) need to be modular and potentially run in isolation. The bot core should not have hard dependencies on skill implementations.</p>"},{"location":"project/design-decisions/#decision_4","title":"Decision","text":"<p>Implement skills as a separate Docker service with a REST API (aiohttp on port 8080). Skills communicate with the bot via HTTP with HMAC authentication.</p>"},{"location":"project/design-decisions/#alternatives-considered_4","title":"Alternatives Considered","text":"Option Pros Cons In-process plugins Simple, fast Tight coupling, crashes affect bot gRPC service Typed contracts, streaming Complex setup, code generation REST API Standard, debuggable, language-agnostic HTTP overhead, no streaming Message queue (Redis/RabbitMQ) Decoupled, async Additional infrastructure, complexity"},{"location":"project/design-decisions/#consequences_4","title":"Consequences","text":"<ul> <li>Skills run in a separate container with their own lifecycle</li> <li>Authentication via <code>X-API-Secret</code> HMAC header</li> <li>Abstract <code>Skill</code> base class with <code>handle()</code>, <code>initialize()</code>, <code>on_heartbeat()</code></li> <li>15 granular permissions for access control</li> <li>SkillRegistry routes intents to the correct skill</li> <li>New skills can be added without modifying the bot core</li> </ul>"},{"location":"project/design-decisions/#adr-006-aes-256-gcm-for-memory-encryption","title":"ADR-006: AES-256-GCM for Memory Encryption","text":"<p>Date: 2026-02-06 Status: Accepted</p>"},{"location":"project/design-decisions/#context_5","title":"Context","text":"<p>Qdrant stores user conversations as vector embeddings with payload metadata. This payload can contain sensitive information (names, locations, preferences). Data at rest should be encrypted.</p>"},{"location":"project/design-decisions/#decision_5","title":"Decision","text":"<p>Field-level encryption using AES-256-GCM with PBKDF2-HMAC-SHA256 key derivation (600,000 iterations, 32-byte random salt per encryption operation).</p>"},{"location":"project/design-decisions/#alternatives-considered_5","title":"Alternatives Considered","text":"Option Pros Cons No encryption Simple Data readable if Qdrant compromised Full-disk encryption Transparent Doesn't protect against application-level access AES-256-CBC Well-known No authentication, vulnerable to padding oracle AES-256-GCM Authenticated encryption, tamper detection Slightly more complex"},{"location":"project/design-decisions/#consequences_5","title":"Consequences","text":"<ul> <li>Each encrypted field includes: nonce (12 bytes) + ciphertext + auth tag (16 bytes) + salt (32 bytes)</li> <li>Key derived from user-provided passphrase via PBKDF2</li> <li>Encryption is optional (controlled by <code>ENCRYPTION_ENABLED</code> flag)</li> <li>Performance impact: ~1-2ms per encrypt/decrypt operation</li> <li>Vectors themselves are NOT encrypted (would break similarity search)</li> </ul>"},{"location":"project/design-decisions/#adr-007-multi-provider-llm-routing","title":"ADR-007: Multi-Provider LLM Routing","text":"<p>Date: 2026-02-06 Status: Accepted</p>"},{"location":"project/design-decisions/#context_6","title":"Context","text":"<p>Different LLM providers excel at different tasks. Claude is strong at code, OpenAI at reasoning, Gemini at long documents, and Ollama provides privacy. A single provider would be suboptimal.</p>"},{"location":"project/design-decisions/#decision_6","title":"Decision","text":"<p>Implement an InferenceBroker that routes requests to the best provider based on task type, with automatic fallback chains.</p>"},{"location":"project/design-decisions/#routing-matrix","title":"Routing Matrix","text":"Task Type Primary Fallback 1 Fallback 2 Code generation Claude OpenAI Gemini Complex reasoning OpenAI Claude Gemini Long document analysis Gemini Claude OpenAI Simple queries Gemini/Ollama - - Routing/classification Ollama/Gemini - -"},{"location":"project/design-decisions/#consequences_6","title":"Consequences","text":"<ul> <li>16 distinct TaskTypes for granular routing</li> <li>Provider capability matrix determines routing</li> <li>Automatic fallback when primary is unavailable or rate-limited</li> <li>Cost tracking per provider and task type</li> <li>Users can override with environment variables</li> </ul>"},{"location":"project/design-decisions/#adr-008-observation-pipeline-for-implicit-learning","title":"ADR-008: Observation Pipeline for Implicit Learning","text":"<p>Date: 2026-02-07 Status: Accepted</p>"},{"location":"project/design-decisions/#context_7","title":"Context","text":"<p>Users share information implicitly during conversations (\"I'm heading to Melbourne next week\", \"Working on the API migration\"). Extracting and storing this knowledge without explicit profile commands improves the user experience.</p>"},{"location":"project/design-decisions/#decision_7","title":"Decision","text":"<p>Implement a background observation pipeline that runs after each response, extracting implicit information using tiered inference.</p>"},{"location":"project/design-decisions/#tiers","title":"Tiers","text":"Tier Method Speed Confidence 1 Regex patterns ~1ms High (0.85-0.95) 2 LLM-based extraction ~500ms Medium (0.50-0.75)"},{"location":"project/design-decisions/#consequences_7","title":"Consequences","text":"<ul> <li>Extraction runs asynchronously (does not delay responses)</li> <li>Low-confidence extractions require user confirmation</li> <li>Confidence decays over time if not reinforced (-10% at 30 days, -20% at 90 days)</li> <li>Users can disable observation entirely (<code>PROFILE_INFERENCE_ENABLED=false</code>)</li> <li>All learned data is exportable and deletable (GDPR compliance)</li> </ul> <p>Last Updated: 2026-02-08</p>"},{"location":"project/roadmap/","title":"Roadmap","text":"<p>Current status and future plans for Zetherion AI.</p>"},{"location":"project/roadmap/#completed-phases","title":"Completed Phases","text":""},{"location":"project/roadmap/#phase-1-4-foundation-complete","title":"Phase 1-4: Foundation (Complete)","text":"Phase Feature Status 1 Core agent with Discord as first input interface and dual LLM backends (Gemini + Ollama) Complete 2 Message routing with intent classification Complete 3 Qdrant vector memory with semantic search Complete 4 Security controls (rate limiting, allowlist, prompt injection) Complete"},{"location":"project/roadmap/#phase-5-core-intelligence-complete","title":"Phase 5: Core Intelligence (Complete)","text":"Sub-Phase Feature Status 5A AES-256-GCM encryption layer Complete 5B InferenceBroker multi-provider routing Complete 5B.1 Model registry and cost tracking Complete 5C User profile system with tiered inference Complete 5C.1 Employment profile and trust levels Complete 5D Skills framework with permissions Complete 5E Built-in skills (tasks, calendar, profile) Complete 5F Heartbeat scheduler Complete 5G Router enhancement for skill intents Complete"},{"location":"project/roadmap/#phase-6-docker-hardening-complete","title":"Phase 6: Docker Hardening (Complete)","text":"<ul> <li>Distroless base images for bot and skills containers</li> <li>Read-only root filesystem, no-new-privileges on all containers</li> <li>Resource limits (CPU and memory) for all services</li> <li>Dual Ollama architecture (separate router and generation containers)</li> <li>Health checks on all 6 services</li> </ul>"},{"location":"project/roadmap/#phase-7-github-integration-complete","title":"Phase 7: GitHub Integration (Complete)","text":"<ul> <li>GitHub skill with 18 intents for repository management</li> <li>Issue and PR management (list, view, create, close, merge)</li> <li>Three autonomy levels with safety-first defaults</li> </ul>"},{"location":"project/roadmap/#phase-8-gmail-integration-complete","title":"Phase 8: Gmail Integration (Complete)","text":"<ul> <li>12-file Gmail module with full email management</li> <li>Two-dimensional progressive trust system (per-contact + per-type)</li> <li>OAuth account management with encrypted token storage</li> <li>Reply draft pipeline, digest generation, email analytics</li> <li>Observation pipeline for implicit knowledge extraction</li> </ul>"},{"location":"project/roadmap/#phase-9-personal-understanding-complete","title":"Phase 9: Personal Understanding (Complete)","text":"<ul> <li>PostgreSQL-backed personal model (profiles, contacts, policies, learnings)</li> <li>Communication style adaptation (formality, verbosity, directness, proactivity)</li> <li>Contact graph with relationship tracking</li> <li>Policy system with configurable autonomy modes</li> </ul>"},{"location":"project/roadmap/#current-state","title":"Current State","text":"Metric Value Source files 91 Python files Test files 89 Total tests 3,000+ Coverage 93%+ Docker services 6 Skills 6 built-in (tasks, calendar, profile, gmail, github, personal)"},{"location":"project/roadmap/#future-directions","title":"Future Directions","text":"<p>The following areas are under consideration for future development. These are ideas, not commitments -- priorities may shift based on usage patterns and community feedback.</p>"},{"location":"project/roadmap/#voice-integration","title":"Voice Integration","text":"<ul> <li>Discord voice channel support</li> <li>Speech-to-text and text-to-speech</li> <li>Voice-triggered commands and responses</li> </ul>"},{"location":"project/roadmap/#multi-tenant-api","title":"Multi-Tenant API","text":"<ul> <li>Public REST API for additional input sources and third-party integrations</li> <li>Multi-user authentication and authorization</li> <li>API rate limiting and usage tracking per tenant</li> </ul>"},{"location":"project/roadmap/#enhanced-observation","title":"Enhanced Observation","text":"<ul> <li>Deeper behavioral pattern recognition</li> <li>Cross-platform activity correlation</li> <li>Proactive insight generation based on observed patterns</li> </ul>"},{"location":"project/roadmap/#additional-integrations","title":"Additional Integrations","text":"<ul> <li>Slack bot adapter</li> <li>Telegram bot adapter</li> <li>Microsoft Teams integration</li> <li>Jira/Linear issue tracking</li> <li>Notion/Confluence document management</li> </ul>"},{"location":"project/roadmap/#advanced-memory","title":"Advanced Memory","text":"<ul> <li>Hierarchical memory with forgetting curves</li> <li>Cross-user knowledge sharing (opt-in)</li> <li>Memory compression and summarization</li> <li>Temporal awareness (time-sensitive memories)</li> </ul>"},{"location":"project/roadmap/#improved-routing","title":"Improved Routing","text":"<ul> <li>Learning-based router that adapts to query patterns</li> <li>Cost-aware routing with automatic budget optimization</li> <li>Latency-aware provider selection</li> </ul>"},{"location":"project/roadmap/#self-improvement","title":"Self-Improvement","text":"<ul> <li>Automated feedback collection from user interactions</li> <li>Response quality scoring</li> <li>A/B testing of different response strategies</li> </ul>"},{"location":"project/roadmap/#contributing-ideas","title":"Contributing Ideas","text":"<p>Have a feature request or idea? The best ways to contribute:</p> <ol> <li>Open a GitHub Issue with a feature proposal</li> <li>Start a GitHub Discussion for broader ideas</li> <li>Submit a PR with an implementation (see Adding a Skill for extending capabilities)</li> </ol> <p>Last Updated: 2026-02-08</p>"},{"location":"technical/api-reference/","title":"Skills REST API Reference","text":""},{"location":"technical/api-reference/#overview","title":"Overview","text":"<p>The Skills Service exposes a REST API on port 8080, accessible only within the internal Docker network. This API is consumed by the bot service to dispatch skill requests, trigger heartbeat actions, manage users, and query skill state. All endpoints except <code>/health</code> require authentication via the <code>X-API-Secret</code> header.</p> <p>Base URL: <code>http://zetherion-ai-skills:8080</code> (Docker internal network only)</p>"},{"location":"technical/api-reference/#authentication","title":"Authentication","text":"<p>All endpoints except <code>/health</code> require the <code>X-API-Secret</code> header. The value is compared against the configured secret using HMAC constant-time comparison to prevent timing attacks.</p> <pre><code>X-API-Secret: your-skills-api-secret\n</code></pre> <p>Configure the secret via the <code>SKILLS_API_SECRET</code> environment variable in your <code>.env</code> file. Requests without a valid secret receive a <code>401 Unauthorized</code> response.</p>"},{"location":"technical/api-reference/#health-and-status","title":"Health and Status","text":""},{"location":"technical/api-reference/#get-health","title":"GET /health","text":"<p>Returns service health status. Does not require authentication. Used by Docker HEALTHCHECK and load balancers.</p> <p>Response 200:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"skills_ready\": 5,\n  \"skills_total\": 5\n}\n</code></pre> <p>If any skills failed to initialize, <code>skills_ready</code> will be less than <code>skills_total</code>. The endpoint still returns 200 as long as the service itself is running.</p>"},{"location":"technical/api-reference/#get-status","title":"GET /status","text":"<p>Returns detailed status information for each registered skill.</p> <p>Response 200:</p> <pre><code>{\n  \"status\": \"running\",\n  \"skills\": {\n    \"task_manager\": \"ready\",\n    \"calendar\": \"ready\",\n    \"profile\": \"ready\",\n    \"gmail\": \"ready\",\n    \"github_management\": \"ready\"\n  }\n}\n</code></pre> <p>Possible skill statuses: <code>ready</code>, <code>initializing</code>, <code>failed</code>, <code>disabled</code>.</p>"},{"location":"technical/api-reference/#get-skills","title":"GET /skills","text":"<p>List all registered skills with their metadata.</p> <p>Response 200:</p> <pre><code>{\n  \"skills\": [\n    {\n      \"name\": \"task_manager\",\n      \"description\": \"Track tasks and todos\",\n      \"version\": \"1.0.0\",\n      \"intents\": [\"create_task\", \"list_tasks\", \"complete_task\", \"delete_task\", \"task_summary\"]\n    },\n    {\n      \"name\": \"gmail\",\n      \"description\": \"Email management with multi-account support\",\n      \"version\": \"1.0.0\",\n      \"intents\": [\"email_check\", \"email_unread\", \"email_drafts\", \"email_digest\", \"email_status\", \"email_search\", \"email_calendar\"]\n    },\n    {\n      \"name\": \"github_management\",\n      \"description\": \"GitHub repository management with configurable autonomy\",\n      \"version\": \"1.0.0\",\n      \"intents\": [\"list_issues\", \"get_issue\", \"create_issue\", \"update_issue\", \"close_issue\", \"reopen_issue\", \"add_label\", \"remove_label\", \"add_comment\", \"list_prs\", \"get_pr\", \"get_pr_diff\", \"merge_pr\", \"list_workflows\", \"rerun_workflow\", \"get_repo_info\", \"set_autonomy\", \"get_autonomy\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"technical/api-reference/#get-skillsname","title":"GET /skills/{name}","text":"<p>Get metadata for a specific skill by name.</p> <p>Response 200:</p> <pre><code>{\n  \"name\": \"task_manager\",\n  \"description\": \"Track tasks and todos\",\n  \"version\": \"1.0.0\",\n  \"intents\": [\"create_task\", \"list_tasks\", \"complete_task\", \"delete_task\", \"task_summary\"]\n}\n</code></pre> <p>Response 404:</p> <pre><code>{\n  \"error\": \"Skill not found: unknown_skill\"\n}\n</code></pre>"},{"location":"technical/api-reference/#skill-handling","title":"Skill Handling","text":""},{"location":"technical/api-reference/#post-handle","title":"POST /handle","text":"<p>Execute a skill request. This is the primary endpoint used by the bot service to dispatch classified user intents to the appropriate skill.</p> <p>Request:</p> <pre><code>{\n  \"skill_name\": \"gmail\",\n  \"user_id\": \"123456789\",\n  \"params\": {\n    \"intent\": \"email_check\",\n    \"message\": \"check my email\"\n  }\n}\n</code></pre> Field Type Required Description <code>skill_name</code> string Yes Target skill identifier <code>user_id</code> string Yes Discord user ID of the requester <code>params.intent</code> string Yes Classified intent name <code>params.message</code> string Yes Original user message <p>Response 200:</p> <pre><code>{\n  \"skill_name\": \"gmail\",\n  \"status\": \"success\",\n  \"result\": {\n    \"message\": \"You have 3 new emails since your last check.\",\n    \"data\": {\n      \"total_emails\": 15,\n      \"unread_count\": 3\n    }\n  }\n}\n</code></pre> <p>Response 404 (skill not found):</p> <pre><code>{\n  \"error\": \"Skill not found: unknown_skill\"\n}\n</code></pre> <p>Response 500 (skill error):</p> <pre><code>{\n  \"error\": \"Internal server error\",\n  \"detail\": \"Gmail API connection timed out\"\n}\n</code></pre>"},{"location":"technical/api-reference/#post-heartbeat","title":"POST /heartbeat","text":"<p>Trigger heartbeat actions for the specified users. The scheduler calls this endpoint periodically. Each skill's <code>on_heartbeat()</code> method is invoked, and resulting actions are aggregated and returned sorted by priority.</p> <p>Request:</p> <pre><code>{\n  \"user_ids\": [\"123456789\", \"987654321\"]\n}\n</code></pre> Field Type Required Description <code>user_ids</code> list[string] Yes Discord user IDs to generate actions for <p>Response 200:</p> <pre><code>{\n  \"actions\": [\n    {\n      \"skill_name\": \"gmail\",\n      \"action_type\": \"send_message\",\n      \"user_id\": \"123456789\",\n      \"data\": {\n        \"type\": \"email_digest\",\n        \"summary\": \"3 unread emails in your primary inbox\"\n      },\n      \"priority\": 3\n    },\n    {\n      \"skill_name\": \"task_manager\",\n      \"action_type\": \"send_message\",\n      \"user_id\": \"123456789\",\n      \"data\": {\n        \"type\": \"overdue_reminder\",\n        \"task_count\": 2\n      },\n      \"priority\": 2\n    }\n  ]\n}\n</code></pre> <p>Actions are returned sorted by priority (1 = highest). The bot service is responsible for executing the actions (e.g., sending Discord messages) and respecting quiet hours.</p>"},{"location":"technical/api-reference/#intent-and-context","title":"Intent and Context","text":""},{"location":"technical/api-reference/#get-intents","title":"GET /intents","text":"<p>List all registered intents and their skill mappings. Useful for debugging routing and verifying that skills are correctly registered.</p> <p>Response 200:</p> <pre><code>{\n  \"intents\": {\n    \"email_check\": \"gmail\",\n    \"email_unread\": \"gmail\",\n    \"email_drafts\": \"gmail\",\n    \"email_digest\": \"gmail\",\n    \"email_status\": \"gmail\",\n    \"email_search\": \"gmail\",\n    \"email_calendar\": \"gmail\",\n    \"list_issues\": \"github_management\",\n    \"get_issue\": \"github_management\",\n    \"create_issue\": \"github_management\",\n    \"create_task\": \"task_manager\",\n    \"list_tasks\": \"task_manager\",\n    \"complete_task\": \"task_manager\",\n    \"delete_task\": \"task_manager\",\n    \"task_summary\": \"task_manager\",\n    \"check_schedule\": \"calendar\",\n    \"work_hours\": \"calendar\",\n    \"availability\": \"calendar\",\n    \"show_profile\": \"profile\",\n    \"update_profile\": \"profile\",\n    \"delete_profile\": \"profile\",\n    \"export_data\": \"profile\"\n  }\n}\n</code></pre>"},{"location":"technical/api-reference/#get-prompt-fragments","title":"GET /prompt-fragments","text":"<p>Get system prompt context contributions from all skills for a specific user.</p> <p>Query Parameters:</p> Parameter Type Required Description <code>user_id</code> string Yes The user ID to generate fragments for <p>Example: <code>GET /prompt-fragments?user_id=123456789</code></p> <p>Response 200:</p> <pre><code>{\n  \"fragments\": [\n    \"[GitHub: 2 action(s) pending confirmation]\",\n    \"[Tasks: 3 open, 1 overdue]\",\n    \"[Gmail: 5 unread across 2 accounts]\",\n    \"[Calendar: Next meeting in 45 minutes]\"\n  ]\n}\n</code></pre> <p>Skills that return <code>None</code> from <code>get_system_prompt_fragment()</code> are excluded from the response.</p>"},{"location":"technical/api-reference/#user-management","title":"User Management","text":""},{"location":"technical/api-reference/#get-users","title":"GET /users","text":"<p>List registered users. Supports optional role filtering.</p> <p>Query Parameters:</p> Parameter Type Required Description <code>role</code> string No Filter by role (<code>admin</code>, <code>user</code>) <p>Example: <code>GET /users?role=admin</code></p> <p>Response 200:</p> <pre><code>{\n  \"users\": [\n    {\n      \"user_id\": \"123456789\",\n      \"role\": \"admin\",\n      \"added_at\": \"2026-01-15T10:30:00Z\",\n      \"added_by\": \"system\"\n    },\n    {\n      \"user_id\": \"987654321\",\n      \"role\": \"user\",\n      \"added_at\": \"2026-02-01T14:00:00Z\",\n      \"added_by\": \"123456789\"\n    }\n  ]\n}\n</code></pre>"},{"location":"technical/api-reference/#post-users","title":"POST /users","text":"<p>Add a new user to the system.</p> <p>Request:</p> <pre><code>{\n  \"user_id\": \"123456789\",\n  \"role\": \"user\",\n  \"added_by\": \"987654321\"\n}\n</code></pre> Field Type Required Description <code>user_id</code> string Yes Discord user ID to add <code>role</code> string Yes Role assignment (<code>admin</code> or <code>user</code>) <code>added_by</code> string Yes Discord user ID of the admin performing the action <p>Response 201:</p> <pre><code>{\n  \"ok\": true\n}\n</code></pre> <p>Response 409 (user already exists):</p> <pre><code>{\n  \"error\": \"User already exists: 123456789\"\n}\n</code></pre>"},{"location":"technical/api-reference/#delete-usersuser_id","title":"DELETE /users/{user_id}","text":"<p>Remove a user from the system.</p> <p>Query Parameters:</p> Parameter Type Required Description <code>removed_by</code> string Yes Discord user ID of the admin performing the removal <p>Example: <code>DELETE /users/123456789?removed_by=987654321</code></p> <p>Response 200:</p> <pre><code>{\n  \"ok\": true\n}\n</code></pre> <p>Response 404:</p> <pre><code>{\n  \"error\": \"User not found: 123456789\"\n}\n</code></pre>"},{"location":"technical/api-reference/#patch-usersuser_idrole","title":"PATCH /users/{user_id}/role","text":"<p>Change a user's role.</p> <p>Request:</p> <pre><code>{\n  \"role\": \"admin\",\n  \"changed_by\": \"987654321\"\n}\n</code></pre> Field Type Required Description <code>role</code> string Yes New role (<code>admin</code> or <code>user</code>) <code>changed_by</code> string Yes Discord user ID of the admin making the change <p>Response 200:</p> <pre><code>{\n  \"ok\": true,\n  \"user_id\": \"123456789\",\n  \"role\": \"admin\"\n}\n</code></pre>"},{"location":"technical/api-reference/#get-usersaudit","title":"GET /users/audit","text":"<p>Get recent audit log entries for user management actions.</p> <p>Query Parameters:</p> Parameter Type Required Description <code>limit</code> integer No Maximum entries to return (default: 50, max: 500) <p>Example: <code>GET /users/audit?limit=50</code></p> <p>Response 200:</p> <pre><code>{\n  \"entries\": [\n    {\n      \"timestamp\": \"2026-02-07T14:30:00Z\",\n      \"action\": \"role_change\",\n      \"user_id\": \"123456789\",\n      \"performed_by\": \"987654321\",\n      \"details\": {\n        \"old_role\": \"user\",\n        \"new_role\": \"admin\"\n      }\n    },\n    {\n      \"timestamp\": \"2026-02-07T10:00:00Z\",\n      \"action\": \"user_added\",\n      \"user_id\": \"555666777\",\n      \"performed_by\": \"987654321\",\n      \"details\": {\n        \"role\": \"user\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"technical/api-reference/#settings-management","title":"Settings Management","text":""},{"location":"technical/api-reference/#get-settings","title":"GET /settings","text":"<p>List all settings. Supports optional namespace filtering.</p> <p>Query Parameters:</p> Parameter Type Required Description <code>namespace</code> string No Filter by settings namespace (e.g., <code>gmail</code>, <code>github</code>, <code>cost_tracking</code>) <p>Example: <code>GET /settings?namespace=gmail</code></p> <p>Response 200:</p> <pre><code>{\n  \"settings\": [\n    {\n      \"namespace\": \"gmail\",\n      \"key\": \"digest_enabled\",\n      \"value\": \"true\",\n      \"data_type\": \"bool\",\n      \"updated_at\": \"2026-02-07T10:00:00Z\",\n      \"updated_by\": \"123456789\"\n    },\n    {\n      \"namespace\": \"gmail\",\n      \"key\": \"digest_hour\",\n      \"value\": \"9\",\n      \"data_type\": \"int\",\n      \"updated_at\": \"2026-02-05T08:00:00Z\",\n      \"updated_by\": \"123456789\"\n    }\n  ]\n}\n</code></pre>"},{"location":"technical/api-reference/#get-settingsnamespacekey","title":"GET /settings/{namespace}/{key}","text":"<p>Get a specific setting value.</p> <p>Example: <code>GET /settings/gmail/digest_enabled</code></p> <p>Response 200:</p> <pre><code>{\n  \"namespace\": \"gmail\",\n  \"key\": \"digest_enabled\",\n  \"value\": \"true\",\n  \"data_type\": \"bool\",\n  \"updated_at\": \"2026-02-07T10:00:00Z\",\n  \"updated_by\": \"123456789\"\n}\n</code></pre> <p>Response 404:</p> <pre><code>{\n  \"error\": \"Setting not found: gmail/unknown_key\"\n}\n</code></pre>"},{"location":"technical/api-reference/#put-settingsnamespacekey","title":"PUT /settings/{namespace}/{key}","text":"<p>Update a setting value. Creates the setting if it does not exist.</p> <p>Request:</p> <pre><code>{\n  \"value\": \"true\",\n  \"changed_by\": \"123456789\",\n  \"data_type\": \"bool\"\n}\n</code></pre> Field Type Required Description <code>value</code> string Yes Setting value (stored as string, interpreted by <code>data_type</code>) <code>changed_by</code> string Yes Discord user ID making the change <code>data_type</code> string Yes Value type: <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>json</code> <p>Response 200:</p> <pre><code>{\n  \"ok\": true,\n  \"namespace\": \"gmail\",\n  \"key\": \"digest_enabled\",\n  \"value\": \"true\"\n}\n</code></pre>"},{"location":"technical/api-reference/#delete-settingsnamespacekey","title":"DELETE /settings/{namespace}/{key}","text":"<p>Remove a setting override, reverting to its default value.</p> <p>Query Parameters:</p> Parameter Type Required Description <code>deleted_by</code> string Yes Discord user ID performing the deletion <p>Example: <code>DELETE /settings/gmail/digest_enabled?deleted_by=123456789</code></p> <p>Response 200:</p> <pre><code>{\n  \"ok\": true,\n  \"reverted_to_default\": true\n}\n</code></pre> <p>Response 404:</p> <pre><code>{\n  \"error\": \"Setting not found: gmail/unknown_key\"\n}\n</code></pre>"},{"location":"technical/api-reference/#error-responses","title":"Error Responses","text":"<p>All error responses follow a consistent format:</p> Status Code Meaning Example 401 Missing or invalid <code>X-API-Secret</code> header <code>{\"error\": \"Unauthorized\"}</code> 404 Requested resource not found <code>{\"error\": \"Skill not found: xyz\"}</code> 409 Conflict (e.g., duplicate user) <code>{\"error\": \"User already exists: 123456789\"}</code> 422 Invalid request body <code>{\"error\": \"Validation error\", \"detail\": \"skill_name is required\"}</code> 500 Internal server error <code>{\"error\": \"Internal server error\", \"detail\": \"Connection refused\"}</code> <p>All 4xx and 5xx responses include an <code>error</code> field. The <code>detail</code> field is included when additional context is available.</p>"},{"location":"technical/api-reference/#rate-limits","title":"Rate Limits","text":"<p>The API does not enforce its own rate limits, but the bot service applies rate limiting at the user level before making API calls. Refer to the bot configuration for rate limit settings:</p> <pre><code>RATE_LIMIT_MESSAGES=5\nRATE_LIMIT_WINDOW=60\n</code></pre>"},{"location":"technical/api-reference/#related-docs","title":"Related Docs","text":"<ul> <li>skills-framework.md -- Skill architecture, lifecycle, and development guide</li> <li>architecture.md -- Overall system architecture and service topology</li> <li>security.md -- Authentication, secrets management, and access control</li> </ul> <p>Last Updated: 2026-02-10 Version: 4.0.0 (Skills REST API)</p>"},{"location":"technical/architecture/","title":"System Architecture","text":""},{"location":"technical/architecture/#overview","title":"Overview","text":"<p>Zetherion AI is a source-agnostic personal AI assistant built on a microservice architecture with 6 Docker services. The system accepts input from any source (Discord is the first interface, with REST API, email sync, and webhooks also available) and provides user-controlled multi-provider LLM routing, AES-256-GCM encrypted semantic memory, Gmail integration, GitHub management, and deep personal understanding through passive observation, proactive prompting, and explicit learning.</p> <p>The codebase comprises 91 source files with 3,000+ tests across 89 test files, maintaining 93%+ code coverage. The architecture prioritizes security, modularity, and cost-efficient inference by routing queries to the most appropriate LLM provider based on complexity, privacy requirements, and task type.</p>"},{"location":"technical/architecture/#key-design-principles","title":"Key Design Principles","text":"<ol> <li>Security-First -- Defense in depth from container to application layer</li> <li>Modularity -- Clean separation across services (Bot, Skills, Storage)</li> <li>Cost Efficiency -- Intelligent routing sends simple queries to cheap/local models</li> <li>Privacy-Aware -- Local inference via Ollama for sensitive operations</li> <li>Resilience -- Fallback chains, retry logic, graceful degradation</li> <li>Async-First -- Non-blocking I/O throughout the entire stack</li> </ol>"},{"location":"technical/architecture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>Any Input Source\n(Discord / REST API / Email / Webhooks)\n    |\n    v\n+---[Bot Service]---+\n|  Security Layer   |---&gt; Prompt Injection Detection (17 regex patterns)\n|  (rate limit,     |---&gt; User Allowlist / RBAC\n|   auth)           |\n|                   |\n|  Agent Core       |---&gt; InferenceBroker\n|   - Router        |     |-&gt; Gemini 2.5 Flash      (simple/routing)\n|   - Providers     |     |-&gt; Claude Sonnet 4.5      (complex reasoning)\n|   - Context       |     |-&gt; GPT-5.2               (alternative complex)\n|                   |     |-&gt; Ollama llama3.1:8b     (local/private)\n|                   |     |-&gt; Ollama llama3.2:3b     (router classification)\n+--------+----------+\n         |\n    +----+----+\n    |         |\n    v         v\n+-------+  +--------+\n|Skills |  |Memory  |\n|Service|  |Layer   |\n+---+---+  +---+----+\n    |          |\n    v          v\n+-------+  +-------+  +----------+\n|Gmail  |  |Qdrant |  |PostgreSQL|\n|GitHub |  |(vectors|  |(users,   |\n|Tasks  |  | memory)|  | contacts,|\n|Calendar| |        |  | policies)|\n|Profile|  +-------+  +----------+\n+-------+\n</code></pre>"},{"location":"technical/architecture/#service-architecture","title":"Service Architecture","text":""},{"location":"technical/architecture/#bot-service","title":"Bot Service","text":"<p>The Bot Service is the primary entry point for user interactions. Discord is the first supported interface, but the service orchestrates the entire request lifecycle independently of the input source. The agent core, security layer, router, and inference broker all operate on messages regardless of origin.</p> <p>Core Responsibilities:</p> <ul> <li> <p>Input Gateway -- Currently connects to Discord via the gateway protocol using <code>discord.py</code>. Handles direct messages, @mentions, and slash commands. The architecture supports additional input sources (REST API, email, webhooks) through the same agent pipeline.</p> </li> <li> <p>Security Layer -- Three-stage defense applied to every incoming message before any processing occurs:</p> </li> <li>User Allowlist: Only pre-authorized Discord user IDs may interact with the bot. Supports RBAC with owner, admin, and user roles stored in PostgreSQL.</li> <li>Rate Limiting: Per-user message throttling (configurable, default 10 messages per 60 seconds) to prevent abuse and runaway API costs.</li> <li> <p>Prompt Injection Detection: 17 compiled regex patterns that scan for known injection techniques including role override attempts, delimiter injection, and Unicode obfuscation.</p> </li> <li> <p>Agent Core -- Manages the full conversation flow: context assembly, provider selection, response generation, and post-response observation. Handles retry logic with exponential backoff (max 3 retries) for transient API failures.</p> </li> <li> <p>Router -- Classifies each incoming query by intent and complexity. The router can operate through multiple backends: Gemini Flash (cloud, fast), Ollama llama3.2:3b (local, dedicated container), or local regex fallback. Classification categories include <code>simple_query</code>, <code>complex_task</code>, <code>memory_store</code>, <code>memory_recall</code>, <code>task_management</code>, and others.</p> </li> <li> <p>InferenceBroker -- Multi-provider routing engine with fallback chains and cost tracking. Selects the optimal LLM provider based on task type, privacy requirements, cost constraints, and availability. Tracks per-request costs in a local SQLite database.</p> </li> </ul> <p>LLM Providers:</p> Provider Model Use Case Google Gemini gemini-2.5-flash Simple queries, routing, fast responses Anthropic Claude claude-sonnet-4-5-20250929 (Sonnet 4.5) Complex reasoning, code, analysis OpenAI gpt-5.2 Alternative complex tasks Ollama (local) llama3.1:8b Privacy-sensitive operations Ollama (local) llama3.2:3b Fast query classification (router) <p>Embedding Providers:</p> Provider Model Dimensions Google Gemini text-embedding-004 768 Ollama nomic-embed-text 768 OpenAI text-embedding-3-large 3072"},{"location":"technical/architecture/#skills-service","title":"Skills Service","text":"<p>The Skills Service is an independent aiohttp REST API running on port 8080 (internal network only, not exposed to the host). It provides a pluggable skill framework with lifecycle management.</p> <p>Core Responsibilities:</p> <ul> <li> <p>Skill Registry -- Manages registration, initialization, and shutdown of skill modules. Each skill implements a standard interface with <code>initialize()</code>, <code>execute()</code>, and <code>cleanup()</code> lifecycle methods.</p> </li> <li> <p>Built-in Skills:</p> </li> <li>TaskManager -- Create, update, complete, and query tasks with priority and due date support.</li> <li>Calendar -- Schedule events, check availability, and receive proactive reminders.</li> <li>Profile -- Manage personal data, preferences, and contacts. Supports passive learning from conversations.</li> <li>Gmail -- Read, search, draft, and send emails. Includes trust scoring for senders and sync state management.</li> <li> <p>GitHub -- Repository management, issue tracking, PR reviews, and audit logging with configurable autonomy levels.</p> </li> <li> <p>Heartbeat Scheduler -- A background scheduler that triggers proactive actions such as daily summaries, upcoming event reminders, and email digest notifications. Runs on configurable intervals.</p> </li> <li> <p>Authentication -- All requests from the Bot Service must include an <code>X-API-Secret</code> header with an HMAC-based token. Requests without valid authentication are rejected.</p> </li> </ul>"},{"location":"technical/architecture/#qdrant","title":"Qdrant","text":"<p>Qdrant serves as the vector database for semantic memory storage and retrieval.</p> <ul> <li>Collections: <code>long_term_memory</code> and <code>conversation_history</code>, with per-user filtering via metadata payloads.</li> <li>Embeddings: Supports three embedding providers with different dimensionalities -- 768-dim (Gemini text-embedding-004), 768-dim (Ollama nomic-embed-text), or 3072-dim (OpenAI text-embedding-3-large).</li> <li>Encryption: All memory content undergoes AES-256-GCM field-level encryption before being stored in Qdrant payloads. Encryption keys are derived using PBKDF2 from a master secret and per-record salt.</li> <li>Search: Cosine similarity with configurable <code>top_k</code> (default 5). Results are decrypted, ranked, and returned as context fragments.</li> </ul>"},{"location":"technical/architecture/#postgresql","title":"PostgreSQL","text":"<p>PostgreSQL provides persistent relational storage for structured data that does not benefit from vector search.</p> <ul> <li>User Management -- RBAC system with three roles: owner (full control), admin (manage users and settings), and user (standard interaction). User records include Discord ID, role, and metadata.</li> <li>Dynamic Settings -- Namespace/key/value store with full audit trail. Supports runtime configuration changes without restarts. Falls back to environment variables when database values are not set.</li> <li>Personal Understanding:</li> <li>Profiles: User preferences, communication style, timezone, interests.</li> <li>Contacts: People the user mentions, with relationship context and interaction frequency.</li> <li>Policies: User-defined rules (e.g., \"always respond formally\", \"never mention competitor X\").</li> <li>Learnings: Passively observed facts extracted from conversations by the observation pipeline.</li> <li>Gmail Integration -- Account registration, OAuth state, sync cursors, message metadata, trust scores per sender, and draft management.</li> <li>GitHub Integration -- Audit log of all actions taken, autonomy configuration per repository, and webhook state.</li> </ul>"},{"location":"technical/architecture/#ollama-generation","title":"Ollama (Generation)","text":"<p>A dedicated Ollama container for privacy-sensitive LLM operations and local embedding generation.</p> <ul> <li>Default Model: llama3.1:8b (8 billion parameters). Provides capable text generation for queries that should not leave the local network.</li> <li>Embeddings: Also serves <code>nomic-embed-text</code> for local embedding generation, ensuring that sensitive text never reaches external APIs.</li> <li>Resource Allocation: 2G-8G memory, 1-4 CPU cores. The model remains loaded in memory to eliminate cold-start latency.</li> <li>Port: Exposed on 11434 to the host for debugging and direct model interaction.</li> </ul>"},{"location":"technical/architecture/#ollama-router","title":"Ollama Router","text":"<p>A separate, lightweight Ollama container dedicated exclusively to fast query classification.</p> <ul> <li>Default Model: llama3.2:3b (3 billion parameters). Small enough to classify queries in under 500ms on CPU.</li> <li>Purpose: Eliminates the 2-10 second model-swapping delay that would occur if routing and generation shared a single Ollama instance. Each container keeps exactly one model loaded in memory at all times.</li> <li>Classification Output: Returns structured JSON with intent category, confidence score, and provider recommendation.</li> <li>Resource Allocation: 1.5G-3G memory, 0.5-2 CPU cores. Minimal footprint due to the small model size.</li> <li>Network: Internal only, no port exposed to host.</li> </ul>"},{"location":"technical/architecture/#request-flow","title":"Request Flow","text":"<p>A complete request lifecycle from incoming message to response:</p> <ol> <li> <p>Message received -- The Bot Service receives a message from an input source (currently Discord via the gateway WebSocket, but the pipeline is source-agnostic).</p> </li> <li> <p>Security checks -- Three sequential checks are applied:</p> </li> <li>Rate limit verification (reject if user has exceeded their message quota).</li> <li>Allowlist check (reject if the user's Discord ID is not authorized).</li> <li> <p>Prompt injection scan (reject if the message matches any of the 17 injection detection patterns).</p> </li> <li> <p>Router classification -- The message is sent to the router for intent classification. The router attempts Gemini Flash first, falls back to Ollama llama3.2:3b, and finally to local regex patterns if both external calls fail.</p> </li> <li> <p>Skill dispatch -- If the router identifies a skill-related intent (e.g., <code>task_management</code>, <code>email_read</code>, <code>github_action</code>), the Bot Service forwards the request to the Skills Service via an internal HTTP call to <code>http://zetherion-ai-skills:8080</code>.</p> </li> <li> <p>Provider selection -- The InferenceBroker selects an LLM provider based on the routing classification and user configuration. You control which providers handle which task types:</p> </li> <li>Simple queries can route to Gemini 2.5 Flash or Ollama (your choice).</li> <li>Complex reasoning can route to Claude Sonnet 4.5, GPT-5.2, or local Ollama (your choice).</li> <li>Privacy-sensitive queries can be restricted to Ollama llama3.1:8b (local inference, never leaves your machine).</li> <li> <p>Fallback chains ensure a response even if the primary provider is unavailable.</p> </li> <li> <p>Context assembly -- The system builds a rich context window by combining:</p> </li> <li>Recent conversation history (last N messages from the current session).</li> <li>Semantic memory search results from Qdrant (top-k similar memories).</li> <li>User profile data from PostgreSQL (preferences, communication style).</li> <li> <p>Skill-specific context fragments (e.g., upcoming tasks, recent emails).</p> </li> <li> <p>LLM generation -- The assembled prompt is sent to the selected LLM provider. The response is streamed or returned as a complete message depending on provider capabilities.</p> </li> <li> <p>Observation pipeline -- After generating the response, a passive observation step extracts learnings from the conversation (e.g., \"user mentioned they prefer Python over JavaScript\") and stores them in PostgreSQL for future context enrichment.</p> </li> <li> <p>Response delivery -- The response is sent back to the originating input source. For Discord, messages exceeding 2,000 characters are automatically split across multiple messages.</p> </li> <li> <p>Cost tracking -- The token usage and estimated cost for the request are recorded in a local SQLite database (<code>costs.db</code>) for monitoring and budget management.</p> </li> </ol>"},{"location":"technical/architecture/#data-flow","title":"Data Flow","text":""},{"location":"technical/architecture/#storage-responsibilities","title":"Storage Responsibilities","text":"Data Type Storage Details Conversation context Qdrant + in-memory Last N messages held in memory; semantic history in Qdrant vectors Long-term memory Qdrant Encrypted vector embeddings with metadata payloads User profiles PostgreSQL personal_profiles, personal_contacts, personal_policies tables Gmail data PostgreSQL gmail_accounts, gmail_messages, gmail_drafts, gmail_trust tables GitHub data PostgreSQL github_audit_log, github_autonomy_config tables User/role data PostgreSQL users table with RBAC roles Dynamic settings PostgreSQL settings table with namespace/key/value and audit trail Cost tracking SQLite costs.db in ./data directory Application logs Filesystem Structured JSON logs in ./logs with rotation Encryption salt Filesystem Persistent salt file in ./data"},{"location":"technical/architecture/#configuration-cascade","title":"Configuration Cascade","text":"<p>Settings are resolved in the following priority order:</p> <ol> <li>PostgreSQL dynamic settings (highest priority, runtime-changeable)</li> <li>Environment variables (set in docker-compose.yml or .env)</li> <li>Default values in Pydantic Settings (lowest priority, compile-time)</li> </ol>"},{"location":"technical/architecture/#security-architecture","title":"Security Architecture","text":"<p>Security is implemented as defense in depth across every layer of the stack. For comprehensive details, see security.md.</p> <p>Container Security: - Distroless base images for bot and skills services (no shell, minimal attack surface) - Read-only root filesystems with tmpfs mounts for writable temporary directories - <code>no-new-privileges</code> flag on all 6 containers prevents privilege escalation - Resource limits (CPU and memory quotas) on every service prevent denial-of-service</p> <p>Network Security: - All services communicate over an internal Docker bridge network (<code>zetherion-ai-net</code>) - Only Qdrant (6333) and Ollama generation (11434) expose ports to the host - The Skills Service, PostgreSQL, and Ollama Router are entirely internal</p> <p>Application Security: - AES-256-GCM encryption with PBKDF2 key derivation for all stored memories - User allowlist with RBAC (owner/admin/user roles) - Rate limiting per user to prevent abuse - 17 compiled regex patterns for prompt injection detection - Pydantic <code>SecretStr</code> for all credentials (never logged or serialized) - HMAC-based service-to-service authentication</p> <p>Supply Chain Security: - Pinned Docker image digests for Qdrant and Ollama (Dependabot auto-updates) - Gitleaks pre-commit hook for secret scanning - CodeQL weekly static analysis scans - Dependabot weekly dependency updates - Bandit security scanning in CI pipeline</p>"},{"location":"technical/architecture/#related-documentation","title":"Related Documentation","text":"<ul> <li>Docker Services and Deployment -- Service configuration, resource limits, and deployment procedures</li> <li>Security Architecture -- Comprehensive security controls, threat model, and hardening measures</li> <li>Configuration Guide -- Environment variables, settings hierarchy, and secrets management</li> <li>Skills Framework -- Building and registering custom skills</li> </ul>"},{"location":"technical/configuration/","title":"Configuration Reference","text":""},{"location":"technical/configuration/#overview","title":"Overview","text":"<p>All configuration for Zetherion AI is managed via environment variables defined in a <code>.env</code> file at the project root. The bot uses Pydantic <code>BaseSettings</code> for validation, type coercion, and default values. Settings are loaded once at startup and cached via <code>@lru_cache</code>.</p> <p>Configuration files: - <code>.env.example</code> -- Template with all variables (checked into git, no real values) - <code>.env</code> -- Active configuration (gitignored, contains your secrets)</p> <p>Creating your config: <pre><code>cp .env.example .env\n# Edit .env with your values\n</code></pre></p>"},{"location":"technical/configuration/#required-variables","title":"Required Variables","text":"<p>These three variables are mandatory. The bot will not start without them.</p> Variable Description Example <code>DISCORD_TOKEN</code> Discord bot authentication token <code>MTQ2ODc4...</code> <code>GEMINI_API_KEY</code> Google Gemini API key (used for embeddings and routing) <code>AIzaSy...</code> <code>ENCRYPTION_PASSPHRASE</code> Master passphrase for AES-256-GCM encryption (minimum 16 characters) <code>your-secure-passphrase-here</code>"},{"location":"technical/configuration/#discord-configuration","title":"Discord Configuration","text":"Variable Default Description <code>DISCORD_TOKEN</code> (required) Bot authentication token from the Discord Developer Portal <code>ALLOWED_USER_IDS</code> <code>\"\"</code> Comma-separated Discord user IDs permitted to interact with the bot. Empty string allows all users (not recommended for production) <code>ALLOW_ALL_USERS</code> <code>false</code> Explicit flag to allow all users when no allowlist is configured <code>OWNER_USER_ID</code> <code>0</code> Bootstrap admin user ID for RBAC. This user is automatically assigned the <code>owner</code> role on first startup"},{"location":"technical/configuration/#llm-provider-configuration","title":"LLM Provider Configuration","text":"Variable Default Description <code>CLAUDE_MODEL</code> <code>claude-sonnet-4-5-20250929</code> Anthropic model identifier for complex reasoning tasks <code>OPENAI_MODEL</code> <code>gpt-5.2</code> OpenAI model identifier for complex tasks <code>ROUTER_MODEL</code> <code>gemini-2.5-flash</code> Gemini model for routing decisions and simple query responses <code>EMBEDDING_MODEL</code> <code>text-embedding-004</code> Gemini embedding model for vector generation <code>ANTHROPIC_API_KEY</code> (optional) Anthropic API key for Claude. Loaded as <code>SecretStr</code> <code>OPENAI_API_KEY</code> (optional) OpenAI API key. Loaded as <code>SecretStr</code>"},{"location":"technical/configuration/#router-configuration","title":"Router Configuration","text":"Variable Default Description <code>ROUTER_BACKEND</code> <code>gemini</code> Router backend selection. Valid values: <code>gemini</code> (cloud-based, fast startup) or <code>ollama</code> (local, privacy-focused) <p>When set to <code>gemini</code>, routing uses the Gemini API. When set to <code>ollama</code>, routing uses a dedicated local Ollama container for message classification.</p>"},{"location":"technical/configuration/#ollama-configuration-generation","title":"Ollama Configuration (Generation)","text":"<p>These settings control the main Ollama container used for text generation and local embeddings.</p> Variable Default Description <code>OLLAMA_HOST</code> <code>ollama</code> Ollama generation container hostname (Docker service name) <code>OLLAMA_PORT</code> <code>11434</code> Ollama API port <code>OLLAMA_GENERATION_MODEL</code> <code>llama3.1:8b</code> Model for local text generation <code>OLLAMA_EMBEDDING_MODEL</code> <code>nomic-embed-text</code> Model for local embedding generation (768 dimensions) <code>OLLAMA_TIMEOUT</code> <code>30</code> API request timeout in seconds"},{"location":"technical/configuration/#ollama-router-configuration","title":"Ollama Router Configuration","text":"<p>These settings control the dedicated lightweight Ollama container used for fast message classification.</p> Variable Default Description <code>OLLAMA_ROUTER_HOST</code> <code>ollama-router</code> Router container hostname (Docker service name) <code>OLLAMA_ROUTER_PORT</code> <code>11434</code> Router container API port <code>OLLAMA_ROUTER_MODEL</code> <code>llama3.2:3b</code> Small, fast model for query classification"},{"location":"technical/configuration/#embeddings-configuration","title":"Embeddings Configuration","text":"Variable Default Description <code>EMBEDDINGS_BACKEND</code> <code>ollama</code> Embeddings backend selection. Valid values: <code>ollama</code>, <code>gemini</code>, or <code>openai</code> <code>OPENAI_EMBEDDING_MODEL</code> <code>text-embedding-3-large</code> OpenAI embedding model (used when backend is <code>openai</code>) <code>OPENAI_EMBEDDING_DIMENSIONS</code> <code>3072</code> Embedding vector dimensions for OpenAI model"},{"location":"technical/configuration/#encryption","title":"Encryption","text":"Variable Default Description <code>ENCRYPTION_PASSPHRASE</code> (required) Master passphrase for key derivation. Minimum 16 characters. Used with PBKDF2-HMAC-SHA256 (600,000 iterations) to derive the AES-256-GCM key. Loaded as <code>SecretStr</code> <code>ENCRYPTION_SALT_PATH</code> <code>data/salt.bin</code> Filesystem path for the persistent salt file. Auto-generated on first run. Must be backed up <code>ENCRYPTION_STRICT</code> <code>false</code> When <code>true</code>, decryption failures raise errors instead of passing through unencrypted data. Set to <code>false</code> for backward compatibility with legacy unencrypted records"},{"location":"technical/configuration/#database","title":"Database","text":""},{"location":"technical/configuration/#postgresql","title":"PostgreSQL","text":"Variable Default Description <code>POSTGRES_DSN</code> <code>postgresql://zetherion:changeme@postgres:5432/zetherion</code> Full PostgreSQL connection string. Used for RBAC, dynamic settings, audit trail, and Gmail trust state"},{"location":"technical/configuration/#qdrant-vector-database","title":"Qdrant (Vector Database)","text":"Variable Default Description <code>QDRANT_HOST</code> <code>qdrant</code> Qdrant server hostname (Docker service name) <code>QDRANT_PORT</code> <code>6333</code> Qdrant HTTP API port <code>QDRANT_USE_TLS</code> <code>false</code> Enable TLS encryption for the Qdrant connection <code>QDRANT_CERT_PATH</code> (optional) Path to TLS certificate file for Qdrant server verification"},{"location":"technical/configuration/#inferencebroker","title":"InferenceBroker","text":"<p>The InferenceBroker provides smart multi-provider routing across Anthropic, OpenAI, and Google.</p> Variable Default Description <code>INFERENCE_BROKER_ENABLED</code> <code>true</code> Enable the multi-provider routing system <code>COST_TRACKING_ENABLED</code> <code>true</code> Track API costs per provider and task type"},{"location":"technical/configuration/#model-discovery","title":"Model Discovery","text":"Variable Default Description <code>MODEL_DISCOVERY_ENABLED</code> <code>true</code> Enable automatic model discovery from provider APIs <code>MODEL_REFRESH_HOURS</code> <code>24</code> Hours between model list refreshes from provider APIs <code>ANTHROPIC_TIER</code> <code>balanced</code> Default tier for Anthropic models. Valid values: <code>quality</code>, <code>balanced</code>, <code>fast</code> <code>OPENAI_TIER</code> <code>balanced</code> Default tier for OpenAI models. Valid values: <code>quality</code>, <code>balanced</code>, <code>fast</code> <code>GOOGLE_TIER</code> <code>fast</code> Default tier for Google models. Valid values: <code>quality</code>, <code>balanced</code>, <code>fast</code>"},{"location":"technical/configuration/#cost-tracking","title":"Cost Tracking","text":"Variable Default Description <code>COST_DB_PATH</code> <code>data/costs.db</code> Path to the SQLite database for cost tracking <code>DAILY_BUDGET_USD</code> (optional) Daily spending limit in USD. When set, alerts are triggered at the warning threshold <code>MONTHLY_BUDGET_USD</code> (optional) Monthly spending limit in USD. When set, alerts are triggered at the warning threshold <code>BUDGET_WARNING_PCT</code> <code>80.0</code> Percentage of budget at which to send a warning notification (0-100)"},{"location":"technical/configuration/#notifications","title":"Notifications","text":"Variable Default Description <code>NOTIFICATIONS_ENABLED</code> <code>true</code> Enable the notification system for cost and model alerts <code>NOTIFY_ON_NEW_MODELS</code> <code>true</code> Send a notification when new models are discovered from provider APIs <code>NOTIFY_ON_DEPRECATION</code> <code>true</code> Send a notification when a model is marked as deprecated <code>NOTIFY_ON_MISSING_PRICING</code> <code>false</code> Send a notification for discovered models that lack pricing data <code>DAILY_SUMMARY_ENABLED</code> <code>false</code> Send a daily cost summary notification via Discord <code>DAILY_SUMMARY_HOUR</code> <code>9</code> Hour of day (0-23) at which to send the daily cost summary"},{"location":"technical/configuration/#profile-system","title":"Profile System","text":"Variable Default Description <code>PROFILE_INFERENCE_ENABLED</code> <code>true</code> Enable automatic profile extraction from conversations <code>PROFILE_TIER1_ONLY</code> <code>false</code> Use only Tier 1 regex-based extraction (no LLM calls). Reduces cost at the expense of extraction quality <code>PROFILE_CONFIDENCE_THRESHOLD</code> <code>0.6</code> Minimum confidence score (0.0-1.0) to auto-apply a profile update without user confirmation <code>PROFILE_CACHE_TTL</code> <code>300</code> Profile cache time-to-live in seconds <code>PROFILE_DB_PATH</code> <code>data/profiles.db</code> Path to the SQLite database for profile operational data <code>PROFILE_MAX_PENDING_CONFIRMATIONS</code> <code>5</code> Maximum number of pending confirmation prompts per user <code>PROFILE_CONFIRMATION_EXPIRY_HOURS</code> <code>72</code> Hours before a pending confirmation expires automatically <code>DEFAULT_FORMALITY</code> <code>0.5</code> Initial response formality level (0.0 = casual, 1.0 = formal) <code>DEFAULT_VERBOSITY</code> <code>0.5</code> Initial response detail level (0.0 = terse, 1.0 = detailed) <code>DEFAULT_PROACTIVITY</code> <code>0.3</code> Initial proactive behavior level (0.0 = reactive only, 1.0 = fully proactive) <code>TRUST_EVOLUTION_RATE</code> <code>0.05</code> Trust increase per positive interaction"},{"location":"technical/configuration/#skills-service","title":"Skills Service","text":"Variable Default Description <code>SKILLS_SERVICE_URL</code> <code>http://zetherion_ai-skills:8080</code> URL of the Skills Service on the internal Docker network <code>SKILLS_API_SECRET</code> (optional) Shared secret for <code>X-API-Secret</code> header authentication. Loaded as <code>SecretStr</code>. Required for production <code>SKILLS_REQUEST_TIMEOUT</code> <code>30</code> Timeout in seconds for requests to the Skills Service"},{"location":"technical/configuration/#gmail-integration","title":"Gmail Integration","text":"Variable Default Description <code>GOOGLE_CLIENT_ID</code> (optional) Google OAuth 2.0 client ID for Gmail integration <code>GOOGLE_CLIENT_SECRET</code> (optional) Google OAuth 2.0 client secret. Loaded as <code>SecretStr</code> <code>GOOGLE_REDIRECT_URI</code> <code>http://localhost:8080/gmail/callback</code> OAuth 2.0 callback URL. Must match the redirect URI configured in the Google Cloud Console"},{"location":"technical/configuration/#github-integration","title":"GitHub Integration","text":"Variable Default Description <code>GITHUB_TOKEN</code> (optional) GitHub personal access token. Loaded as <code>SecretStr</code> <code>GITHUB_DEFAULT_REPO</code> (optional) Default repository in <code>owner/repo</code> format <code>GITHUB_API_TIMEOUT</code> <code>30</code> Timeout in seconds for GitHub API requests"},{"location":"technical/configuration/#logging","title":"Logging","text":"Variable Default Description <code>LOG_LEVEL</code> <code>INFO</code> Logging verbosity. Valid values: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code> <code>LOG_TO_FILE</code> <code>true</code> Enable writing logs to rotating files <code>LOG_DIRECTORY</code> <code>logs</code> Directory path for log files <code>LOG_FILE_MAX_BYTES</code> <code>52428800</code> Maximum size in bytes per log file before rotation (default: 50 MB) <code>LOG_FILE_BACKUP_COUNT</code> <code>10</code> Number of rotated log files to retain <code>LOG_ERROR_FILE_ENABLED</code> <code>true</code> Enable a separate error log file capturing WARNING-level and above"},{"location":"technical/configuration/#application","title":"Application","text":"Variable Default Description <code>ENVIRONMENT</code> <code>production</code> Environment name. Set to <code>development</code> for colored console logging and debug behavior"},{"location":"technical/configuration/#dynamic-settings","title":"Dynamic Settings","text":"<p>The <code>Settings</code> class supports a three-level cascade for runtime-configurable values:</p> <pre><code>PostgreSQL override  -&gt;  Environment variable  -&gt;  Default value\n</code></pre> <p>Use the <code>get_dynamic(namespace, key, default)</code> function for settings that may be changed at runtime without restarting the bot. The function reads from an in-memory cache populated from PostgreSQL and never blocks on database I/O.</p> <pre><code>from zetherion_ai.config import get_dynamic\n\nmodel = get_dynamic(\"models\", \"claude_model\", \"claude-sonnet-4-5-20250929\")\n</code></pre>"},{"location":"technical/configuration/#example-env-minimal","title":"Example .env (Minimal)","text":"<p>The minimum configuration needed to start the bot:</p> <pre><code>DISCORD_TOKEN=your_discord_token\nGEMINI_API_KEY=your_gemini_key\nENCRYPTION_PASSPHRASE=your-16-char-minimum-passphrase\n</code></pre>"},{"location":"technical/configuration/#example-env-full-featured","title":"Example .env (Full Featured)","text":"<p>A production-ready configuration with all major features enabled:</p> <pre><code># Required\nDISCORD_TOKEN=MTQ2ODc4...\nGEMINI_API_KEY=AIzaSy...\nENCRYPTION_PASSPHRASE=your-very-secure-passphrase\n\n# Optional LLM providers\nANTHROPIC_API_KEY=sk-ant-...\nOPENAI_API_KEY=sk-...\n\n# Router\nROUTER_BACKEND=gemini\n\n# Access control\nALLOWED_USER_IDS=123456789,987654321\nOWNER_USER_ID=123456789\n\n# Skills Service\nSKILLS_API_SECRET=your-skills-api-secret\n\n# Budgets\nDAILY_BUDGET_USD=5.00\nMONTHLY_BUDGET_USD=50.00\n\n# Gmail\nGOOGLE_CLIENT_ID=your-client-id\nGOOGLE_CLIENT_SECRET=your-client-secret\n\n# GitHub\nGITHUB_TOKEN=ghp_...\nGITHUB_DEFAULT_REPO=owner/repo\n\n# Logging\nLOG_LEVEL=INFO\nLOG_TO_FILE=true\n\n# PostgreSQL (use a strong password in production)\nPOSTGRES_DSN=postgresql://zetherion:strong-random-password@postgres:5432/zetherion\n</code></pre>"},{"location":"technical/configuration/#related-docs","title":"Related Docs","text":"<ul> <li>Architecture -- System design and component interactions</li> <li>Security Model -- Encryption, access control, and threat mitigation</li> <li>Docker Deployment -- Container setup and orchestration</li> </ul>"},{"location":"technical/cost-tracking/","title":"Cost Tracking","text":""},{"location":"technical/cost-tracking/#overview","title":"Overview","text":"<p>Monitor, budget, and optimize your LLM API spending with Zetherion AI's built-in cost tracking system. The system monitors every API call to LLM providers and provides:</p> <ul> <li>Real-time spending tracking per provider and task type</li> <li>Budget enforcement with configurable daily and monthly limits</li> <li>Threshold alerts before you exceed budgets</li> <li>Spending reports for daily and monthly analysis</li> <li>History storage in SQLite for querying and export</li> </ul>"},{"location":"technical/cost-tracking/#how-it-works","title":"How It Works","text":"<pre><code>API Request -&gt; InferenceBroker -&gt; Cost Calculation -&gt; Budget Check -&gt; Storage\n                                        |\n                                Alert if threshold reached\n</code></pre>"},{"location":"technical/cost-tracking/#configuration","title":"Configuration","text":""},{"location":"technical/cost-tracking/#enable-cost-tracking","title":"Enable Cost Tracking","text":"<pre><code># Enable the cost tracking system\nCOST_TRACKING_ENABLED=true\n\n# Storage location\nCOST_DB_PATH=data/costs.db\n</code></pre>"},{"location":"technical/cost-tracking/#set-budgets","title":"Set Budgets","text":"<pre><code># Daily spending limit (USD)\nDAILY_BUDGET_USD=5.00\n\n# Monthly spending limit (USD)\nMONTHLY_BUDGET_USD=50.00\n\n# Warning threshold (percentage)\nBUDGET_WARNING_PCT=80.0\n</code></pre>"},{"location":"technical/cost-tracking/#enable-notifications","title":"Enable Notifications","text":"<pre><code># Enable notifications for cost alerts\nNOTIFICATIONS_ENABLED=true\n\n# Daily summary at 8 PM\nDAILY_SUMMARY_ENABLED=true\nDAILY_SUMMARY_HOUR=20\n</code></pre>"},{"location":"technical/cost-tracking/#provider-pricing","title":"Provider Pricing","text":"Provider Model Input (per 1M tokens) Output (per 1M tokens) Anthropic Claude Sonnet 4.5 $3.00 $15.00 Anthropic Claude Haiku 4.5 $0.25 $1.25 OpenAI GPT-5.2 $2.50 $10.00 Google Gemini 2.5 Flash Free tier Free tier Ollama Local models (Llama, etc.) $0.00 $0.00 <p>Prices as of February 2026. Check provider websites for current rates.</p>"},{"location":"technical/cost-tracking/#token-estimation","title":"Token Estimation","text":"<p>Approximate token counts: - 1 word -- approximately 1.3 tokens - 100 words -- approximately 130 tokens - 1 page of text -- approximately 500-700 tokens</p>"},{"location":"technical/cost-tracking/#typical-query-costs","title":"Typical Query Costs","text":"Query Type Input Tokens Output Tokens Estimated Cost (Claude Sonnet 4.5) Simple question ~50 ~100 $0.0016 Code review ~500 ~300 $0.006 Complex analysis ~1000 ~500 $0.01 Long conversation ~2000 ~1000 $0.02"},{"location":"technical/cost-tracking/#cost-by-task-type","title":"Cost by Task Type","text":"<p>The system tracks costs by task type:</p> Task Type Typical Provider Avg Cost/Query Simple Query Gemini 2.5 Flash $0.00 (free) Memory Search Gemini 2.5 Flash $0.00 (free) Complex Reasoning Claude Sonnet 4.5 $0.005 Code Generation Claude Sonnet 4.5 $0.008 Creative Writing GPT-5.2 $0.006"},{"location":"technical/cost-tracking/#budget-management","title":"Budget Management","text":""},{"location":"technical/cost-tracking/#daily-budgets","title":"Daily Budgets","text":"<p>Daily budgets reset at midnight (local time).</p> <p>Workflow: 1. Each API call adds to daily total 2. At 80% (configurable), warning notification sent 3. At 100%, exceeded notification sent 4. Complex queries may be limited (uses cheaper provider)</p>"},{"location":"technical/cost-tracking/#monthly-budgets","title":"Monthly Budgets","text":"<p>Monthly budgets reset on the 1st of each month.</p> <p>Workflow: 1. Each API call adds to monthly total 2. At 80%, warning notification sent 3. At 100%, exceeded notification sent 4. Daily budget may be reduced automatically</p>"},{"location":"technical/cost-tracking/#budget-notifications","title":"Budget Notifications","text":"<pre><code>Budget Warning (80% reached)\n\nDaily Spending: $4.00 / $5.00 (80%)\nMonthly Spending: $35.00 / $50.00 (70%)\n\nTop spending:\n- Claude Sonnet 4.5: $2.50 (62%)\n- GPT-5.2: $1.20 (30%)\n- Gemini 2.5 Flash: $0.00 (0%)\n\nRemaining today: $1.00\n</code></pre>"},{"location":"technical/cost-tracking/#budget-actions","title":"Budget Actions","text":"<p>When budgets are exceeded:</p> Level Action 80% Warning Notification only, no restrictions 100% Daily Prefer cheaper providers, limit complex queries 100% Monthly Strict limits, may require manual override"},{"location":"technical/cost-tracking/#cost-reports","title":"Cost Reports","text":""},{"location":"technical/cost-tracking/#daily-summary","title":"Daily Summary","text":"<p>Automatically sent at configured hour (default: 8 PM):</p> <pre><code>Daily Cost Summary (Feb 10, 2026)\n\nTotal Spent Today: $3.45\n\nBy Provider:\n  Claude Sonnet 4.5: $2.10 (61%)\n  GPT-5.2: $1.05 (30%)\n  Gemini 2.5 Flash: $0.00 (0%)\n  Ollama (Llama): $0.00 (0%)\n\nBy Task Type:\n  Complex Reasoning: $1.50 (43%)\n  Code Generation: $1.20 (35%)\n  Simple Queries: $0.00 (0%)\n  Memory Operations: $0.00 (0%)\n\nQueries: 47 total\n  - Successful: 45 (96%)\n  - Rate Limited: 2 (4%)\n\nBudget Status:\n  Daily: $3.45 / $5.00 (69%)\n  Monthly: $28.45 / $50.00 (57%)\n</code></pre>"},{"location":"technical/cost-tracking/#monthly-summary","title":"Monthly Summary","text":"<p>Sent on the 1st of each month:</p> <pre><code>Monthly Cost Summary (January 2026)\n\nTotal Spent: $42.50\n\nBy Provider:\n  Claude Sonnet 4.5: $28.00 (66%)\n  GPT-5.2: $12.50 (29%)\n  Gemini 2.5 Flash: $0.00 (0%)\n  Ollama (Llama): $0.00 (0%)\n\nDaily Average: $1.37\nPeak Day: Jan 15 ($4.80)\nLowest Day: Jan 3 ($0.12)\n\nTotal Queries: 1,247\nAverage Cost/Query: $0.034\n\nBudget: $42.50 / $50.00 (85%)\n</code></pre>"},{"location":"technical/cost-tracking/#querying-cost-data","title":"Querying Cost Data","text":"<p>Access cost data programmatically:</p> <pre><code># View SQLite database\ndocker exec zetherion-ai-bot sqlite3 /app/data/costs.db \"\n  SELECT date(timestamp), SUM(cost_usd) as daily_cost\n  FROM usage_records\n  GROUP BY date(timestamp)\n  ORDER BY date(timestamp) DESC\n  LIMIT 7;\n\"\n</code></pre>"},{"location":"technical/cost-tracking/#export-cost-data","title":"Export Cost Data","text":"<pre><code># Export to CSV\ndocker exec zetherion-ai-bot sqlite3 -header -csv /app/data/costs.db \"\n  SELECT * FROM usage_records\n  WHERE timestamp &gt; datetime('now', '-30 days');\n\" &gt; costs_last_30_days.csv\n</code></pre>"},{"location":"technical/cost-tracking/#optimization-strategies","title":"Optimization Strategies","text":""},{"location":"technical/cost-tracking/#1-use-free-tiers-effectively","title":"1. Use Free Tiers Effectively","text":"<p>Gemini 2.5 Flash Free Tier: - 15 requests/minute - 1,500 requests/day - Use for routing, simple queries, embeddings</p> <p>Strategy: <pre><code># Route simple queries to Gemini\nROUTER_BACKEND=gemini\n</code></pre></p>"},{"location":"technical/cost-tracking/#2-optimize-context-window","title":"2. Optimize Context Window","text":"<p>Reduce tokens sent per request:</p> <pre><code># Fewer messages in context\nCONTEXT_WINDOW_SIZE=5  # Default: 10\n\n# Fewer memory search results\nMEMORY_SEARCH_LIMIT=3  # Default: 5\n</code></pre> <p>Savings: ~30-50% reduction in input tokens</p>"},{"location":"technical/cost-tracking/#3-use-ollama-for-routing","title":"3. Use Ollama for Routing","text":"<p>Local routing with Llama models means zero API costs:</p> <pre><code>ROUTER_BACKEND=ollama\nOLLAMA_ROUTER_MODEL=llama3.1:8b\n</code></pre> <p>Savings: 100% of routing costs (typically 10-20% of total)</p>"},{"location":"technical/cost-tracking/#4-choose-cost-effective-models","title":"4. Choose Cost-Effective Models","text":"Need Expensive Cost-Effective Simple Q&amp;A Claude Sonnet 4.5 Gemini 2.5 Flash Code Review GPT-5.2 Claude Haiku 4.5 Summarization Claude Sonnet 4.5 Claude Haiku 4.5"},{"location":"technical/cost-tracking/#5-rate-limiting","title":"5. Rate Limiting","text":"<p>Prevent runaway costs:</p> <pre><code># Limit messages per user\nRATE_LIMIT_MESSAGES=5\nRATE_LIMIT_WINDOW=60\n</code></pre>"},{"location":"technical/cost-tracking/#6-hybrid-approach","title":"6. Hybrid Approach","text":"<p>Best of both worlds:</p> <pre><code># Free routing\nROUTER_BACKEND=gemini\n\n# Quality for complex tasks only\nANTHROPIC_API_KEY=sk-ant-...\n\n# Skip OpenAI (redundant with Claude)\nOPENAI_API_KEY=\n\n# Strict budget\nDAILY_BUDGET_USD=3.00\n</code></pre> <p>Expected Monthly Cost: $20-40</p>"},{"location":"technical/cost-tracking/#cost-comparison-strategies","title":"Cost Comparison: Strategies","text":"Strategy Monthly Cost Quality Privacy All Cloud (Claude Sonnet 4.5 + GPT-5.2) $50-100 Best Low Gemini 2.5 Flash Only $0 (free tier) Good Low Ollama Only (Llama models) $0 (electricity) Good High Hybrid (Gemini 2.5 Flash + Claude Sonnet 4.5) $20-40 Very Good Medium Hybrid (Ollama Llama + Claude Sonnet 4.5) $15-30 Very Good High"},{"location":"technical/cost-tracking/#database-schema","title":"Database Schema","text":"<p>The cost database uses SQLite with this schema:</p> <pre><code>CREATE TABLE usage_records (\n    id INTEGER PRIMARY KEY,\n    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n    provider TEXT NOT NULL,\n    model TEXT NOT NULL,\n    task_type TEXT,\n    input_tokens INTEGER,\n    output_tokens INTEGER,\n    cost_usd REAL,\n    latency_ms INTEGER,\n    success BOOLEAN,\n    error_message TEXT\n);\n\nCREATE INDEX idx_timestamp ON usage_records(timestamp);\nCREATE INDEX idx_provider ON usage_records(provider);\n</code></pre>"},{"location":"technical/cost-tracking/#troubleshooting","title":"Troubleshooting","text":""},{"location":"technical/cost-tracking/#costs-higher-than-expected","title":"Costs Higher Than Expected","text":"<p>Check usage patterns: <pre><code># Top cost queries today\ndocker exec zetherion-ai-bot sqlite3 /app/data/costs.db \"\n  SELECT provider, task_type, COUNT(*) as count, SUM(cost_usd) as total\n  FROM usage_records\n  WHERE date(timestamp) = date('now')\n  GROUP BY provider, task_type\n  ORDER BY total DESC;\n\"\n</code></pre></p> <p>Common causes: 1. Long conversations (high context window) 2. Complex queries routed to expensive models 3. Retry loops on failed requests 4. Memory search returning too many results</p>"},{"location":"technical/cost-tracking/#budget-not-enforcing","title":"Budget Not Enforcing","text":"<p>Check configuration: <pre><code># Verify settings loaded\ndocker exec zetherion-ai-bot python -c \"\nfrom zetherion_ai.config import get_settings\ns = get_settings()\nprint(f'Daily: {s.daily_budget_usd}')\nprint(f'Monthly: {s.monthly_budget_usd}')\nprint(f'Cost tracking: {s.cost_tracking_enabled}')\n\"\n</code></pre></p> <p>Ensure InferenceBroker enabled: <pre><code>INFERENCE_BROKER_ENABLED=true\nCOST_TRACKING_ENABLED=true\n</code></pre></p>"},{"location":"technical/cost-tracking/#notifications-not-sending","title":"Notifications Not Sending","text":"<p>Check notification configuration: <pre><code>NOTIFICATIONS_ENABLED=true\nBUDGET_WARNING_PCT=80.0\n</code></pre></p> <p>Verify Discord connection: <pre><code>docker-compose logs zetherion-ai-bot | grep -i notification\n</code></pre></p>"},{"location":"technical/cost-tracking/#database-issues","title":"Database Issues","text":"<p>Reset cost database (lose history): <pre><code>docker exec zetherion-ai-bot rm /app/data/costs.db\ndocker-compose restart zetherion-ai-bot\n</code></pre></p> <p>Backup before reset: <pre><code>docker cp zetherion-ai-bot:/app/data/costs.db ./costs_backup.db\n</code></pre></p>"},{"location":"technical/cost-tracking/#related-docs","title":"Related Docs","text":"<ul> <li>configuration.md -- All environment variables and settings</li> <li>architecture.md -- System architecture and service topology</li> </ul> <p>Last Updated: 2026-02-10 Version: 4.0.0 (Cost Tracking)</p>"},{"location":"technical/docker/","title":"Docker Services and Deployment","text":""},{"location":"technical/docker/#overview","title":"Overview","text":"<p>Zetherion AI runs as 6 Docker services connected via an internal bridge network (<code>zetherion-ai-net</code>). The architecture uses distroless base images for application services, pinned image digests for third-party services, and resource limits on every container. Two separate Ollama containers eliminate model-swapping delays by keeping dedicated models loaded in memory at all times.</p>"},{"location":"technical/docker/#service-overview","title":"Service Overview","text":"Service Image Port Purpose Memory (min-max) CPU (min-max) bot Distroless (custom) none Discord gateway, agent logic 512M - 2G 0.5 - 2.0 skills Distroless (custom) 8080 (internal) Skills REST API 128M - 512M 0.25 - 1.0 qdrant qdrant/qdrant (pinned digest) 6333 (host) Vector database 256M - 2G 0.25 - 2.0 postgres postgres:17-alpine 5432 (internal) Relational database 64M - 256M 0.25 - 1.0 ollama ollama/ollama (pinned digest) 11434 (host) LLM generation + embeddings 2G - 8G 1.0 - 4.0 ollama-router ollama/ollama (pinned digest) none Query classification 1.5G - 3G 0.5 - 2.0 <p>Total resource envelope: 4.5G - 16.25G memory, 2.75 - 12.0 CPU cores.</p>"},{"location":"technical/docker/#service-details","title":"Service Details","text":""},{"location":"technical/docker/#bot-service-zetherion-ai-bot","title":"Bot Service (zetherion-ai-bot)","text":"<p>The primary application container. Connects to Discord, runs the Agent Core, InferenceBroker, and security layer.</p> <ul> <li>Build: Custom <code>Dockerfile</code> using a Google distroless base image. No shell or package manager in the final image.</li> <li>Filesystem: Read-only root with <code>tmpfs</code> mounts at <code>/tmp</code> and <code>/home/nonroot/.cache</code> for writable temporary storage.</li> <li>Security: <code>no-new-privileges:true</code> prevents any privilege escalation.</li> <li>Dependencies: Waits for <code>qdrant</code> (healthy), <code>zetherion-ai-skills</code> (healthy), and <code>postgres</code> (healthy) before starting.</li> <li>Volumes:</li> <li><code>./data:/app/data</code> -- Persistent storage for encryption salt, SQLite cost database, and local state.</li> <li><code>./logs:/app/logs</code> -- Structured JSON log files with rotation (10MB x 6 files).</li> <li>Environment Variables:</li> <li><code>QDRANT_HOST=qdrant</code>, <code>QDRANT_PORT=6333</code></li> <li><code>OLLAMA_HOST=ollama</code>, <code>OLLAMA_PORT=11434</code></li> <li><code>OLLAMA_ROUTER_HOST=ollama-router</code>, <code>OLLAMA_ROUTER_PORT=11434</code></li> <li><code>SKILLS_SERVICE_URL=http://zetherion-ai-skills:8080</code></li> <li><code>POSTGRES_DSN=postgresql://zetherion:changeme@postgres:5432/zetherion</code></li> <li><code>ENVIRONMENT=production</code></li> <li>Additional secrets loaded from <code>.env</code> file.</li> <li>Resources: 512M reserved, 2G limit. 0.5 CPU reserved, 2.0 CPU limit.</li> <li>Ports: None exposed to host. Communicates only over the internal network.</li> </ul>"},{"location":"technical/docker/#skills-service-zetherion-ai-skills","title":"Skills Service (zetherion-ai-skills)","text":"<p>An aiohttp REST API that provides the pluggable skills framework. Registers and manages TaskManager, Calendar, Profile, Gmail, and GitHub skills.</p> <ul> <li>Build: Custom <code>Dockerfile.skills</code> using a Google distroless base image.</li> <li>Filesystem: Read-only root with <code>tmpfs</code> at <code>/tmp</code> and <code>/home/nonroot/.cache</code>.</li> <li>Security: <code>no-new-privileges:true</code>.</li> <li>Dependencies: Waits for <code>qdrant</code> (healthy) and <code>postgres</code> (healthy) before starting.</li> <li>Volumes: None. All persistent data is stored in PostgreSQL and Qdrant.</li> <li>Environment Variables:</li> <li><code>QDRANT_HOST=qdrant</code>, <code>QDRANT_PORT=6333</code></li> <li><code>OLLAMA_HOST=ollama</code>, <code>OLLAMA_PORT=11434</code></li> <li><code>OLLAMA_ROUTER_HOST=ollama-router</code>, <code>OLLAMA_ROUTER_PORT=11434</code></li> <li><code>POSTGRES_DSN=postgresql://zetherion:changeme@postgres:5432/zetherion</code></li> <li><code>SKILLS_HOST=0.0.0.0</code>, <code>SKILLS_PORT=8080</code></li> <li>Resources: 128M reserved, 512M limit. 0.25 CPU reserved, 1.0 CPU limit.</li> <li>Ports: 8080 (internal only). Not exposed to the host. Only the Bot Service communicates with this service via the internal Docker network.</li> <li>Authentication: Requires <code>X-API-Secret</code> header with HMAC token on all requests.</li> </ul>"},{"location":"technical/docker/#qdrant-zetherion-ai-qdrant","title":"Qdrant (zetherion-ai-qdrant)","text":"<p>Vector database for semantic memory storage. Provides cosine similarity search over encrypted embedding payloads.</p> <ul> <li>Image: <code>qdrant/qdrant:latest</code> pinned by SHA256 digest for reproducible builds. Dependabot automatically proposes digest updates.</li> <li>Security: <code>no-new-privileges:true</code>.</li> <li>Ports: 6333 exposed to host (provides both the REST API and the web dashboard).</li> <li>Volume: <code>qdrant_storage:/qdrant/storage</code> -- Persistent named volume for all vector data and indexes.</li> <li>Health Check: TCP connection test to port 6333 every 10 seconds, 5-second timeout, 5 retries, 10-second startup period.</li> <li>Resources: 256M reserved, 2G limit. 0.25 CPU reserved, 2.0 CPU limit.</li> <li>TLS: Certificate mount points are prepared in the compose file but commented out. Run <code>scripts/generate-qdrant-certs.sh</code> and uncomment the volume mounts to enable TLS.</li> </ul>"},{"location":"technical/docker/#postgresql-zetherion-ai-postgres","title":"PostgreSQL (zetherion-ai-postgres)","text":"<p>Relational database for user management, RBAC, dynamic settings, personal understanding data, Gmail state, and GitHub audit logs.</p> <ul> <li>Image: <code>postgres:17-alpine</code> -- Lightweight Alpine-based PostgreSQL 17.</li> <li>Security: <code>no-new-privileges:true</code>.</li> <li>Ports: Internal only. No port exposed to the host. Only the Bot Service and Skills Service connect via the internal network.</li> <li>Volume: <code>postgres_data:/var/lib/postgresql/data</code> -- Persistent named volume for all relational data.</li> <li>Health Check: <code>pg_isready -U zetherion</code> every 10 seconds, 5-second timeout, 5 retries, 10-second startup period.</li> <li>Resources: 64M reserved, 256M limit. 0.25 CPU reserved, 1.0 CPU limit.</li> <li>Default Credentials: <code>POSTGRES_DB=zetherion</code>, <code>POSTGRES_USER=zetherion</code>, <code>POSTGRES_PASSWORD=password</code>. These must be changed for production deployments.</li> </ul>"},{"location":"technical/docker/#ollama-generation-zetherion-ai-ollama","title":"Ollama Generation (zetherion-ai-ollama)","text":"<p>Local LLM container for privacy-sensitive inference and local embedding generation.</p> <ul> <li>Image: <code>ollama/ollama:latest</code> pinned by SHA256 digest.</li> <li>Security: <code>no-new-privileges:true</code>.</li> <li>Ports: 11434 exposed to host for debugging, direct model interaction, and health monitoring.</li> <li>Volume: <code>ollama_models:/root/.ollama</code> -- Persistent named volume for downloaded model weights. Models are downloaded once and cached across container restarts.</li> <li>Health Check: TCP connection test to port 11434 every 30 seconds, 10-second timeout, 3 retries, 60-second startup period. The longer startup period accounts for initial model loading.</li> <li>Resources: 2G reserved, 8G limit. 1.0 CPU reserved, 4.0 CPU limit.</li> <li>Models:</li> <li><code>llama3.1:8b</code> -- Primary generation model (8 billion parameters). Handles complex queries when privacy is required.</li> <li><code>nomic-embed-text</code> -- Local embedding model (768 dimensions). Ensures sensitive text never leaves the local network.</li> </ul>"},{"location":"technical/docker/#ollama-router-zetherion-ai-ollama-router","title":"Ollama Router (zetherion-ai-ollama-router)","text":"<p>Dedicated lightweight Ollama container for fast query classification. Keeps a small model loaded in memory at all times for sub-second routing decisions.</p> <ul> <li>Image: <code>ollama/ollama:latest</code> pinned by SHA256 digest (same image as generation container).</li> <li>Security: <code>no-new-privileges:true</code>.</li> <li>Ports: None exposed to host. Internal network access only.</li> <li>Volume: <code>ollama_router_models:/root/.ollama</code> -- Separate persistent volume from the generation container. Each container manages its own model cache independently.</li> <li>Health Check: TCP connection test to port 11434 every 30 seconds, 10-second timeout, 3 retries, 30-second startup period. Faster startup than the generation container due to the smaller model.</li> <li>Resources: 1.5G reserved, 3G limit. 0.5 CPU reserved, 2.0 CPU limit.</li> <li>Model: <code>llama3.2:3b</code> -- Small classification model (3 billion parameters). Fast enough for real-time query routing on CPU.</li> </ul>"},{"location":"technical/docker/#network-architecture","title":"Network Architecture","text":"<p>All 6 services are connected to a single Docker bridge network named <code>zetherion-ai-net</code>.</p> <pre><code>                    Host Machine\n                         |\n          +--------------+--------------+\n          |              |              |\n     port 6333      port 11434     (no other\n     (Qdrant)       (Ollama)      host ports)\n          |              |\n+---------+--------------+--------------+\n|            zetherion-ai-net            |\n|                                       |\n|  +-----+  +------+  +------+         |\n|  | bot |--| skills|--| qdrant|        |\n|  +--+--+  +--+---+  +-------+        |\n|     |        |                        |\n|  +--+--------+---+  +-------------+  |\n|  |   postgres    |  | ollama      |  |\n|  +---------------+  +-------------+  |\n|                      +-------------+  |\n|                      | ollama-     |  |\n|                      | router      |  |\n|                      +-------------+  |\n+---------------------------------------+\n</code></pre> <p>Service Discovery: Containers reference each other by container name (e.g., <code>http://qdrant:6333</code>, <code>http://zetherion-ai-skills:8080</code>). Docker's built-in DNS resolves these names to container IP addresses on the bridge network.</p> <p>Host Exposure: Only two services expose ports to the host: - Qdrant on port 6333 (dashboard and API access for debugging) - Ollama generation on port 11434 (direct model interaction for debugging)</p> <p>All other services (bot, skills, postgres, ollama-router) are accessible only from within the Docker network.</p>"},{"location":"technical/docker/#volumes","title":"Volumes","text":"Volume Type Service Purpose <code>qdrant_storage</code> Named qdrant Vector embeddings, indexes, and collection metadata <code>ollama_models</code> Named ollama Generation model weights (llama3.1:8b, nomic-embed-text) <code>ollama_router_models</code> Named ollama-router Router model weights (llama3.2:3b) <code>postgres_data</code> Named postgres Relational data (users, settings, profiles, Gmail, GitHub) <code>./data</code> Bind mount bot Encryption salt file, SQLite cost database, local state <code>./logs</code> Bind mount bot Structured JSON application logs with rotation <p>Named volumes are managed by Docker and persist across container restarts, removals, and image updates. Bind mounts (<code>./data</code>, <code>./logs</code>) map host directories directly into the container for easy access to logs and data files.</p>"},{"location":"technical/docker/#security-hardening","title":"Security Hardening","text":"<p>Every container in the stack is hardened with multiple security controls:</p> <p>Distroless Base Images (bot, skills) - No shell (<code>/bin/sh</code>, <code>/bin/bash</code>) present in the image - No package manager (<code>apt</code>, <code>apk</code>) available - Minimal filesystem containing only the Python runtime and application code - Significantly reduced attack surface compared to standard base images</p> <p>Read-Only Root Filesystem - The root filesystem is mounted read-only via <code>read_only: true</code> - Writable directories are provided through <code>tmpfs</code> mounts at <code>/tmp</code> and <code>/home/nonroot/.cache</code> - Prevents attackers from writing persistent malware or modifying application code</p> <p>No-New-Privileges - The <code>no-new-privileges:true</code> security option is set on all 6 containers - Prevents any process from gaining additional privileges via <code>setuid</code>, <code>setgid</code>, or capability escalation</p> <p>Resource Limits - Every container has both CPU and memory limits defined under the <code>deploy.resources</code> section - Prevents any single container from consuming all host resources - Protects against denial-of-service through resource exhaustion</p> <p>Network Isolation - All services communicate over an isolated Docker bridge network - Only 2 of 6 services expose ports to the host - PostgreSQL, Skills Service, and Ollama Router are completely internal</p>"},{"location":"technical/docker/#health-checks","title":"Health Checks","text":"<p>All services define health checks that Docker uses to determine readiness. The Bot Service depends on three other services being healthy before it starts, and the Skills Service depends on two.</p> Service Check Method Interval Timeout Retries Start Period bot Dockerfile HEALTHCHECK -- -- -- -- skills Dockerfile HEALTHCHECK -- -- -- -- qdrant TCP port 6333 10s 5s 5 10s postgres <code>pg_isready -U zetherion</code> 10s 5s 5 10s ollama TCP port 11434 30s 10s 3 60s ollama-router TCP port 11434 30s 10s 3 30s <p>Startup Order (enforced via <code>depends_on</code> with <code>condition: service_healthy</code>):</p> <ol> <li><code>qdrant</code> and <code>postgres</code> start first (no dependencies)</li> <li><code>zetherion-ai-skills</code> starts after <code>qdrant</code> and <code>postgres</code> are healthy</li> <li><code>zetherion-ai-bot</code> starts after <code>qdrant</code>, <code>postgres</code>, and <code>zetherion-ai-skills</code> are healthy</li> <li><code>ollama</code> and <code>ollama-router</code> start independently (no <code>depends_on</code> constraints from other services, but the bot connects to them at runtime)</li> </ol>"},{"location":"technical/docker/#dual-ollama-architecture","title":"Dual Ollama Architecture","text":"<p>The system runs two separate Ollama containers rather than a single shared instance. This is a deliberate architectural decision driven by Ollama's model management behavior.</p> <p>The Problem with a Single Container</p> <p>Ollama loads one model into memory at a time. When a request arrives for a different model, Ollama must: 1. Unload the current model from memory (1-3 seconds) 2. Load the requested model from disk (2-10 seconds depending on model size) 3. Process the request</p> <p>In a single-container setup, every routing request would trigger a model swap from the generation model to the router model, and every generation request would trigger a swap back. This adds 4-20 seconds of latency to every interaction.</p> <p>The Two-Container Solution</p> <ul> <li>ollama-router keeps <code>llama3.2:3b</code> (3B parameters) loaded at all times. This model is small enough to classify queries in under 500ms on CPU, and the container only needs 1.5G-3G of memory.</li> <li>ollama keeps <code>llama3.1:8b</code> (8B parameters) and <code>nomic-embed-text</code> loaded for generation and embedding tasks. This container has a larger resource allocation (2G-8G memory) to accommodate the bigger model.</li> </ul> <p>Each container maintains its own model cache via separate named volumes (<code>ollama_models</code> and <code>ollama_router_models</code>), ensuring that model downloads are independent and persistent.</p>"},{"location":"technical/docker/#gpu-support","title":"GPU Support","text":"<p>Optional NVIDIA GPU acceleration can be enabled for the Ollama generation container. This significantly improves inference speed for the 8B parameter model.</p> <p>To enable GPU support, modify the <code>ollama</code> service in <code>docker-compose.yml</code>:</p> <pre><code>ollama:\n  image: ollama/ollama:latest@sha256:...\n  container_name: zetherion-ai-ollama\n  deploy:\n    resources:\n      reservations:\n        devices:\n          - driver: nvidia\n            count: all\n            capabilities: [gpu]\n</code></pre> <p>Requirements: - NVIDIA GPU with CUDA support - NVIDIA Container Toolkit (<code>nvidia-docker2</code>) installed on the host - Docker runtime configured to use the NVIDIA runtime</p> <p>GPU acceleration is not required. The system runs entirely on CPU with acceptable performance for personal use.</p>"},{"location":"technical/docker/#managing-services","title":"Managing Services","text":""},{"location":"technical/docker/#starting-and-stopping","title":"Starting and Stopping","text":"<pre><code># Start all services in detached mode\ndocker-compose up -d\n\n# Stop all services and remove containers\ndocker-compose down\n\n# Stop all services and remove containers AND volumes (destroys data)\ndocker-compose down -v\n\n# Restart a single service\ndocker-compose restart zetherion-ai-bot\n\n# Rebuild and restart after code changes\ndocker-compose up -d --build\n</code></pre>"},{"location":"technical/docker/#monitoring","title":"Monitoring","text":"<pre><code># View logs for a specific service (follow mode)\ndocker-compose logs -f zetherion-ai-bot\n\n# View logs for all services\ndocker-compose logs -f\n\n# Check resource usage for all containers\ndocker stats\n\n# Check health status of all services\ndocker-compose ps\n</code></pre>"},{"location":"technical/docker/#model-management","title":"Model Management","text":"<pre><code># Pull the generation model into the ollama container\ndocker exec zetherion-ai-ollama ollama pull llama3.1:8b\n\n# Pull the embedding model\ndocker exec zetherion-ai-ollama ollama pull nomic-embed-text\n\n# Pull the router model into the router container\ndocker exec zetherion-ai-ollama-router ollama pull llama3.2:3b\n\n# List models in each container\ndocker exec zetherion-ai-ollama ollama list\ndocker exec zetherion-ai-ollama-router ollama list\n</code></pre>"},{"location":"technical/docker/#related-documentation","title":"Related Documentation","text":"<ul> <li>System Architecture -- High-level architecture, request flow, and component design</li> <li>Security Architecture -- Comprehensive security controls and threat model</li> <li>Configuration Guide -- Environment variables, settings hierarchy, and secrets management</li> </ul>"},{"location":"technical/gmail-architecture/","title":"Gmail Architecture","text":""},{"location":"technical/gmail-architecture/#overview","title":"Overview","text":"<p>The Gmail integration is a 12-file module (src/zetherion_ai/skills/gmail/) providing email management with a progressive trust system for reply automation.</p>"},{"location":"technical/gmail-architecture/#module-structure","title":"Module Structure","text":"File Purpose skill.py Entry point, intent routing (7 intents) trust.py Per-contact and per-type trust scoring accounts.py Multi-account management with encrypted tokens inbox.py Unified inbox aggregation digest.py Morning/evening/weekly digest generation replies.py AI-powered reply generation and classification analytics.py Email analytics and relationship scoring auth.py OAuth2 authentication client.py Gmail API client sync.py Email synchronization calendar_sync.py Calendar integration conflicts.py Calendar conflict detection"},{"location":"technical/gmail-architecture/#trust-system","title":"Trust System","text":""},{"location":"technical/gmail-architecture/#two-dimensional-trust","title":"Two-Dimensional Trust","text":"<p>Trust is tracked along two dimensions: 1. Type Trust: Per reply type (e.g., how much to trust acknowledgment replies globally) 2. Contact Trust: Per sender (e.g., how much to trust replies to your manager)</p>"},{"location":"technical/gmail-architecture/#effective-trust-calculation","title":"Effective Trust Calculation","text":"<pre><code>effective_trust = min(type_trust, contact_trust, reply_type_ceiling)\n</code></pre>"},{"location":"technical/gmail-architecture/#trust-evolution","title":"Trust Evolution","text":"Event Delta User approves draft +0.05 User makes minor edit -0.02 User makes major edit -0.10 User rejects draft -0.20 Floor 0.00 Global cap 0.95"},{"location":"technical/gmail-architecture/#reply-type-ceilings","title":"Reply Type Ceilings","text":"Reply Type Ceiling Rationale ACKNOWLEDGMENT 0.95 Low risk, formulaic MEETING_CONFIRM 0.90 Simple confirmation MEETING_DECLINE 0.80 Needs care with wording INFO_REQUEST 0.75 Content-dependent TASK_UPDATE 0.70 Context-dependent GENERAL 0.60 Variable risk NEGOTIATION 0.50 High stakes SENSITIVE 0.30 Highest risk"},{"location":"technical/gmail-architecture/#auto-send-decision","title":"Auto-Send Decision","text":"<p>A reply is auto-sent when BOTH conditions are met: - effective_trust &gt;= 0.85 - confidence &gt;= 0.85</p>"},{"location":"technical/gmail-architecture/#database-schema","title":"Database Schema","text":"<pre><code>gmail_type_trust (user_id, reply_type, score, approvals, rejections, edits, total_interactions)\ngmail_contact_trust (user_id, contact_email, score, approvals, rejections, edits, total_interactions)\n</code></pre>"},{"location":"technical/gmail-architecture/#reply-pipeline","title":"Reply Pipeline","text":"<ol> <li>Email received and classified by ReplyClassifier (keyword matching)</li> <li>Reply type determined (8 types from ACKNOWLEDGMENT to SENSITIVE)</li> <li>ReplyGenerator creates draft using InferenceBroker with type-specific templates</li> <li>Confidence score calculated: (ceiling * 0.7) + bonuses - penalties</li> <li>Trust check: if effective_trust &gt;= 0.85 AND confidence &gt;= 0.85, auto-send</li> <li>Otherwise, draft stored as PENDING for user review</li> <li>User approves/edits/rejects, trust evolves accordingly</li> </ol>"},{"location":"technical/gmail-architecture/#account-management","title":"Account Management","text":"<ul> <li>Multi-account support (first account = primary)</li> <li>OAuth tokens encrypted with AES-256-GCM before storage</li> <li>Token refresh handled automatically</li> <li>Sync state tracked per account (history_id, last sync timestamps)</li> </ul>"},{"location":"technical/gmail-architecture/#database-schema_1","title":"Database Schema","text":"<pre><code>gmail_accounts (id, user_id, email, access_token_encrypted, refresh_token_encrypted, token_expiry, scopes, is_primary, last_sync)\ngmail_sync_state (account_id, history_id, last_full_sync, last_partial_sync)\ngmail_drafts (id, email_id, account_id, draft_text, reply_type, confidence, status, sent_at)\n</code></pre>"},{"location":"technical/gmail-architecture/#digest-generation","title":"Digest Generation","text":"<p>Three digest types: - Morning: Unread summary by classification, today's volume, pending drafts - Evening: Day summary, drafted count, neglected threads (&gt;2 days) - Weekly: 7-day volume trends, top 5 contacts, classification breakdown, neglected threads (&gt;5 days)</p>"},{"location":"technical/gmail-architecture/#analytics","title":"Analytics","text":"<ul> <li>Contact relationship scoring: volume (log scale, 0.4 max) + recency (0.3 max) + response time (0.2 max)</li> <li>Period statistics: received/sent/drafted counts, average response time</li> <li>Top senders identification</li> <li>Neglected thread detection</li> </ul>"},{"location":"technical/gmail-architecture/#heartbeat-integration","title":"Heartbeat Integration","text":"<p>The Gmail skill provides heartbeat actions for periodic digest generation. When users have connected accounts, the scheduler triggers email_digest at configured intervals.</p>"},{"location":"technical/gmail-architecture/#related-docs","title":"Related Docs","text":"<p>Links to: architecture.md, security.md (OAuth, trust), configuration.md (Gmail vars)</p>"},{"location":"technical/observation-pipeline/","title":"Observation Pipeline","text":""},{"location":"technical/observation-pipeline/#overview","title":"Overview","text":"<p>The observation pipeline passively extracts facts, preferences, and context from user interactions. It operates alongside explicit commands, building understanding without requiring users to explicitly tell the bot everything.</p>"},{"location":"technical/observation-pipeline/#architecture","title":"Architecture","text":"<pre><code>User Input\n    |\n    v\n+---[Extraction]---+\n|  Tier 1: Regex   |---&gt; High confidence patterns\n|  Tier 2: LLM     |---&gt; Deeper context understanding\n+--------+---------+\n         |\n         v\n+---[Classification]---+\n|  Category assignment  |\n|  Confidence scoring   |\n+--------+-------------+\n         |\n         v\n+---[Storage]----------+\n|  PersonalLearning    |\n|  (PostgreSQL)        |\n+--------+-------------+\n         |\n         v\n+---[Integration]------+\n|  Profile building    |\n|  Context enrichment  |\n|  Response adaptation |\n+-----------------------+\n</code></pre>"},{"location":"technical/observation-pipeline/#extraction-tiers","title":"Extraction Tiers","text":""},{"location":"technical/observation-pipeline/#tier-1-pattern-based-regex","title":"Tier 1: Pattern-Based (Regex)","text":"<p>Fast, high-confidence extraction for explicit statements: - \"My name is X\" -&gt; Identity.name (confidence: 0.95) - \"I prefer X\" -&gt; Preferences (confidence: 0.85) - \"I work at X\" / \"I'm from X\" -&gt; Identity (confidence: 0.80) - \"I'm working on X\" -&gt; Projects (confidence: 0.75)</p> <p>Configure: PROFILE_TIER1_ONLY=true to disable LLM extraction.</p>"},{"location":"technical/observation-pipeline/#tier-2-llm-based","title":"Tier 2: LLM-Based","text":"<p>Deeper understanding via InferenceBroker: - Inferred preferences from conversation patterns - Relationship extraction from mentions - Schedule patterns from activity - Lower confidence, requires confirmation</p>"},{"location":"technical/observation-pipeline/#learning-categories","title":"Learning Categories","text":"Category Description Example PREFERENCE User preferences \"Prefers Python\" CONTACT Relationship info \"Works with Sarah\" SCHEDULE Time patterns \"Available mornings\" POLICY Action permissions \"Auto-reply to team\" CORRECTION User corrections \"Actually, I meant Go\" FACT General knowledge \"Has AWS certification\""},{"location":"technical/observation-pipeline/#learning-sources","title":"Learning Sources","text":"Source Description EXPLICIT User directly stated INFERRED Derived from behavior EMAIL Extracted from Gmail data CALENDAR From calendar events DISCORD From Discord messages"},{"location":"technical/observation-pipeline/#confidence-scoring","title":"Confidence Scoring","text":"<ul> <li>Explicit statements: 0.90-0.95</li> <li>Direct answers: 0.80-0.90</li> <li>Contextual mentions: 0.65-0.80</li> <li>Inferred from behavior: 0.40-0.60</li> </ul>"},{"location":"technical/observation-pipeline/#confirmation-flow","title":"Confirmation Flow","text":"<ul> <li>High confidence (&gt;= 0.90): Auto-applied</li> <li>Medium confidence (0.60-0.90): Applied, may request confirmation</li> <li>Low confidence (&lt; 0.60): Stored as pending, bot asks for confirmation</li> <li>Unconfirmed learnings expire after PROFILE_CONFIRMATION_EXPIRY_HOURS (default 72h)</li> </ul>"},{"location":"technical/observation-pipeline/#storage","title":"Storage","text":"<p>Learnings stored in PostgreSQL personal_learnings table: <pre><code>personal_learnings (id, user_id, category, content, confidence, source, confirmed, created_at)\n</code></pre></p>"},{"location":"technical/observation-pipeline/#integration-points","title":"Integration Points","text":"<ol> <li>Profile Building: Confirmed learnings update PersonalProfile</li> <li>Context Enrichment: Learnings added to LLM context for personalized responses</li> <li>Response Adaptation: Communication style adjusts based on learned preferences</li> <li>Proactive Actions: Schedule learnings inform heartbeat timing</li> </ol>"},{"location":"technical/observation-pipeline/#related-docs","title":"Related Docs","text":"<p>Links to: personal-understanding.md, architecture.md, configuration.md</p>"},{"location":"technical/personal-understanding/","title":"Personal Understanding","text":""},{"location":"technical/personal-understanding/#overview","title":"Overview","text":"<p>The Personal Understanding layer builds a comprehensive model of each user using PostgreSQL storage. It maintains profiles, a contact graph, action policies, and accumulated learnings.</p>"},{"location":"technical/personal-understanding/#data-model","title":"Data Model","text":""},{"location":"technical/personal-understanding/#personalprofile","title":"PersonalProfile","text":"<p>Core user identity and preferences: | Field | Type | Description | |-------|------|-------------| | user_id | int | Discord user ID (PK) | | display_name | str | User's preferred name | | timezone | str | Timezone (e.g., \"AEDT\") | | locale | str | Language/locale | | working_hours | JSON | {start, end, days} | | communication_style | JSON | {formality, verbosity, emoji_usage, humor} 0-1 scales | | goals | JSON[] | List of user goals | | preferences | JSON | Free-form key/value preferences |</p>"},{"location":"technical/personal-understanding/#personalcontact-contact-graph","title":"PersonalContact (Contact Graph)","text":"<p>Tracked relationships: | Field | Type | Description | |-------|------|-------------| | user_id | int | Owner | | contact_email | str | Contact identifier | | contact_name | str | Display name | | relationship | enum | COLLEAGUE, CLIENT, FRIEND, MANAGER, VENDOR, FAMILY, ACQUAINTANCE, OTHER | | importance | float | 0-1 importance score | | company | str | Organization | | interaction_count | int | Total interactions | | last_interaction | datetime | Most recent |</p>"},{"location":"technical/personal-understanding/#personalpolicy","title":"PersonalPolicy","text":"<p>Per-domain action permissions: | Field | Type | Description | |-------|------|-------------| | user_id | int | Owner | | domain | enum | EMAIL, CALENDAR, TASKS, GENERAL, DISCORD_OBSERVE | | action | str | Specific action | | mode | enum | AUTO, DRAFT, ASK, NEVER | | conditions | JSON | Optional approval conditions | | trust_score | float | Learned trust (0-1) |</p> <p>Policy Modes: - AUTO: Execute immediately - DRAFT: Create draft for review - ASK: Request explicit approval - NEVER: Block the action entirely</p>"},{"location":"technical/personal-understanding/#personallearning","title":"PersonalLearning","text":"<p>Accumulated observations: | Field | Type | Description | |-------|------|-------------| | user_id | int | Owner | | category | enum | PREFERENCE, CONTACT, SCHEDULE, POLICY, CORRECTION, FACT | | content | str | What was learned | | confidence | float | 0-1 confidence | | source | enum | EXPLICIT, INFERRED, EMAIL, CALENDAR, DISCORD | | confirmed | bool | User-confirmed |</p>"},{"location":"technical/personal-understanding/#postgresql-schema","title":"PostgreSQL Schema","text":"<pre><code>personal_profile (user_id PK, display_name, timezone, locale, working_hours JSONB, communication_style JSONB, goals JSONB, preferences JSONB, updated_at)\n\npersonal_contacts (id PK, user_id, contact_email, contact_name, relationship, importance, company, notes, last_interaction, interaction_count, updated_at)\nUNIQUE (user_id, contact_email)\n\npersonal_policies (id PK, user_id, domain, action, mode, conditions JSONB, trust_score, created_at, updated_at)\nUNIQUE (user_id, domain, action)\n\npersonal_learnings (id PK, user_id, category, content, confidence, source, confirmed, created_at)\n</code></pre>"},{"location":"technical/personal-understanding/#storage-layer-personalstorage","title":"Storage Layer (PersonalStorage)","text":"<p>CRUD operations via asyncpg connection pool: - Profile: upsert_profile, get_profile, delete_profile - Contacts: upsert_contact, list_contacts, increment_contact_interaction - Policies: upsert_policy, list_policies, update_trust_score, reset_domain_trust - Learnings: add_learning, list_learnings, confirm_learning, delete_learning</p>"},{"location":"technical/personal-understanding/#communication-style","title":"Communication Style","text":"<p>Four dimensions (0.0 to 1.0): | Dimension | Low (0.0) | High (1.0) | |-----------|-----------|------------| | Formality | Casual | Formal | | Verbosity | Terse | Detailed | | Emoji Usage | Never | Frequent | | Humor | Serious | Playful |</p> <p>Defaults configurable via DEFAULT_FORMALITY, DEFAULT_VERBOSITY.</p>"},{"location":"technical/personal-understanding/#contact-graph","title":"Contact Graph","text":"<ul> <li>Implicit graph via personal_contacts table</li> <li>Relationships typed (8 categories)</li> <li>Importance scored 0-1</li> <li>Interaction tracking (count + recency)</li> <li>Ordered by importance DESC, interaction_count DESC</li> <li>Used for: Gmail trust context, response personalization</li> </ul>"},{"location":"technical/personal-understanding/#policy-system","title":"Policy System","text":"<ul> <li>Per-domain policies control bot autonomy</li> <li>Trust scores learned from user feedback over time</li> <li>Domains: EMAIL, CALENDAR, TASKS, GENERAL, DISCORD_OBSERVE</li> <li>Supports conditional approval (JSON conditions field)</li> <li>Trust can be reset per domain</li> </ul>"},{"location":"technical/personal-understanding/#integration-with-gmail","title":"Integration with Gmail","text":"<ul> <li>Contact graph updated from email interactions</li> <li>Gmail trust scores separate but complementary</li> <li>Email policies control reply automation</li> <li>Calendar policies control scheduling</li> </ul>"},{"location":"technical/personal-understanding/#related-docs","title":"Related Docs","text":"<p>Links to: observation-pipeline.md, gmail-architecture.md, architecture.md, configuration.md</p>"},{"location":"technical/security/","title":"Security Model","text":""},{"location":"technical/security/#overview","title":"Overview","text":"<p>Zetherion AI implements a defense-in-depth security architecture spanning multiple layers: container hardening with distroless images, field-level encryption at rest using AES-256-GCM, role-based access control backed by PostgreSQL, prompt injection defense with 17 regex patterns and Unicode analysis, progressive trust for Gmail automation, and network isolation via Docker bridge networking. Each layer operates independently so that a breach at one level does not compromise the entire system.</p>"},{"location":"technical/security/#container-security","title":"Container Security","text":""},{"location":"technical/security/#distroless-images","title":"Distroless Images","text":"<p>The bot and skills services use Google's <code>gcr.io/distroless/python3-debian12:nonroot</code> as the runtime base image. Distroless images contain only the application and its runtime dependencies. They do not include:</p> <ul> <li>No shell (<code>/bin/sh</code>, <code>/bin/bash</code>)</li> <li>No package manager (<code>apt</code>, <code>yum</code>, <code>apk</code>)</li> <li>No system utilities (<code>curl</code>, <code>wget</code>, <code>nc</code>)</li> <li>No OS libraries beyond what the application requires</li> </ul> <p>This reduces the container image size by approximately 70% compared to <code>python:3.11-slim</code> and eliminates the tools an attacker would need for lateral movement, reconnaissance, or privilege escalation after gaining code execution.</p> <p>The image runs as the <code>nonroot</code> user (UID 65532) by default, preventing root-level filesystem access even if a container escape were attempted.</p>"},{"location":"technical/security/#runtime-hardening","title":"Runtime Hardening","text":"Control Detail Read-only root filesystem <code>read_only: true</code> in Docker Compose; writable paths via <code>tmpfs</code> for <code>/tmp</code> No new privileges <code>security_opt: no-new-privileges:true</code> on all containers Resource limits CPU and memory quotas via Docker Compose <code>deploy.resources</code> Network isolation All services communicate on a dedicated <code>zetherion_ai-net</code> bridge network Health checks TCP-based health checks with intervals, timeouts, retries, and start periods Restart policy <code>unless-stopped</code> for automatic recovery"},{"location":"technical/security/#encryption","title":"Encryption","text":""},{"location":"technical/security/#field-level-encryption","title":"Field-Level Encryption","text":"<p>All sensitive data stored in Qdrant and PostgreSQL is encrypted at the application layer before being written to disk.</p> <ul> <li>Algorithm: AES-256-GCM (authenticated encryption providing both confidentiality and integrity)</li> <li>Key derivation: PBKDF2-HMAC-SHA256 with 600,000 iterations (OWASP-recommended count)</li> <li>Salt: Random 256-bit (32 bytes), persisted at <code>ENCRYPTION_SALT_PATH</code></li> <li>Per-field encryption: Each field encryption generates a unique random 96-bit nonce/IV</li> <li>Tamper detection: GCM authentication tag detects any modification to ciphertext</li> </ul>"},{"location":"technical/security/#what-gets-encrypted","title":"What Gets Encrypted","text":"Collection / Store Encrypted Fields Plaintext Fields <code>conversations</code> <code>content</code> <code>user_id</code>, <code>channel_id</code>, <code>role</code>, <code>timestamp</code> <code>long_term_memory</code> <code>content</code> <code>type</code>, <code>timestamp</code>, metadata <code>user_profiles</code> <code>key</code>, <code>value</code> <code>category</code>, <code>confidence</code>, <code>user_id</code> <code>skill_tasks</code> <code>title</code>, <code>description</code> <code>status</code>, <code>priority</code>, <code>deadline</code> Gmail tokens <code>access_token</code>, <code>refresh_token</code> <code>user_id</code>, <code>expiry</code>"},{"location":"technical/security/#what-is-not-encrypted","title":"What Is NOT Encrypted","text":"<ul> <li>Vector embeddings: Required for similarity search in Qdrant. Encrypting embeddings would destroy the distance properties that make vector search possible.</li> <li>Metadata: Timestamps, IDs, user IDs, and other structural data needed for indexing and queries.</li> <li>Configuration data: Settings stored in PostgreSQL dynamic settings table.</li> </ul>"},{"location":"technical/security/#key-management","title":"Key Management","text":"<pre><code>ENCRYPTION_PASSPHRASE=minimum-16-character-passphrase\nENCRYPTION_SALT_PATH=data/salt.bin\n</code></pre> <ul> <li>The passphrase is loaded as a <code>SecretStr</code> and never stored in the database or logged.</li> <li>The salt file is generated automatically on first run and must be backed up. Loss of the salt file means loss of all encrypted data.</li> <li>Key rotation is supported via <code>KeyManager.rotate_key()</code> but requires a data migration step to re-encrypt all existing records.</li> </ul>"},{"location":"technical/security/#access-control","title":"Access Control","text":""},{"location":"technical/security/#user-allowlist","title":"User Allowlist","text":"<pre><code>ALLOWED_USER_IDS=123456789,987654321\n</code></pre> <ul> <li>When set, only the listed Discord user IDs can interact with the bot.</li> <li>When empty, all users are permitted (a warning is logged at startup).</li> <li>Checked on every incoming message before any processing occurs.</li> <li>Users can be added or removed at runtime via <code>UserAllowlist.add()</code> and <code>.remove()</code>.</li> </ul>"},{"location":"technical/security/#rbac-role-based-access-control","title":"RBAC (Role-Based Access Control)","text":"<p>PostgreSQL-backed user management provides three roles with distinct permission boundaries:</p> Role Permissions <code>owner</code> Full system control, manage admin users, change all settings <code>admin</code> Manage regular users, change non-critical settings <code>user</code> Standard bot interaction, no administrative capabilities <p>The bootstrap admin is set via the <code>OWNER_USER_ID</code> environment variable. This user is automatically assigned the <code>owner</code> role on first startup.</p> <p>RBAC is managed through the Skills Service API:</p> Endpoint Method Description <code>/users</code> POST Add a user with a specified role <code>/users/{id}/role</code> PATCH Change a user's role <code>/users/{id}</code> DELETE Remove a user's access <code>/users/audit</code> GET Retrieve the RBAC audit trail <p>All role changes are recorded in the PostgreSQL audit trail with timestamps, the acting user, and the action performed.</p>"},{"location":"technical/security/#skills-service-authentication","title":"Skills Service Authentication","text":"<p>All non-health endpoints on the Skills Service require an <code>X-API-Secret</code> header:</p> <ul> <li>The secret is configured via <code>SKILLS_API_SECRET</code> in the environment.</li> <li>Comparison uses HMAC-based constant-time comparison to prevent timing attacks.</li> <li>The health endpoint (<code>/health</code>) bypasses authentication to allow monitoring and orchestration tools to check service status.</li> </ul>"},{"location":"technical/security/#prompt-injection-defense","title":"Prompt Injection Defense","text":"<p>Every user message is checked before being forwarded to any LLM backend. The defense system is implemented in <code>src/zetherion_ai/discord/security.py</code> and operates in three layers:</p> <ol> <li> <p>Regex pattern matching: 17 case-insensitive patterns detect common injection techniques including \"ignore previous instructions\", \"you are now a...\", \"system prompt:\", \"jailbreak\", \"DAN mode\", and \"disable/bypass filters\" variations. Patterns account for spacing, punctuation, and phrasing differences.</p> </li> <li> <p>Unicode obfuscation detection: Compares NFKC-normalized text to the original. A length difference exceeding 10% indicates homoglyph substitution (for example, Cyrillic characters replacing Latin ones to bypass keyword filters).</p> </li> <li> <p>Roleplay marker heuristic: Flags messages containing more than 5 bracket pairs or <code>(system</code> markers, which indicate structured injection attempts.</p> </li> </ol> <p>Flagged messages are logged with the matched pattern and rejected before reaching any LLM. Graceful degradation ensures that if the Unicode check fails, it is skipped rather than crashing the message pipeline.</p>"},{"location":"technical/security/#gmail-security","title":"Gmail Security","text":""},{"location":"technical/security/#oauth-20-flow","title":"OAuth 2.0 Flow","text":"<p>Gmail integration uses the standard OAuth 2.0 authorization code flow:</p> <ul> <li>Scopes requested: <code>gmail.readonly</code> (minimum required), <code>gmail.send</code> (granted only when trust thresholds are met)</li> <li>Token storage: Access tokens and refresh tokens are encrypted at rest using the same AES-256-GCM field encryption used for all other sensitive data</li> <li>Token refresh: Handled automatically when the access token expires</li> <li>Configuration: Requires <code>GOOGLE_CLIENT_ID</code>, <code>GOOGLE_CLIENT_SECRET</code>, and <code>GOOGLE_REDIRECT_URI</code> environment variables</li> </ul>"},{"location":"technical/security/#progressive-trust-system","title":"Progressive Trust System","text":"<p>Gmail automation uses a two-dimensional trust model to gradually increase autonomy based on demonstrated reliability:</p> <p>Trust dimensions: - Contact trust: Trust level specific to a particular email contact, reflecting the history of interactions with that person - Reply type trust: Trust level specific to the category of reply (e.g., informational, scheduling, sensitive)</p> <p>Trust evolution: | User Action | Trust Delta | |-------------|------------| | Approval (send as-is) | +0.05 | | Minor edit (small changes) | -0.02 | | Major edit (significant rewrite) | -0.10 | | Rejection (discard draft) | -0.20 |</p> <p>Auto-send thresholds: - Trust starts at 0.0 for all new contacts and reply types - Auto-send requires: <code>effective_trust &gt;= 0.85</code> AND <code>confidence &gt;= 0.85</code> - Global trust cap: 0.95 (the system never becomes fully autonomous) - Reply type ceilings limit trust by category (e.g., <code>SENSITIVE</code> replies are capped at 0.30)</p>"},{"location":"technical/security/#trust-formula","title":"Trust Formula","text":"<pre><code>effective_trust = min(type_trust, contact_trust, reply_type_ceiling)\n</code></pre> <p>The effective trust is the minimum of the three values, ensuring that all dimensions must independently reach the threshold before automation is permitted. This prevents a high contact trust from overriding a low reply type ceiling for sensitive communications.</p>"},{"location":"technical/security/#github-security","title":"GitHub Security","text":"<ul> <li>The personal access token is stored in <code>.env</code> as <code>GITHUB_TOKEN</code> and loaded as a <code>SecretStr</code>. It is never stored in the database.</li> <li>Configurable autonomy levels control which actions the bot can perform without confirmation.</li> <li>High-risk actions (such as merging a pull request or deleting a branch) always require explicit user confirmation regardless of autonomy settings.</li> <li>All GitHub actions are logged in the audit trail with the action type, repository, and outcome.</li> </ul>"},{"location":"technical/security/#postgresql-security","title":"PostgreSQL Security","text":"Control Detail Network exposure Internal Docker network only; no host port mapping by default Credentials Stored in <code>.env</code> file, loaded via <code>POSTGRES_DSN</code> Connection Via internal Docker bridge network (<code>zetherion_ai-net</code>) Password policy Production deployments should use strong, randomly generated passwords Data stored RBAC users and roles, dynamic settings, audit trail, Gmail trust state <p>The PostgreSQL container is not exposed to the host network. Only containers on the <code>zetherion_ai-net</code> bridge can connect to it.</p>"},{"location":"technical/security/#network-security","title":"Network Security","text":"Control Detail Internal network All services communicate on the <code>zetherion_ai-net</code> Docker bridge network Host exposure Only Qdrant (6333) and Ollama (11434) are mapped to host ports (for development/testing) Bot/Skills communication Via internal network; no external ingress required External API calls All outbound API calls (Anthropic, OpenAI, Gemini, Discord) use HTTPS via <code>httpx</code> No inbound web server The bot connects outbound to Discord's WebSocket gateway and does not listen on any HTTP port"},{"location":"technical/security/#rate-limiting","title":"Rate Limiting","text":"Parameter Default Environment Variable Max messages per window 10 <code>RATE_LIMIT_MESSAGES</code> Window duration 60 seconds <code>RATE_LIMIT_WINDOW</code> Warning cooldown 30 seconds (hardcoded) <p>Rate limiting is per-user with automatic timestamp cleanup. When a user exceeds the limit, a warning message is returned, throttled to one warning per cooldown period to avoid spam.</p>"},{"location":"technical/security/#logging-and-audit","title":"Logging and Audit","text":"Layer Implementation Structured logging <code>structlog</code> with JSON output (production) or colored console (development) Log rotation <code>RotatingFileHandler</code>: 50MB max per file, 10 backup files Separate error log WARNING-level and above written to a dedicated error log file Credential protection <code>SecretStr</code> objects log as <code>'**********'</code>; passphrase never appears in logs RBAC audit trail All role changes recorded in PostgreSQL with timestamp, actor, and action Gmail trust events Trust score changes logged with contact, reply type, action, and new trust values GitHub actions All API operations logged with action type, repository, and result Security events Prompt injection attempts, allowlist changes, and rate limit triggers logged Third-party noise Discord and httpx loggers set to WARNING level"},{"location":"technical/security/#security-checklist","title":"Security Checklist","text":"<ul> <li>[ ] Set <code>ALLOWED_USER_IDS</code> to restrict access in production</li> <li>[ ] Set a strong <code>ENCRYPTION_PASSPHRASE</code> (minimum 16 characters, recommend 32+)</li> <li>[ ] Back up the salt file (<code>data/salt.bin</code>) securely and separately from the repository</li> <li>[ ] Set <code>SKILLS_API_SECRET</code> for Skills Service authentication</li> <li>[ ] Use a strong, randomly generated PostgreSQL password in <code>POSTGRES_DSN</code></li> <li>[ ] Review rate limit settings for your expected usage pattern</li> <li>[ ] Enable Message Content Intent in the Discord Developer Portal</li> <li>[ ] Never commit <code>.env</code> to version control</li> <li>[ ] Set <code>OWNER_USER_ID</code> for RBAC bootstrap</li> <li>[ ] Review Gmail OAuth scopes and trust thresholds before enabling email automation</li> <li>[ ] Store <code>GITHUB_TOKEN</code> only in <code>.env</code>, never in code or database</li> </ul>"},{"location":"technical/security/#related-docs","title":"Related Docs","text":"<ul> <li>Architecture -- System design and component interactions</li> <li>Configuration Reference -- Complete environment variable reference</li> <li>Docker Deployment -- Container setup and orchestration</li> </ul>"},{"location":"technical/skills-framework/","title":"Skills Framework","text":""},{"location":"technical/skills-framework/#overview","title":"Overview","text":"<p>The skills framework provides an extensible system for adding capabilities to Zetherion AI. Skills are self-contained modules that handle specific domains of functionality. Each skill is registered with a central registry, served via a REST API, and invoked based on classified user intents. Skills can also perform proactive actions through a heartbeat mechanism, contribute context to the LLM system prompt, and manage their own data storage independently.</p> <p>Key characteristics of a skill:</p> <ul> <li>Handles one or more specific intents (request types)</li> <li>Maintains its own persistent data storage</li> <li>Can perform proactive actions via periodic heartbeat calls</li> <li>Declares required permissions and access controls</li> <li>Contributes contextual fragments to the LLM system prompt</li> </ul>"},{"location":"technical/skills-framework/#architecture","title":"Architecture","text":"<pre><code>User Message -&gt; Router -&gt; Intent Classification -&gt; Skill Registry -&gt; Skill Handler -&gt; Response\n                                                        |\n                                                   Heartbeat Scheduler\n                                                   (proactive actions)\n</code></pre> <p>The skills service runs as a separate Docker container (<code>zetherion-ai-skills</code>) on port 8080, accessible only within the internal Docker network. The bot service communicates with skills via REST API calls authenticated with a shared secret.</p>"},{"location":"technical/skills-framework/#component-responsibilities","title":"Component Responsibilities","text":"Component Role Router Classifies incoming messages into intents Skill Registry Maintains the catalog of available skills and their intent mappings Skill Handler Dispatches requests to the correct skill based on intent Heartbeat Scheduler Periodically invokes <code>on_heartbeat()</code> on all skills for proactive behavior"},{"location":"technical/skills-framework/#skill-lifecycle","title":"Skill Lifecycle","text":"<p>Skills follow a well-defined lifecycle from registration through shutdown:</p>"},{"location":"technical/skills-framework/#1-registration","title":"1. Registration","text":"<p>Skills register with the <code>SkillRegistry</code> during service startup. Each skill provides metadata including its name, description, version, supported intents, and required permissions.</p> <pre><code>from zetherion_ai.skills.registry import SkillRegistry\n\nregistry = SkillRegistry()\nregistry.register(TaskManagerSkill())\nregistry.register(CalendarSkill())\nregistry.register(ProfileSkill())\nregistry.register(GmailSkill())\nregistry.register(GitHubSkill())\n</code></pre>"},{"location":"technical/skills-framework/#2-initialization","title":"2. Initialization","text":"<p>After registration, the registry calls <code>initialize()</code> on each skill. This method performs any required setup such as connecting to databases, validating configuration, or loading cached data. A skill that returns <code>True</code> from <code>initialize()</code> transitions to <code>READY</code> status. A skill that returns <code>False</code> is marked as <code>FAILED</code> and will not receive requests.</p>"},{"location":"technical/skills-framework/#3-handling","title":"3. Handling","text":"<p>During normal operation, the router classifies incoming user messages into intents. The registry maps each intent to its owning skill and dispatches a <code>SkillRequest</code>. The skill processes the request and returns a <code>SkillResponse</code>.</p>"},{"location":"technical/skills-framework/#4-heartbeat","title":"4. Heartbeat","text":"<p>The heartbeat scheduler periodically calls <code>on_heartbeat()</code> on all ready skills, passing the list of active user IDs. Skills can return <code>HeartbeatAction</code> objects representing proactive messages or notifications to send. The scheduler respects quiet hours and rate limits.</p>"},{"location":"technical/skills-framework/#5-cleanup","title":"5. Cleanup","text":"<p>On service shutdown, <code>cleanup()</code> is called on each skill, allowing it to release resources, close connections, and flush any pending data.</p>"},{"location":"technical/skills-framework/#built-in-skills","title":"Built-in Skills","text":""},{"location":"technical/skills-framework/#task-manager","title":"Task Manager","text":"<p>Manages tasks, todos, and projects with priorities, deadlines, and status tracking.</p> <ul> <li>Intents: <code>create_task</code>, <code>list_tasks</code>, <code>complete_task</code>, <code>delete_task</code>, <code>task_summary</code></li> <li>Features: Priority levels (CRITICAL, HIGH, MEDIUM, LOW), deadline tracking, status states (BACKLOG, TODO, IN_PROGRESS, BLOCKED, DONE, CANCELLED), project grouping, tag support</li> <li>Storage: Qdrant collection <code>skill_tasks</code> with vector embeddings for semantic search</li> <li>Heartbeat: Sends overdue task reminders and deadline approaching alerts</li> </ul>"},{"location":"technical/skills-framework/#calendar","title":"Calendar","text":"<p>Provides schedule awareness and availability checking. Currently operates in awareness mode, learning from conversation context rather than syncing with external calendar services.</p> <ul> <li>Intents: <code>check_schedule</code>, <code>work_hours</code>, <code>availability</code></li> <li>Features: Work hours tracking, availability checking, event reminders, recurring pattern detection, conflict detection</li> <li>Integration: Uses user profile working hours for schedule-aware behavior</li> <li>Storage: Qdrant collection for events and schedule data</li> </ul>"},{"location":"technical/skills-framework/#profile","title":"Profile","text":"<p>Manages user preferences, personal information, and learned context with confidence scoring.</p> <ul> <li>Intents: <code>show_profile</code>, <code>update_profile</code>, <code>delete_profile</code>, <code>export_data</code></li> <li>Features: 8-category learning system (Identity, Preferences, Schedule, Projects, Relationships, Skills, Goals, Habits), confidence scoring (0.0-1.0), GDPR-compliant data export</li> <li>Storage: SQLite for structured profile data, Qdrant for semantic profile search</li> <li>Confidence Thresholds: 0.9+ auto-applied, 0.6-0.9 may ask confirmation, below 0.6 always asks confirmation</li> </ul>"},{"location":"technical/skills-framework/#gmail","title":"Gmail","text":"<p>Multi-account email management with progressive trust and reply automation.</p> <ul> <li>Intents: <code>email_check</code>, <code>email_unread</code>, <code>email_drafts</code>, <code>email_digest</code>, <code>email_status</code>, <code>email_search</code>, <code>email_calendar</code></li> <li>Features: Multi-account support, progressive trust levels, automated reply drafting, email digest generation, calendar event extraction from emails</li> <li>Storage: PostgreSQL for email metadata and account configuration</li> <li>See: gmail-architecture.md for detailed architecture</li> </ul>"},{"location":"technical/skills-framework/#github","title":"GitHub","text":"<p>Repository management with configurable autonomy levels and pending action confirmation.</p> <ul> <li>Intents: <code>list_issues</code>, <code>get_issue</code>, <code>create_issue</code>, <code>update_issue</code>, <code>close_issue</code>, <code>reopen_issue</code>, <code>add_label</code>, <code>remove_label</code>, <code>add_comment</code>, <code>list_prs</code>, <code>get_pr</code>, <code>get_pr_diff</code>, <code>merge_pr</code>, <code>list_workflows</code>, <code>rerun_workflow</code>, <code>get_repo_info</code>, <code>set_autonomy</code>, <code>get_autonomy</code></li> <li>Features: Configurable autonomy levels (manual, semi-auto, full-auto), pending action queue with user confirmation, event-driven notifications, repository information caching</li> <li>Storage: Qdrant collections for issue and PR context</li> <li>See: user/github-integration.md for user-facing documentation</li> </ul>"},{"location":"technical/skills-framework/#skill-base-class","title":"Skill Base Class","text":"<p>All skills inherit from the <code>Skill</code> base class, which defines the interface that the registry and handler depend on:</p> <pre><code>class Skill:\n    @property\n    def metadata(self) -&gt; SkillMetadata:\n        \"\"\"Return skill metadata: name, description, version, permissions, intents.\"\"\"\n        ...\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Perform setup. Return True on success, False on failure.\"\"\"\n        ...\n\n    async def handle(self, request: SkillRequest) -&gt; SkillResponse:\n        \"\"\"Handle an intent-matched request and return a response.\"\"\"\n        ...\n\n    async def on_heartbeat(self, user_ids: list[str]) -&gt; list[HeartbeatAction]:\n        \"\"\"Return proactive actions for the given users. Called periodically.\"\"\"\n        ...\n\n    def get_system_prompt_fragment(self, user_id: str) -&gt; str | None:\n        \"\"\"Return a context string to include in the LLM system prompt, or None.\"\"\"\n        ...\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"Release resources on shutdown.\"\"\"\n        ...\n</code></pre>"},{"location":"technical/skills-framework/#skillmetadata","title":"SkillMetadata","text":"<pre><code>@dataclass\nclass SkillMetadata:\n    name: str                    # Unique skill identifier (e.g., \"task_manager\")\n    description: str             # Human-readable description\n    version: str                 # Semantic version (e.g., \"1.0.0\")\n    intents: list[str]           # Intents this skill handles\n    permissions: list[str]       # Required permissions\n</code></pre>"},{"location":"technical/skills-framework/#skillrequest-and-skillresponse","title":"SkillRequest and SkillResponse","text":""},{"location":"technical/skills-framework/#skillrequest","title":"SkillRequest","text":"<p>Represents an incoming request dispatched to a skill by the handler:</p> <pre><code>@dataclass\nclass SkillRequest:\n    id: UUID                     # Unique request identifier\n    skill_name: str              # Target skill name\n    intent: str                  # Classified intent\n    user_id: str                 # Requesting user's ID\n    message: str                 # Original user message\n    context: dict[str, Any]      # Additional context (channel_id, guild_id, etc.)\n</code></pre>"},{"location":"technical/skills-framework/#skillresponse","title":"SkillResponse","text":"<p>Represents the result returned by a skill after processing a request:</p> <pre><code>@dataclass\nclass SkillResponse:\n    request_id: UUID             # Matches the originating SkillRequest.id\n    success: bool = True         # Whether the request was handled successfully\n    message: str = \"\"            # Human-readable response message\n    data: dict = {}              # Structured response data\n    error: str | None = None     # Error description if success is False\n</code></pre>"},{"location":"technical/skills-framework/#permissions","title":"Permissions","text":"<p>Skills declare required permissions in their metadata. The registry enforces these permissions before dispatching requests. Available permissions:</p> Permission Description <code>READ_MEMORIES</code> Access stored memories in Qdrant <code>WRITE_MEMORIES</code> Store new data in Qdrant <code>READ_PROFILE</code> Access user profile information <code>SEND_MESSAGES</code> Send messages to Discord channels"},{"location":"technical/skills-framework/#declaring-permissions","title":"Declaring Permissions","text":"<pre><code>from zetherion_ai.skills.permissions import Permission, PermissionSet\n\nclass MySkill(Skill):\n    @property\n    def required_permissions(self) -&gt; PermissionSet:\n        return PermissionSet([\n            Permission.READ_MEMORIES,\n            Permission.WRITE_MEMORIES,\n            Permission.SEND_MESSAGES,\n        ])\n</code></pre>"},{"location":"technical/skills-framework/#heartbeat-system","title":"Heartbeat System","text":"<p>The heartbeat system enables skills to perform proactive actions without waiting for user input. The scheduler calls <code>on_heartbeat()</code> on all ready skills at a configurable interval.</p>"},{"location":"technical/skills-framework/#heartbeataction","title":"HeartbeatAction","text":"<pre><code>@dataclass\nclass HeartbeatAction:\n    skill_name: str              # Originating skill\n    action_type: str             # Type of action (e.g., \"send_message\")\n    user_id: str                 # Target user\n    data: dict                   # Action-specific payload\n    priority: int                # 1 = highest, 10 = lowest\n</code></pre>"},{"location":"technical/skills-framework/#behavior-and-constraints","title":"Behavior and Constraints","text":"<ul> <li>Actions are sorted by priority before execution (1 is highest, 10 is lowest)</li> <li>The scheduler respects quiet hours derived from the user's configured working hours</li> <li>Rate limiting caps the maximum number of actions per heartbeat cycle</li> <li>If multiple skills produce actions for the same user, they are interleaved by priority</li> </ul>"},{"location":"technical/skills-framework/#common-heartbeat-use-cases","title":"Common Heartbeat Use Cases","text":"Skill Action Priority Task Manager Overdue task reminders 2 Task Manager Deadline approaching alerts (24h) 4 Gmail Unread email digest 3 Gmail High-priority email notification 1 Calendar Upcoming meeting reminder 2"},{"location":"technical/skills-framework/#prompt-fragments","title":"Prompt Fragments","text":"<p>Skills contribute real-time context to the LLM system prompt via <code>get_system_prompt_fragment()</code>. This allows the LLM to be aware of the current state of each skill without requiring explicit user queries.</p>"},{"location":"technical/skills-framework/#examples","title":"Examples","text":"<pre><code>[GitHub: 2 action(s) pending confirmation]\n[Tasks: 3 open, 1 overdue]\n[Gmail: 5 unread across 2 accounts]\n[Calendar: Next meeting in 45 minutes - Sprint Review]\n</code></pre> <p>The bot aggregates all non-None fragments and injects them into the system prompt before each LLM call. This gives the model awareness of pending actions, outstanding tasks, and other skill state.</p>"},{"location":"technical/skills-framework/#intent-routing","title":"Intent Routing","text":"<p>The router classifies user messages into intents and maps them to skills. Classification uses a combination of keyword matching and LLM-based intent detection for ambiguous messages.</p>"},{"location":"technical/skills-framework/#intent-to-skill-mapping","title":"Intent-to-Skill Mapping","text":"Intent Pattern Skill Example Messages <code>create_task</code>, <code>list_tasks</code>, <code>complete_task</code>, <code>delete_task</code>, <code>task_summary</code> TaskManager \"add task: review PR\", \"what are my tasks?\" <code>check_schedule</code>, <code>work_hours</code>, <code>availability</code> Calendar \"am I free at 3pm?\", \"show my schedule\" <code>show_profile</code>, <code>update_profile</code>, <code>delete_profile</code>, <code>export_data</code> Profile \"show my profile\", \"export my data\" <code>email_check</code>, <code>email_unread</code>, <code>email_drafts</code>, <code>email_digest</code>, <code>email_status</code>, <code>email_search</code>, <code>email_calendar</code> Gmail \"check my email\", \"email digest\" <code>list_issues</code>, <code>create_issue</code>, <code>get_pr</code>, <code>merge_pr</code>, <code>list_workflows</code>, etc. GitHub \"list open issues\", \"merge PR #42\" <code>SIMPLE_QUERY</code> Agent (direct) \"what is a binary tree?\" <code>COMPLEX_TASK</code> Agent (complex) \"help me debug this error\" <code>MEMORY_STORE</code> Memory \"remember that I prefer Python\" <code>MEMORY_RECALL</code> Memory \"what did I say about the API?\""},{"location":"technical/skills-framework/#routing-configuration","title":"Routing Configuration","text":"<p>The skills service URL and authentication are configured via environment variables:</p> <pre><code># Skills service URL (Docker internal network)\nSKILLS_SERVICE_URL=http://zetherion-ai-skills:8080\n\n# API authentication\nSKILLS_API_SECRET=your-secret-here\n\n# Request timeout in seconds\nSKILLS_REQUEST_TIMEOUT=30\n</code></pre>"},{"location":"technical/skills-framework/#creating-custom-skills","title":"Creating Custom Skills","text":"<p>To add a new skill to Zetherion AI:</p> <ol> <li>Create a class that inherits from <code>Skill</code></li> <li>Implement the required methods (<code>metadata</code>, <code>initialize</code>, <code>handle</code>)</li> <li>Optionally implement <code>on_heartbeat</code>, <code>get_system_prompt_fragment</code>, and <code>cleanup</code></li> <li>Register the skill with the <code>SkillRegistry</code> in the service startup code</li> <li>Add intent keywords to the router configuration if using keyword-based classification</li> </ol> <pre><code>from zetherion_ai.skills.base import Skill, SkillMetadata, SkillRequest, SkillResponse\n\nclass WeatherSkill(Skill):\n    @property\n    def metadata(self) -&gt; SkillMetadata:\n        return SkillMetadata(\n            name=\"weather\",\n            description=\"Check weather conditions and forecasts\",\n            version=\"1.0.0\",\n            intents=[\"check_weather\", \"weather_forecast\"],\n            permissions=[\"SEND_MESSAGES\"],\n        )\n\n    async def initialize(self) -&gt; bool:\n        # Validate API key, warm up caches, etc.\n        return True\n\n    async def handle(self, request: SkillRequest) -&gt; SkillResponse:\n        if request.intent == \"check_weather\":\n            result = await self._get_current_weather(request.message)\n        else:\n            result = await self._get_forecast(request.message)\n\n        return SkillResponse(\n            request_id=request.id,\n            success=True,\n            message=result,\n        )\n\n    async def cleanup(self) -&gt; None:\n        pass\n</code></pre> <p>For detailed guidance on building and testing custom skills, see Adding a Skill.</p>"},{"location":"technical/skills-framework/#related-docs","title":"Related Docs","text":"<ul> <li>api-reference.md -- REST API endpoints for the skills service</li> <li>architecture.md -- Overall system architecture</li> <li>Adding a Skill -- Step-by-step guide for creating new skills</li> <li>gmail-architecture.md -- Gmail skill deep dive</li> <li>security.md -- Authentication and access control</li> </ul> <p>Last Updated: 2026-02-10 Version: 4.0.0 (Skills Framework)</p>"},{"location":"user/commands/","title":"Commands Reference","text":"<p>Complete reference for all Zetherion AI commands. Discord is the first supported input interface, but the underlying skills and agent core are source-agnostic. This reference covers slash commands, natural language interactions, Gmail integration, GitHub integration, task management, profile management, and cost tracking.</p>"},{"location":"user/commands/#quick-reference","title":"Quick Reference","text":"Command Type Description Example <code>/ask</code> Slash Command Ask a question (routes to optimal LLM) <code>/ask What is Python?</code> <code>/remember</code> Slash Command Store a memory <code>/remember I prefer dark mode</code> <code>/search</code> Slash Command Search memories <code>/search preferences</code> <code>/ping</code> Slash Command Check bot status and latency <code>/ping</code> DM Direct Message Talk naturally, no prefix needed Just send a message @mention Server Message Ask in a server channel <code>@Zetherion AI help me</code> \"Check my email\" Natural Language Check email inbox summary <code>@Zetherion AI check my email</code> \"List issues\" Natural Language List GitHub issues <code>@Zetherion AI list issues</code> \"Add task: ...\" Natural Language Create a new task <code>@Zetherion AI add task: Review PR</code> \"Show my profile\" Natural Language View your learned profile <code>@Zetherion AI show my profile</code> \"Remember that ...\" Natural Language Store a memory <code>Remember that I use VS Code</code> \"Search for ...\" Natural Language Semantic memory search <code>Search for my project notes</code>"},{"location":"user/commands/#slash-commands","title":"Slash Commands","text":""},{"location":"user/commands/#ask-ask-a-question","title":"<code>/ask</code> -- Ask a Question","text":"<p>Ask Zetherion AI a question or request help with a task. The bot analyzes intent and complexity, then routes your query to the best-suited model.</p> <p>Syntax: <pre><code>/ask &lt;question&gt;\n</code></pre></p> <p>Parameters: - <code>question</code> (required) -- Your question or request</p> <p>Examples: <pre><code>/ask What is the capital of France?\n/ask Explain async/await in Python\n/ask Write a function to reverse a string\n/ask Help me debug this error: TypeError...\n</code></pre></p> <p>Routing behavior:</p> <ul> <li>The router classifies your query by intent and complexity, then dispatches to the provider you've configured for that task type</li> <li>You choose between local inference (Ollama) and cloud providers (Gemini, Claude, OpenAI) -- see the LLM Provider Configuration section in the README</li> <li>Routing classification can use Gemini Flash (cloud) or Ollama Llama 3.2 1B (local), depending on your setup</li> <li>The bot searches recent conversation history and relevant memories to provide context</li> </ul> <p>Expected response time: - Simple queries: 1--3 seconds - Complex tasks: 5--15 seconds</p>"},{"location":"user/commands/#remember-store-a-memory","title":"<code>/remember</code> -- Store a Memory","text":"<p>Store information in long-term memory for later retrieval.</p> <p>Syntax: <pre><code>/remember &lt;content&gt;\n</code></pre></p> <p>Parameters: - <code>content</code> (required) -- What you want the bot to remember</p> <p>Examples: <pre><code>/remember I prefer dark mode in all applications\n/remember My birthday is March 15th\n/remember Project deadline is next Friday\n</code></pre></p> <p>Behavior: - Content is stored in the Qdrant vector database - Embedded using Gemini text-embedding-004 for semantic search - Persists across bot restarts - Automatically recalled in relevant future conversations</p>"},{"location":"user/commands/#search-search-memories","title":"<code>/search</code> -- Search Memories","text":"<p>Search your stored memories by semantic similarity.</p> <p>Syntax: <pre><code>/search &lt;query&gt;\n</code></pre></p> <p>Parameters: - <code>query</code> (required) -- What to search for</p> <p>Examples: <pre><code>/search preferences\n/search birthday\n/search Python projects\n</code></pre></p> <p>Behavior: - Uses vector similarity, not keyword matching - Returns the top 5 most relevant memories with similarity scores - Sorted by relevance</p>"},{"location":"user/commands/#ping-check-bot-status","title":"<code>/ping</code> -- Check Bot Status","text":"<p>Verify the bot is online and check latency.</p> <p>Syntax: <pre><code>/ping\n</code></pre></p> <p>Parameters: None</p> <p>Expected response: <pre><code>Pong! Latency: 45ms\n</code></pre></p> <p>Response time: Under 500ms. The response is ephemeral (only visible to you).</p>"},{"location":"user/commands/#natural-language-commands","title":"Natural Language Commands","text":"<p>Zetherion AI understands natural language. You do not need to memorize specific syntax. The examples below show common phrasings, but the bot will understand reasonable variations of each.</p> <p>Natural language commands work via Direct Messages (no prefix needed) or via @mention in a server channel.</p>"},{"location":"user/commands/#asking-questions","title":"Asking Questions","text":"<p>The bot automatically detects the complexity of your question and routes it to the appropriate model.</p> <p>Simple questions are routed to your configured fast provider (e.g. Gemini Flash or Ollama): <pre><code>Hello!\nWhat's 2 + 2?\nGood morning\nThanks for your help!\n</code></pre></p> <p>Complex questions are routed to your configured reasoning provider (e.g. Claude, GPT, or local Ollama): <pre><code>Write a Python function to validate email addresses\nExplain how transformers work in detail\nHelp me design a REST API for a blog\nDebug this code: [code snippet]\n</code></pre></p> <p>Routing logic:</p> <ul> <li>The router classifies your message by intent and complexity (using Gemini Flash or local Llama 3.2 1B, depending on your configuration)</li> <li>If the query is classified as complex, it is dispatched to your configured reasoning provider</li> <li>Simple queries go to your configured fast provider</li> <li>You control which providers handle which task types -- see the LLM Provider Configuration section in the README</li> </ul>"},{"location":"user/commands/#memory-commands","title":"Memory Commands","text":"<p>Store a memory: <pre><code>Remember that I prefer tabs over spaces\nNote: Project uses PostgreSQL\nKeep in mind that I'm in PST timezone\nDon't forget my favorite color is blue\n</code></pre></p> <p>Recall memories: <pre><code>What do you know about me?\nWhat did we discuss yesterday?\nWhat do you remember about my projects?\nTell me about my preferences\n</code></pre></p> <p>Search memories: <pre><code>Search for my project notes\nSearch for deadlines\nSearch for food preferences\n</code></pre></p> <p>The bot uses semantic similarity search, so you do not need to use exact keywords. Asking \"What are my coding preferences?\" will find memories about tabs, spaces, editors, and similar topics.</p>"},{"location":"user/commands/#gmail-commands","title":"Gmail Commands","text":"<p>Zetherion AI can connect to your Gmail account to check emails, generate digests, and search your inbox from Discord. See the Gmail Integration Guide for full setup instructions.</p> <p>Check email: <pre><code>Check my email\n</code></pre> Triggers the <code>email_check</code> intent. Shows total count, unread count, and high-priority items.</p> <p>Show unread emails: <pre><code>Show unread emails\nShow my unread messages\n</code></pre> Triggers the <code>email_unread</code> intent. Lists up to 5 unread emails with subject and sender.</p> <p>Show drafts: <pre><code>Show my drafts\nList my email drafts\n</code></pre> Triggers the <code>email_drafts</code> intent. Lists pending reply drafts awaiting your review.</p> <p>Email digest: <pre><code>Give me an email digest\nMorning digest\nEvening digest\nWeekly digest\n</code></pre> Triggers the <code>email_digest</code> intent. Generates a summary organized by priority and topic.</p> <p>Gmail status: <pre><code>Gmail status\nShow Gmail connection status\n</code></pre> Triggers the <code>email_status</code> intent. Shows connected accounts and last sync time.</p> <p>Search emails: <pre><code>Search emails for invoice\nFind emails about project update\nSearch my email for meeting notes\n</code></pre> Triggers the <code>email_search</code> intent. Searches by subject and sender across connected accounts.</p>"},{"location":"user/commands/#github-commands","title":"GitHub Commands","text":"<p>Zetherion AI integrates with GitHub to manage issues, pull requests, and CI workflows directly from Discord.</p> <p>List issues: <pre><code>List issues\nShow open issues\nWhat issues are open?\n</code></pre> Triggers the <code>list_issues</code> action. Lists open issues in the configured repository.</p> <p>View a specific issue: <pre><code>Show issue #42\nWhat's issue #42 about?\n</code></pre> Triggers the <code>get_issue</code> action. Displays the issue title, body, labels, and status.</p> <p>Create an issue: <pre><code>Create issue: Fix login button alignment\nCreate issue: Add dark mode support\n</code></pre> Triggers the <code>create_issue</code> action. Requires confirmation unless autonomy is set to autonomous for this action.</p> <p>Close an issue: <pre><code>Close issue #42\n</code></pre> Triggers the <code>close_issue</code> action.</p> <p>List pull requests: <pre><code>List PRs\nShow pull requests\nWhat PRs are open?\n</code></pre> Triggers the <code>list_prs</code> action.</p> <p>View a pull request: <pre><code>Show PR #10\nWhat's PR #10 about?\n</code></pre> Triggers the <code>get_pr</code> action. Displays the PR title, description, review status, and merge status.</p> <p>View a PR diff: <pre><code>Show PR diff #10\nWhat changed in PR #10?\n</code></pre> Triggers the <code>get_pr_diff</code> action. Displays the file changes in the pull request.</p> <p>Merge a pull request: <pre><code>Merge PR #10\n</code></pre> Triggers the <code>merge_pr</code> action. This always requires explicit confirmation, regardless of autonomy settings.</p> <p>List workflows / CI status: <pre><code>List workflows\nShow CI status\nWhat's the build status?\n</code></pre> Triggers the <code>list_workflows</code> action.</p> <p>Repository info: <pre><code>Repo info\nShow repository information\n</code></pre> Triggers the <code>get_repo_info</code> action.</p> <p>Set autonomy level: <pre><code>Set autonomy for create_issue to autonomous\nSet autonomy for close_issue to confirm\n</code></pre> Triggers the <code>set_autonomy</code> action. Controls whether actions require confirmation.</p> <p>View autonomy settings: <pre><code>Show autonomy settings\nWhat are my autonomy settings?\n</code></pre> Triggers the <code>get_autonomy</code> action.</p>"},{"location":"user/commands/#task-commands","title":"Task Commands","text":"<p>Manage personal tasks and to-do items through Discord.</p> <p>Create a task: <pre><code>Add task: Review PR #123\nAdd task: Update documentation\nCreate task: Deploy to staging\n</code></pre></p> <p>List tasks: <pre><code>List my tasks\nShow my to-do list\nWhat tasks do I have?\n</code></pre></p> <p>Complete a task: <pre><code>Complete task 1\nMark task 1 as done\nFinish task 1\n</code></pre></p> <p>Delete a task: <pre><code>Delete task 2\nRemove task 2\n</code></pre></p>"},{"location":"user/commands/#profile-commands","title":"Profile Commands","text":"<p>Zetherion AI learns about you over time. You can view, update, and manage your profile data.</p> <p>View your profile: <pre><code>Show my profile\nWhat do you know about me?\nDisplay my profile info\n</code></pre> Displays all learned information the bot has stored about you (name, location, preferences, and more).</p> <p>Update profile fields: <pre><code>Update my name to James\nSet my timezone to PST\nMy location is London\n</code></pre></p> <p>Remove profile data: <pre><code>Forget my location\nRemove my timezone\nClear my name\n</code></pre></p> <p>Export your data (GDPR): <pre><code>Export my data\nDownload my data\nGive me all my data\n</code></pre> Generates a full export of all data the bot holds about you.</p> <p>Delete all your data: <pre><code>Delete all my data\nErase everything about me\nRemove all my information\n</code></pre> Permanently deletes all stored data. This action requires confirmation before proceeding.</p>"},{"location":"user/commands/#cost-commands","title":"Cost Commands","text":"<p>Cost tracking is handled automatically by the system and is not triggered by direct user commands. Costs are tracked per-model and per-user. Information about costs appears in:</p> <ul> <li>Daily summary reports (generated by the heartbeat scheduler)</li> <li>Admin dashboards and logs</li> <li>Per-request metadata (visible in debug mode)</li> </ul> <p>The 6 Docker services that make up Zetherion AI each contribute to overall resource usage, and cost tracking covers all external API calls to Claude Sonnet 4.5, GPT-5.2, and Gemini 2.5 Flash.</p>"},{"location":"user/commands/#direct-messages","title":"Direct Messages","text":"<p>You can message Zetherion AI directly for a private conversation.</p> <p>How to start a DM: 1. Find Zetherion AI in your server member list 2. Right-click and select \"Message\" 3. Type your message naturally</p> <p>Key points: - No prefix or slash command is needed. Just type normally. - All functionality is available: asking questions, storing memories, Gmail commands, GitHub commands, tasks, and profile management. - Conversation history is maintained across sessions. - DMs are more private than server messages.</p> <p>Examples: <pre><code>Hello!\nWhat can you help me with?\nRemember that I prefer Python 3.12\nCheck my email\nList issues\nShow my profile\n</code></pre></p>"},{"location":"user/commands/#mentions","title":"Mentions","text":"<p>In server channels, mention the bot to get its attention.</p> <p>Syntax: <pre><code>@Zetherion AI &lt;your message&gt;\n</code></pre></p> <p>Examples: <pre><code>@Zetherion AI what's the best way to learn Python?\n@Zetherion AI remember our team meeting is every Monday\n@Zetherion AI check my email\n@Zetherion AI show open issues\n</code></pre></p> <p>Behavior: - The bot only responds when explicitly mentioned. - The mention prefix is stripped from your message before processing. - Responses are public (visible to everyone in the channel). - All functionality is the same as via DM or slash commands.</p> <p>Empty mention: <pre><code>@Zetherion AI\n</code></pre> The bot will respond with a prompt asking how it can help.</p>"},{"location":"user/commands/#rate-limits","title":"Rate Limits","text":"<p>Default configuration:</p> Setting Value Max messages per user 10 Time window 60 seconds Warning cooldown 30 seconds <p>Behavior: 1. A user can send up to 10 messages within a 60-second window. 2. The 11th message within that window is blocked, and a warning is shown. 3. Additional messages within the 30-second warning cooldown are silently blocked. 4. After 60 seconds from the first message, the counter resets.</p> <p>If you are rate limited, the bot will respond with: <pre><code>You're sending messages too quickly. Please wait a moment before trying again.\n</code></pre></p>"},{"location":"user/commands/#permissions","title":"Permissions","text":""},{"location":"user/commands/#permissions-the-bot-requires-in-discord","title":"Permissions the Bot Requires in Discord","text":"Permission Reason Send Messages To respond to commands and queries Read Message History To load conversation context Use Slash Commands For <code>/ask</code>, <code>/remember</code>, <code>/search</code>, <code>/ping</code> Embed Links For rich formatting in responses View Channels To see channels where it is mentioned"},{"location":"user/commands/#permissions-users-need","title":"Permissions Users Need","text":"Permission Reason Send Messages To use any command Read Message History For context-aware conversations View Channel To interact in channels where the bot is present"},{"location":"user/commands/#allowlist","title":"Allowlist","text":"<p>By default, all users can interact with the bot. To restrict access:</p> <pre><code># In .env -- comma-separated Discord user IDs\nALLOWED_USER_IDS=123456789,987654321\n</code></pre> <p>Leave the value empty to allow all users: <pre><code>ALLOWED_USER_IDS=\n</code></pre></p>"},{"location":"user/commands/#security-notes","title":"Security Notes","text":"<ul> <li>All messages pass through prompt injection detection before processing.</li> <li>Unauthorized users receive a clear rejection message.</li> <li>Rate limiting is enforced per user to prevent abuse.</li> <li>Gmail OAuth tokens are stored securely and email content is encrypted at rest.</li> <li>GitHub actions that modify state (create issue, close issue, merge PR) require confirmation unless autonomy settings have been explicitly changed.</li> </ul>"},{"location":"user/commands/#related-guides","title":"Related Guides","text":"<ul> <li>Gmail Integration -- Full setup and usage guide for Gmail features</li> <li>Troubleshooting -- Common issues and solutions</li> <li>FAQ -- Frequently asked questions</li> </ul>"},{"location":"user/faq/","title":"Frequently Asked Questions","text":""},{"location":"user/faq/#general","title":"General","text":""},{"location":"user/faq/#what-is-zetherion-ai","title":"What is Zetherion AI?","text":"<p>Zetherion AI is a secure, intelligent Discord bot that serves as a personal AI assistant. It features multi-provider LLM routing through its InferenceBroker, encrypted vector-based memory, and integrations with Gmail, GitHub, and calendar services. It runs entirely on your own infrastructure, giving you full control over your data.</p>"},{"location":"user/faq/#is-it-free","title":"Is it free?","text":"<p>The bot itself is open source and free to use. The Gemini API has a generous free tier that is sufficient for personal use. Claude and GPT are optional providers for complex tasks and require paid API keys. Discord bot hosting is free.</p>"},{"location":"user/faq/#does-it-store-my-data","title":"Does it store my data?","text":"<p>Yes, all data is stored locally on your machine. Qdrant is used for vector storage (conversation history, semantic memories), and PostgreSQL is used for structured data (user profiles, tasks, integrations). If encryption is enabled, all sensitive fields are encrypted with AES-256-GCM. Nothing is sent to third parties beyond the LLM API calls themselves.</p>"},{"location":"user/faq/#can-multiple-people-use-it","title":"Can multiple people use it?","text":"<p>Yes. Set <code>ALLOWED_USER_IDS</code> in your <code>.env</code> file with a comma-separated list of Discord user IDs. Leave it empty to allow all users. Each user gets their own memory space and profile.</p>"},{"location":"user/faq/#setup","title":"Setup","text":""},{"location":"user/faq/#what-hardware-do-i-need","title":"What hardware do I need?","text":"<p>Minimum requirements depend on your chosen backend:</p> <ul> <li>Gemini backend (cloud routing): 8GB RAM, 4GB free disk space</li> <li>Ollama backend (local inference): 12-16GB RAM, 10GB+ free disk space for model weights</li> </ul> <p>See the Getting Started guide for detailed hardware recommendations.</p>"},{"location":"user/faq/#can-i-run-it-on-windows","title":"Can I run it on Windows?","text":"<p>Yes. Use <code>start.ps1</code> in PowerShell. Docker Desktop for Windows is required. WSL2 is not needed since the PowerShell script handles everything natively.</p>"},{"location":"user/faq/#do-i-need-all-api-keys","title":"Do I need all API keys?","text":"<p>No. Only two keys are required:</p> <ul> <li>Discord Token (required)</li> <li>Gemini API Key (required)</li> </ul> <p>Claude (<code>ANTHROPIC_API_KEY</code>) and GPT (<code>OPENAI_API_KEY</code>) are optional. Without them, all queries are handled by Gemini, which is still very capable for most tasks.</p>"},{"location":"user/faq/#can-i-run-it-on-a-raspberry-pi","title":"Can I run it on a Raspberry Pi?","text":"<p>It is possible with the Gemini backend, since all heavy inference is done in the cloud. However, it is not recommended for the Ollama backend due to memory and CPU constraints. A Raspberry Pi 4 with 8GB RAM can work for Gemini-only mode.</p>"},{"location":"user/faq/#features","title":"Features","text":""},{"location":"user/faq/#what-llm-models-does-it-use","title":"What LLM models does it use?","text":"<p>Zetherion AI uses multiple models, each selected for its strengths:</p> Model Role Gemini 2.5 Flash Routing, simple queries, embeddings Claude Sonnet 4.5 Complex reasoning, code analysis, creative tasks GPT-5.2 Alternative for complex tasks Llama 3.2 1B Local router (Ollama backend) Llama 3.1 8B Local generation (Ollama backend) <p>Embeddings use Gemini text-embedding-004 (768 dimensions).</p>"},{"location":"user/faq/#how-does-routing-work","title":"How does routing work?","text":"<p>The InferenceBroker classifies each query by complexity and routes it to the optimal provider:</p> <ol> <li>User sends a message.</li> <li>The router (Gemini 2.5 Flash or Llama 3.2 1B) analyzes intent and complexity.</li> <li>Simple queries (greetings, factual questions) are handled by the router model directly.</li> <li>Complex queries (code generation, analysis, multi-step reasoning) are routed to Claude Sonnet 4.5 or GPT-5.2.</li> </ol> <p>This approach keeps costs low while ensuring quality for tasks that need it.</p>"},{"location":"user/faq/#can-it-read-my-email","title":"Can it read my email?","text":"<p>Yes, with Gmail integration via OAuth. The progressive trust system ensures the bot only accesses your email with explicit authorization. You can connect your account, search emails, and get summaries. See the Gmail integration documentation for setup details.</p>"},{"location":"user/faq/#can-it-manage-github","title":"Can it manage GitHub?","text":"<p>Yes. With a GitHub personal access token, Zetherion AI can manage issues, pull requests, workflows, and labels. Autonomy levels are configurable so you control how much the bot can do independently.</p>"},{"location":"user/faq/#does-it-learn-about-me","title":"Does it learn about me?","text":"<p>Yes. The profile system tracks information across 8 categories with confidence scoring. You have full privacy controls over what is stored, and you can review, edit, or delete profile information at any time.</p>"},{"location":"user/faq/#can-i-use-different-models","title":"Can I use different models?","text":"<p>Yes. Configure models in your <code>.env</code> file:</p> <pre><code>CLAUDE_MODEL=claude-sonnet-4-5-20250514\nOPENAI_MODEL=gpt-5.2\nROUTER_MODEL=gemini-2.5-flash\n</code></pre> <p>See <code>src/zetherion_ai/config.py</code> for all available model options.</p>"},{"location":"user/faq/#how-much-does-it-cost-to-run","title":"How much does it cost to run?","text":"Tier Monthly Cost Details Free (Gemini only) $0/month Handles most personal use comfortably With Claude ~$5-20/month For personal use with complex task routing With GPT ~$10-30/month Alternative to Claude for complex tasks <p>You can reduce costs by using Gemini-only mode, adjusting routing thresholds, or reducing context window sizes.</p>"},{"location":"user/faq/#privacy-and-security","title":"Privacy and Security","text":""},{"location":"user/faq/#is-my-data-encrypted","title":"Is my data encrypted?","text":"<p>Yes. Zetherion AI uses AES-256-GCM field-level encryption with PBKDF2 key derivation. Sensitive fields in both Qdrant and PostgreSQL are encrypted at rest. Enable encryption by setting the encryption key in your <code>.env</code> file.</p>"},{"location":"user/faq/#are-api-keys-safe-in-the-env-file","title":"Are API keys safe in the .env file?","text":"<p>Yes, provided you follow basic precautions:</p> <ul> <li><code>.env</code> is included in <code>.gitignore</code> by default and will not be committed to Git.</li> <li>Restrict file permissions: <code>chmod 600 .env</code></li> <li>Never share the <code>.env</code> file or post its contents anywhere.</li> </ul>"},{"location":"user/faq/#what-about-prompt-injection","title":"What about prompt injection?","text":"<p>Zetherion AI has built-in prompt injection detection that includes regex patterns for common injection techniques, Unicode obfuscation detection, and role-play marker detection. Suspicious messages are automatically rejected before reaching the LLM.</p>"},{"location":"user/faq/#can-i-delete-all-my-data","title":"Can I delete all my data?","text":"<p>Yes. Send <code>@Zetherion AI delete all my data</code> in Discord. The bot will ask for confirmation before permanently removing all your stored memories, profile data, and conversation history.</p>"},{"location":"user/faq/#can-i-export-my-data","title":"Can I export my data?","text":"<p>Yes. Send <code>@Zetherion AI export my data</code> in Discord. The bot will compile and send you a complete export of all your stored data, supporting GDPR compliance requirements.</p>"},{"location":"user/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user/faq/#the-bot-is-not-responding","title":"The bot is not responding","text":"<p>Common causes include:</p> <ul> <li>Message Content Intent not enabled in the Discord Developer Portal.</li> <li>User not on the allowlist (check <code>ALLOWED_USER_IDS</code>).</li> <li>Bot missing permissions (Send Messages, Read Messages, Embed Links).</li> <li>Rate limits exceeded (default is 10 messages per 60 seconds).</li> </ul> <p>See the Troubleshooting guide for step-by-step solutions.</p>"},{"location":"user/faq/#slash-commands-are-not-appearing","title":"Slash commands are not appearing","text":"<p>Slash commands can take up to 1 hour to sync globally. Try restarting Discord, or reinvite the bot with the <code>applications.commands</code> scope. See Troubleshooting - Slash Commands for details.</p>"},{"location":"user/faq/#api-costs-are-too-high","title":"API costs are too high","text":"<p>To reduce costs:</p> <ol> <li>Use Gemini-only mode (remove Claude/OpenAI API keys).</li> <li>Set budget limits in your API provider dashboards.</li> <li>Reduce the context window size (<code>CONTEXT_WINDOW_SIZE</code> in <code>.env</code>).</li> <li>Restrict usage with <code>ALLOWED_USER_IDS</code>.</li> </ol> <p>For detailed troubleshooting, see the Troubleshooting guide.</p>"},{"location":"user/faq/#still-have-questions","title":"Still Have Questions?","text":"<ol> <li>Check the Troubleshooting guide.</li> <li>Search GitHub Issues.</li> <li>Create a new issue with the <code>[Question]</code> tag.</li> </ol>"},{"location":"user/getting-started/","title":"Getting Started","text":"<p>This guide walks you through everything you need to install, configure, and run Zetherion AI as your personal AI assistant. Discord is the first supported input interface, but the system is designed to accept input from any source. Most users are up and running in under ten minutes.</p>"},{"location":"user/getting-started/#what-you-need","title":"What You Need","text":"Requirement Details Docker Desktop 4.0+ Required. Zetherion AI runs as 6 Docker services. Discord bot token Required. Free to create in the Discord Developer Portal. Gemini API key Optional. Free tier from Google AI Studio (1,500 requests/day). Enables cloud routing and simple queries. Anthropic API key Optional. Enables Claude Sonnet 4.5 (<code>claude-sonnet-4-5-20250929</code>). OpenAI API key Optional. Enables GPT-5.2. Python 3.12+ Required on the host for the setup script. Minimum hardware 8 GB RAM, 20 GB free disk space. Recommended hardware 16 GB RAM, 30 GB SSD."},{"location":"user/getting-started/#step-1-get-your-api-keys","title":"Step 1: Get Your API Keys","text":""},{"location":"user/getting-started/#discord-bot-token","title":"Discord Bot Token","text":"<ol> <li>Open the Discord Developer Portal.</li> <li>Click New Application and give it a name (e.g., \"Zetherion AI\").</li> <li>Navigate to the Bot tab in the left sidebar.</li> <li>Click Reset Token and copy the token. Store it somewhere safe -- you will    not be able to view it again.</li> <li>Scroll down to Privileged Gateway Intents and enable Message Content    Intent.</li> <li>Navigate to OAuth2 &gt; URL Generator.</li> <li>Under Scopes, select <code>bot</code> and <code>applications.commands</code>.</li> <li>Under Bot Permissions, select at minimum: Send Messages, Embed Links,    Read Message History, and Use Slash Commands.</li> <li>Copy the generated URL. You will use it in Step 3 to invite the bot to your    server.</li> </ol>"},{"location":"user/getting-started/#gemini-api-key","title":"Gemini API Key","text":"<ol> <li>Go to Google AI Studio.</li> <li>Click Create API key.</li> <li>Copy the key. The free tier provides 1,500 requests per day, which is more    than enough for personal use.</li> </ol>"},{"location":"user/getting-started/#optional-api-keys","title":"Optional API Keys","text":"<p>Anthropic (Claude Sonnet 4.5)</p> <ol> <li>Visit the Anthropic Console.</li> <li>Navigate to API Keys and create a new key.</li> <li>Add credit to your account. Claude Sonnet 4.5 is a paid model.</li> </ol> <p>OpenAI (GPT-5.2)</p> <ol> <li>Visit the OpenAI Platform.</li> <li>Create a new secret key.</li> <li>Ensure your account has billing enabled.</li> </ol>"},{"location":"user/getting-started/#step-2-install-and-run","title":"Step 2: Install and Run","text":""},{"location":"user/getting-started/#macos-linux","title":"macOS / Linux","text":"<pre><code>git clone https://github.com/jimtin/zetherion-ai.git\ncd zetherion-ai\nchmod +x start.sh\n./start.sh\n</code></pre>"},{"location":"user/getting-started/#windows","title":"Windows","text":"<pre><code>git clone https://github.com/jimtin/zetherion-ai.git\ncd zetherion-ai\n.\\start.ps1\n</code></pre>"},{"location":"user/getting-started/#what-the-script-does","title":"What the Script Does","text":"<p>The setup script handles the entire installation process:</p> <ol> <li>Checks prerequisites -- verifies that Python 3.12+ and Docker Desktop    are installed and running.</li> <li>Guides you through interactive configuration -- prompts for your Discord    bot token, Gemini API key, and optional keys for Anthropic and OpenAI.</li> <li>Asks you to choose a router backend:</li> <li>Gemini (cloud) -- fast setup, roughly 3 minutes. Uses <code>gemini-2.5-flash</code>      for intent routing. No extra hardware needed.</li> <li>Ollama (local) -- private, roughly 9 minutes. Downloads and runs      <code>llama3.2:3b</code> for routing and <code>llama3.1:8b</code> for local generation. All      inference stays on your machine.</li> <li>Builds and starts all 6 Docker services: <code>bot</code>, <code>skills</code>, <code>qdrant</code>,    <code>postgres</code>, <code>ollama</code>, and <code>ollama-router</code>.</li> <li>Downloads Ollama models if you selected the local backend.</li> </ol> <p>You do not need to edit any configuration files manually. The script generates everything for you.</p>"},{"location":"user/getting-started/#step-3-invite-your-bot","title":"Step 3: Invite Your Bot","text":"<ol> <li>Return to the Discord Developer Portal.</li> <li>Select your application and go to OAuth2 &gt; URL Generator.</li> <li>Under Scopes, check <code>bot</code> and <code>applications.commands</code>.</li> <li>Under Bot Permissions, select:</li> <li>Send Messages</li> <li>Embed Links</li> <li>Attach Files</li> <li>Read Message History</li> <li>Use Slash Commands</li> <li>Add Reactions</li> <li>Copy the generated invite URL and open it in your browser.</li> <li>Select the Discord server you want to add the bot to and click Authorize.</li> </ol>"},{"location":"user/getting-started/#step-4-verify-everything-works","title":"Step 4: Verify Everything Works","text":""},{"location":"user/getting-started/#check-service-health","title":"Check Service Health","text":"<p>Run the status script to confirm all services are up:</p> <pre><code># macOS / Linux\n./status.sh\n\n# Windows\n.\\status.ps1\n</code></pre> <p>You should see all 6 services reported as healthy:</p> <pre><code>bot            healthy\nskills         healthy\nqdrant         healthy\npostgres       healthy\nollama         healthy\nollama-router  healthy\n</code></pre>"},{"location":"user/getting-started/#test-in-discord","title":"Test in Discord","text":"<p>In any channel where the bot has access, send:</p> <pre><code>@Zetherion AI hello\n</code></pre> <p>The bot should respond within a few seconds.</p>"},{"location":"user/getting-started/#check-qdrant-dashboard","title":"Check Qdrant Dashboard","text":"<p>Open http://localhost:6333/dashboard in your browser to verify the vector database is running and accessible.</p>"},{"location":"user/getting-started/#hardware-recommendations","title":"Hardware Recommendations","text":"Backend RAM CPU GPU Setup Time Notes Gemini (cloud) 8 GB Any Not needed ~3 min Simplest option. Requires internet. Ollama (<code>llama3.1:8b</code>) 12-16 GB 4+ cores Not needed ~9 min Fully local. Private inference. Ollama with GPU 16 GB+ 4+ cores NVIDIA or Apple Silicon ~9 min Fastest local inference. <p>Notes on Ollama with GPU:</p> <ul> <li>On macOS with Apple Silicon (M1/M2/M3/M4), Ollama uses the unified memory   architecture automatically. No extra configuration is needed.</li> <li>On Linux with an NVIDIA GPU, ensure you have the   NVIDIA Container Toolkit   installed so Docker can access the GPU.</li> <li>On Windows with an NVIDIA GPU, use WSL2 with the NVIDIA Container Toolkit.</li> </ul>"},{"location":"user/getting-started/#managing-your-bot","title":"Managing Your Bot","text":"Action Command Start <code>./start.sh</code> (or <code>.\\start.ps1</code> on Windows) Stop <code>./stop.sh</code> (or <code>.\\stop.ps1</code> on Windows) Status <code>./status.sh</code> (or <code>.\\status.ps1</code> on Windows) View logs <code>docker-compose logs -f zetherion-ai-bot</code> View all logs <code>docker-compose logs -f</code> Update <code>git pull &amp;&amp; ./stop.sh &amp;&amp; ./start.sh --force-rebuild</code>"},{"location":"user/getting-started/#troubleshooting","title":"Troubleshooting","text":"<p>If a service fails to start:</p> <ol> <li>Run <code>./status.sh</code> to identify which service is unhealthy.</li> <li>Check the logs for that service: <code>docker-compose logs &lt;service-name&gt;</code>.</li> <li>Ensure Docker Desktop is running and has enough allocated memory.</li> <li>If you changed API keys, re-run <code>./start.sh</code> to regenerate the configuration.</li> </ol>"},{"location":"user/getting-started/#next-steps","title":"Next Steps","text":"<p>Now that Zetherion AI is running, explore what it can do:</p> <ul> <li>Commands -- full list of available commands and slash commands.</li> <li>Tasks and Calendar -- manage tasks and check your   schedule through natural language.</li> <li>Memory and Profiles -- how the bot learns your   preferences over time.</li> <li>Gmail Integration -- connect your Gmail account for   email summaries and drafting.</li> <li>GitHub Integration -- monitor repositories, review   PRs, and track issues.</li> <li>Configuration -- advanced configuration   options and environment variables.</li> </ul>"},{"location":"user/github-integration/","title":"GitHub Integration","text":"<p>Manage your GitHub repositories directly from Discord. Create issues, review pull requests, check workflow status, and manage labels -- all through natural language.</p>"},{"location":"user/github-integration/#setting-up","title":"Setting Up","text":""},{"location":"user/github-integration/#prerequisites","title":"Prerequisites","text":"<p>You need a GitHub personal access token (PAT) with access to the repositories you want to manage. Create one in your GitHub Developer Settings.</p> <p>Add the following to your <code>.env</code> file:</p> <pre><code>GITHUB_TOKEN=ghp_your_token_here\n</code></pre> <p>Optionally, set a default repository so you do not have to specify it in every command:</p> <pre><code>GITHUB_DEFAULT_REPO=owner/repo\n</code></pre>"},{"location":"user/github-integration/#required-token-scopes","title":"Required Token Scopes","text":"<p>Your PAT needs the following scopes depending on what you want to do:</p> Scope Required For <code>repo</code> Issues, PRs, repository info <code>workflow</code> Listing and re-running CI/CD workflows"},{"location":"user/github-integration/#verifying-connection","title":"Verifying Connection","text":"<p>The bot verifies your token on startup and logs your authenticated GitHub username. If the token is invalid or missing required scopes, the bot will report the error in the startup logs.</p>"},{"location":"user/github-integration/#managing-issues","title":"Managing Issues","text":""},{"location":"user/github-integration/#list-issues","title":"List Issues","text":"<p>Ask the bot to show issues from a repository. If you have set a default repository, you do not need to specify one.</p> <pre><code>@Zetherion AI list open issues\n@Zetherion AI show issues in owner/repo\n@Zetherion AI list issues with label \"bug\"\n</code></pre>"},{"location":"user/github-integration/#view-an-issue","title":"View an Issue","text":"<p>Reference an issue by number to see its details, including title, body, labels, assignees, and status.</p> <pre><code>@Zetherion AI show issue #42\n</code></pre>"},{"location":"user/github-integration/#create-an-issue","title":"Create an Issue","text":"<p>Describe the issue you want to create. The bot will parse a title from your message.</p> <pre><code>@Zetherion AI create issue: Fix login page redirect\n</code></pre> <p>By default, this requires confirmation before the bot executes the action. See the Autonomy Levels section for details on changing this behavior.</p>"},{"location":"user/github-integration/#close-and-reopen-issues","title":"Close and Reopen Issues","text":"<pre><code>@Zetherion AI close issue #42\n@Zetherion AI reopen issue #42\n</code></pre> <p>Both actions require confirmation by default.</p>"},{"location":"user/github-integration/#labels","title":"Labels","text":"<p>Add or remove labels from issues. Label operations run autonomously by default and do not require confirmation.</p> <pre><code>@Zetherion AI add label \"bug\" to issue #42\n@Zetherion AI remove label \"wontfix\" from issue #42\n</code></pre>"},{"location":"user/github-integration/#comments","title":"Comments","text":"<p>Add a comment to any issue by referencing its number.</p> <pre><code>@Zetherion AI add comment to #42: Looks good, merging soon\n</code></pre> <p>Comment operations run autonomously by default.</p>"},{"location":"user/github-integration/#pull-requests","title":"Pull Requests","text":""},{"location":"user/github-integration/#list-prs","title":"List PRs","text":"<p>View open pull requests in your repository.</p> <pre><code>@Zetherion AI list pull requests\n@Zetherion AI show open PRs\n</code></pre>"},{"location":"user/github-integration/#view-a-pr","title":"View a PR","text":"<p>See the details of a specific pull request, including its description, review status, and CI checks.</p> <pre><code>@Zetherion AI show PR #10\n</code></pre>"},{"location":"user/github-integration/#view-a-pr-diff","title":"View a PR Diff","text":"<p>Review the code changes in a pull request without leaving Discord.</p> <pre><code>@Zetherion AI show PR diff #10\n</code></pre>"},{"location":"user/github-integration/#merge-a-pr","title":"Merge a PR","text":"<p>Merge a pull request into its target branch.</p> <pre><code>@Zetherion AI merge PR #10\n</code></pre> <p>Merging always requires confirmation. This is a safety measure that cannot be overridden through autonomy settings.</p>"},{"location":"user/github-integration/#workflows-cicd","title":"Workflows (CI/CD)","text":""},{"location":"user/github-integration/#check-status","title":"Check Status","text":"<p>View the status of your repository's GitHub Actions workflows.</p> <pre><code>@Zetherion AI list workflows\n@Zetherion AI show CI status\n</code></pre>"},{"location":"user/github-integration/#re-run-a-workflow","title":"Re-run a Workflow","text":"<p>Trigger a re-run of a specific workflow by its run ID.</p> <pre><code>@Zetherion AI rerun workflow 12345\n</code></pre>"},{"location":"user/github-integration/#repository-info","title":"Repository Info","text":"<p>Get a summary of your repository's key details.</p> <pre><code>@Zetherion AI repo info\n</code></pre> <p>This returns the repository description, default branch, open issues count, star count, fork count, and whether the repository is private.</p>"},{"location":"user/github-integration/#autonomy-levels","title":"Autonomy Levels","text":"<p>The GitHub integration uses a tiered autonomy system to control which actions the bot can perform immediately and which require your explicit confirmation.</p> Level Behavior Default For Autonomous Executes immediately without asking. Labels, comments, listing, repo info Ask Asks for confirmation before executing. Create, close, and reopen issues Always Ask Requires confirmation. Cannot be overridden. Merge PRs"},{"location":"user/github-integration/#view-current-settings","title":"View Current Settings","text":"<p>Check which autonomy level is assigned to each action.</p> <pre><code>@Zetherion AI show autonomy settings\n@Zetherion AI get autonomy\n</code></pre>"},{"location":"user/github-integration/#change-settings","title":"Change Settings","text":"<p>Adjust the autonomy level for any action that is not locked to \"Always Ask\".</p> <pre><code>@Zetherion AI set autonomy for create_issue to autonomous\n</code></pre> <p>You can set an action to <code>autonomous</code>, <code>ask</code>, or <code>always_ask</code>. Actions locked to \"Always Ask\" (such as merging PRs) cannot be changed.</p>"},{"location":"user/github-integration/#confirming-actions","title":"Confirming Actions","text":"<p>When the bot asks for confirmation, it displays the details of what it is about to do along with an action ID. Follow the instructions in the confirmation message to approve or cancel the action.</p>"},{"location":"user/github-integration/#supported-intents","title":"Supported Intents","text":"<p>The GitHub skill recognizes the following intents:</p> Intent Description <code>list_issues</code> List issues, optionally filtered by state or label. <code>get_issue</code> View details of a specific issue. <code>create_issue</code> Create a new issue. <code>update_issue</code> Update an existing issue's title or body. <code>close_issue</code> Close an open issue. <code>reopen_issue</code> Reopen a closed issue. <code>add_label</code> Add a label to an issue. <code>remove_label</code> Remove a label from an issue. <code>add_comment</code> Add a comment to an issue. <code>list_prs</code> List pull requests. <code>get_pr</code> View details of a specific pull request. <code>get_pr_diff</code> View the diff of a pull request. <code>merge_pr</code> Merge a pull request. <code>list_workflows</code> List GitHub Actions workflows and their status. <code>rerun_workflow</code> Re-run a specific workflow. <code>get_repo_info</code> View repository metadata. <code>set_autonomy</code> Change the autonomy level for an action. <code>get_autonomy</code> View current autonomy settings."},{"location":"user/github-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user/github-integration/#github-client-not-initialized","title":"\"GitHub client not initialized\"","text":"<p>The bot could not create a GitHub client on startup. Check that <code>GITHUB_TOKEN</code> is set in your <code>.env</code> file and that the value is a valid personal access token.</p>"},{"location":"user/github-integration/#no-repository-specified","title":"\"No repository specified\"","text":"<p>You issued a command without specifying a repository, and no default is configured. Either set <code>GITHUB_DEFAULT_REPO</code> in your <code>.env</code> file or include the repository in your command (e.g., <code>list issues in owner/repo</code>).</p>"},{"location":"user/github-integration/#github-authentication-failed","title":"\"GitHub authentication failed\"","text":"<p>Your token may be expired, revoked, or missing the required scopes. Generate a new token with the <code>repo</code> and <code>workflow</code> scopes and update your <code>.env</code> file.</p>"},{"location":"user/github-integration/#actions-not-executing","title":"Actions not executing","text":"<p>If the bot responds with a confirmation prompt but you expected it to run immediately, check the autonomy settings. The action may be configured to require confirmation. Use <code>show autonomy settings</code> to review.</p>"},{"location":"user/github-integration/#related-guides","title":"Related Guides","text":"<ul> <li>Getting Started -- installation and initial setup.</li> <li>Commands -- full list of available commands.</li> <li>Configuration -- environment variables and   advanced settings.</li> <li>Security -- token storage and access control.</li> </ul>"},{"location":"user/gmail/","title":"Gmail Integration","text":""},{"location":"user/gmail/#overview","title":"Overview","text":"<p>Zetherion AI can connect to your Gmail account to check emails, generate digests, draft replies, and search your inbox -- all from Discord. The integration supports multiple Gmail accounts, progressive trust for automated actions, and privacy-first design that keeps you in control of your data.</p>"},{"location":"user/gmail/#setting-up-gmail","title":"Setting Up Gmail","text":""},{"location":"user/gmail/#prerequisites","title":"Prerequisites","text":"<p>Before connecting Gmail to Zetherion AI, you need:</p> <ul> <li>A Gmail account with API access enabled</li> <li>OAuth 2.0 credentials configured for the Zetherion AI application (see the deployment guide for setup instructions)</li> <li>The Zetherion AI bot running with all 6 Docker services operational</li> </ul>"},{"location":"user/gmail/#connecting-your-account","title":"Connecting Your Account","text":"<p>To start the OAuth flow, send the following command in Discord:</p> <pre><code>@Zetherion AI connect gmail\n</code></pre> <p>The bot will reply with a unique authorization link. Click the link to open Google's consent screen, where you will:</p> <ol> <li>Sign in to your Gmail account (if not already signed in).</li> <li>Review the permissions Zetherion AI is requesting.</li> <li>Click \"Allow\" to grant access.</li> </ol> <p>Once authorized, the bot confirms the connection and begins syncing your inbox metadata.</p> <p>You can connect multiple Gmail accounts by repeating this process with different Google accounts.</p>"},{"location":"user/gmail/#checking-connection-status","title":"Checking Connection Status","text":"<p>To verify your Gmail connection at any time:</p> <pre><code>@Zetherion AI gmail status\n</code></pre> <p>This triggers the <code>email_status</code> intent and displays:</p> <ul> <li>Connected Gmail accounts</li> <li>Last sync timestamp for each account</li> <li>Current trust level (see the Trust System section below)</li> <li>Any active errors or warnings</li> </ul>"},{"location":"user/gmail/#using-gmail","title":"Using Gmail","text":""},{"location":"user/gmail/#check-your-email","title":"Check Your Email","text":"<pre><code>@Zetherion AI check my email\n</code></pre> <p>This triggers the <code>email_check</code> intent and provides a summary across all connected accounts:</p> <ul> <li>Total email count</li> <li>Unread email count</li> <li>High-priority items (flagged or from known important senders)</li> <li>A brief overview of recent activity</li> </ul>"},{"location":"user/gmail/#view-unread-emails","title":"View Unread Emails","text":"<pre><code>@Zetherion AI show unread emails\n</code></pre> <p>This triggers the <code>email_unread</code> intent and lists up to 5 unread emails, showing:</p> <ul> <li>Sender name and address</li> <li>Subject line</li> <li>Received timestamp</li> </ul> <p>If you have more than 5 unread emails, the bot will indicate the total count and show the most recent ones.</p>"},{"location":"user/gmail/#email-digests","title":"Email Digests","text":"<pre><code>@Zetherion AI morning digest\n@Zetherion AI evening digest\n@Zetherion AI weekly digest\n</code></pre> <p>This triggers the <code>email_digest</code> intent and generates an AI-summarized digest of your email activity. Digests are organized by:</p> <ul> <li>Priority level (urgent, important, informational)</li> <li>Topic or sender grouping</li> <li>Action items extracted from email content</li> </ul> <p>The digest is generated using Gemini 2.5 Flash for speed, with Claude Sonnet 4.5 or GPT-5.2 used when deeper analysis is needed for complex email threads.</p>"},{"location":"user/gmail/#search-emails","title":"Search Emails","text":"<pre><code>@Zetherion AI search emails for invoice\n@Zetherion AI find emails about project update\n@Zetherion AI search my email for meeting notes\n</code></pre> <p>This triggers the <code>email_search</code> intent and searches across all connected accounts by:</p> <ul> <li>Subject line</li> <li>Sender name and address</li> <li>Email body content (where available)</li> </ul> <p>Results are returned with subject, sender, date, and a brief snippet of matching content.</p>"},{"location":"user/gmail/#view-drafts","title":"View Drafts","text":"<pre><code>@Zetherion AI show my drafts\n</code></pre> <p>This triggers the <code>email_drafts</code> intent and lists pending reply drafts that have been auto-generated by the trust system and are awaiting your review. Each draft shows:</p> <ul> <li>The original email subject and sender</li> <li>A preview of the drafted reply</li> <li>Options to approve, edit, or discard</li> </ul>"},{"location":"user/gmail/#calendar-events-from-email","title":"Calendar Events from Email","text":"<pre><code>@Zetherion AI check my email calendar\n@Zetherion AI any upcoming events in my email?\n</code></pre> <p>This triggers the <code>email_calendar</code> intent and extracts calendar-related information from your emails, such as meeting invitations, event confirmations, and scheduling requests.</p>"},{"location":"user/gmail/#trust-system","title":"Trust System","text":"<p>Zetherion AI uses a progressive trust system for Gmail actions. This means the bot starts with minimal permissions and earns greater autonomy as you build confidence in its behavior.</p>"},{"location":"user/gmail/#how-trust-works","title":"How Trust Works","text":"<p>Level 1 -- Read Only (default) When you first connect Gmail, the bot can only read and summarize emails. It cannot draft, send, or modify anything.</p> <p>Level 2 -- Draft with Approval After consistent use, the bot begins drafting replies for your review. Every draft must be explicitly approved by you before it is sent. You will see drafts listed when you run \"show my drafts.\"</p> <p>Level 3 -- Auto-Draft Once you have approved a sufficient number of drafts, the bot can automatically create drafts without prompting you. Drafts are still not sent automatically -- they remain in your drafts folder for review.</p> <p>Level 4 -- Auto-Send (configurable) At the highest trust level, the bot can send replies on your behalf for specific contacts and email types. This level is never enabled by default and must be explicitly configured by you.</p>"},{"location":"user/gmail/#trust-is-granular","title":"Trust is Granular","text":"<p>Trust is tracked at a granular level:</p> <ul> <li>Per contact: The bot may be trusted to auto-draft replies to a frequent collaborator but remain at read-only for unknown senders.</li> <li>Per email type: Routine acknowledgments may reach auto-send level while sensitive topics remain at draft-with-approval.</li> </ul>"},{"location":"user/gmail/#managing-trust","title":"Managing Trust","text":"<p>You always maintain full control over trust levels. You can:</p> <ul> <li>Review current trust levels via \"gmail status\"</li> <li>Revoke trust for specific contacts or globally at any time</li> <li>Reset trust to read-only if desired</li> </ul>"},{"location":"user/gmail/#privacy","title":"Privacy","text":"<p>Zetherion AI is designed with privacy as a core principle for the Gmail integration.</p> <ul> <li>OAuth tokens are stored securely using encryption at rest. They are never exposed in logs or error messages.</li> <li>Email content is encrypted at rest within the bot's storage. Content is only decrypted when actively processing a request.</li> <li>No email content is sent to cloud LLMs without your consent. By default, only metadata (sender, subject, timestamp) is sent for processing. Full email body content is only sent to cloud models (Claude Sonnet 4.5, GPT-5.2, Gemini 2.5 Flash) when the task requires it and you have authorized it.</li> <li>Trust can be revoked at any time. Revoking trust immediately stops all automated actions.</li> <li>Data export and deletion are available via profile commands. You can request a full export of all Gmail-related data or delete it entirely.</li> </ul>"},{"location":"user/gmail/#automatic-digests","title":"Automatic Digests","text":"<p>The heartbeat scheduler can send periodic email digests at configurable times without you needing to ask. This is useful for staying on top of your inbox with a daily morning summary or a weekly roundup.</p>"},{"location":"user/gmail/#configuration","title":"Configuration","text":"<p>Automatic digests are configured through the bot's scheduling system. Common configurations include:</p> <ul> <li>Morning digest -- Sent at a configured time each morning (e.g., 8:00 AM in your timezone) with overnight email activity.</li> <li>Evening digest -- Sent at end of day with a summary of the day's email activity.</li> <li>Weekly digest -- Sent once per week (e.g., Monday morning) with a high-level summary of the past week.</li> </ul> <p>Digest times and frequency are configurable in the bot's environment settings. The heartbeat scheduler runs as part of the 6 Docker services that make up the Zetherion AI deployment.</p>"},{"location":"user/gmail/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user/gmail/#oauth-errors","title":"OAuth Errors","text":"<p>Problem: \"OAuth authentication failed\" or \"Unable to connect Gmail\"</p> <p>Solutions: 1. Verify that OAuth 2.0 credentials are correctly configured in the bot's environment. 2. Check that the Gmail API is enabled in the Google Cloud Console. 3. Ensure the redirect URI matches what is configured in your OAuth client. 4. Try disconnecting and reconnecting your account:    <pre><code>@Zetherion AI disconnect gmail\n@Zetherion AI connect gmail\n</code></pre></p>"},{"location":"user/gmail/#gmail-is-not-configured","title":"\"Gmail is not configured\"","text":"<p>Problem: The bot responds that Gmail is not configured.</p> <p>Solutions: 1. Confirm that the Gmail service credentials are present in the bot's environment variables. 2. Verify that the Gmail-related Docker service is running (check with <code>docker ps</code> or the bot's status command). 3. Check the bot logs for configuration errors at startup.</p>"},{"location":"user/gmail/#no-accounts-connected","title":"No Accounts Connected","text":"<p>Problem: \"No Gmail accounts connected\" when running Gmail commands.</p> <p>Solutions: 1. Run <code>@Zetherion AI connect gmail</code> to start the OAuth flow. 2. Complete the full authorization process in your browser. 3. Check that the OAuth callback was received by verifying with <code>@Zetherion AI gmail status</code>.</p>"},{"location":"user/gmail/#sync-issues","title":"Sync Issues","text":"<p>Problem: Emails appear outdated or missing.</p> <p>Solutions: 1. Check the last sync time with <code>@Zetherion AI gmail status</code>. 2. Verify that the bot's heartbeat scheduler is running (responsible for periodic syncs). 3. Check network connectivity between the bot and Gmail API. 4. If the issue persists, disconnect and reconnect your Gmail account to reset the sync state.</p>"},{"location":"user/gmail/#rate-limiting-from-google","title":"Rate Limiting from Google","text":"<p>Problem: \"Rate limit exceeded\" errors from Gmail API.</p> <p>Solutions: 1. Wait a few minutes and try again. Google enforces per-user and per-application rate limits. 2. Reduce the frequency of automatic digest scheduling if configured for very frequent checks. 3. Check the Google Cloud Console for quota usage details.</p>"},{"location":"user/gmail/#related-guides","title":"Related Guides","text":"<ul> <li>Commands Reference -- Full list of all Zetherion AI commands</li> <li>Security -- Security architecture and privacy details</li> <li>Configuration -- Environment variables and deployment configuration</li> </ul>"},{"location":"user/memory-and-profiles/","title":"Memory and Profiles","text":"<p>Zetherion AI remembers your conversations and learns your preferences over time. The memory system stores past interactions for later retrieval, while the profile system builds an understanding of who you are and adapts its responses accordingly.</p>"},{"location":"user/memory-and-profiles/#how-memory-works","title":"How Memory Works","text":""},{"location":"user/memory-and-profiles/#conversation-memory","title":"Conversation Memory","text":"<p>The bot maintains context from recent messages within the current conversation window. Beyond that window, it automatically searches past conversations for semantically similar content to inform its responses.</p> <p>All memory content is stored in a Qdrant vector database. When encryption is enabled, memories are encrypted at rest using AES-256-GCM.</p>"},{"location":"user/memory-and-profiles/#storing-memories","title":"Storing Memories","text":"<p>You can explicitly ask the bot to remember something. The information is embedded as a vector and becomes searchable by semantic similarity.</p> <pre><code>@Zetherion AI remember I prefer Python for coding\n/remember My birthday is March 15th\n</code></pre> <p>You can also store notes without using a command keyword. Any message that contains factual information the bot recognizes as worth remembering may be stored automatically.</p> <pre><code>\"Note: Project uses PostgreSQL\"\n</code></pre>"},{"location":"user/memory-and-profiles/#searching-memories","title":"Searching Memories","text":"<p>Retrieve stored memories by describing what you are looking for. The bot returns the most relevant results ranked by similarity score.</p> <pre><code>/search preferences\n@Zetherion AI what do you remember about my projects?\n</code></pre>"},{"location":"user/memory-and-profiles/#memory-encryption","title":"Memory Encryption","text":"<p>When encryption is enabled, all memory content is encrypted at rest using AES-256-GCM. Even if the underlying database is compromised, your data remains unreadable without the encryption passphrase.</p> <pre><code>ENCRYPTION_ENABLED=true\nENCRYPTION_PASSPHRASE=your-secure-passphrase\n</code></pre>"},{"location":"user/memory-and-profiles/#profile-system","title":"Profile System","text":"<p>The profile system learns about you from your conversations and uses that information to personalize responses. Learning happens both passively (from things you say in conversation) and actively (from explicit statements).</p>"},{"location":"user/memory-and-profiles/#what-gets-learned","title":"What Gets Learned","text":"<p>The bot tracks information across eight categories:</p> Category Examples Identity Name, location, timezone, pronouns Preferences Coding style, verbosity, formality, response format Schedule Work hours, availability, meeting preferences Projects Current work, technologies in use, interests Relationships Team members, collaborators, manager Skills Programming languages, frameworks, expertise level Goals Short-term objectives, long-term career plans, learning goals Habits Communication patterns, shortcuts, review routines"},{"location":"user/memory-and-profiles/#how-learning-works","title":"How Learning Works","text":"<p>The bot assigns a confidence score to each piece of information it learns. The score depends on how the information was communicated:</p> Source Confidence Example Explicit statement 95% \"My name is James\" Direct preference 85% \"I prefer Python\" Contextual mention 70% \"Working on the API migration...\" Inferred from behavior 50% Detected from conversation patterns <p>The system uses two inference tiers. Tier 1 relies on fast regex-based pattern matching for high-confidence extractions like explicit statements. Tier 2 uses LLM-based analysis for deeper contextual understanding, producing lower confidence scores that are more likely to require confirmation.</p>"},{"location":"user/memory-and-profiles/#confidence-and-confirmation","title":"Confidence and Confirmation","text":"<p>What happens with learned information depends on its confidence score:</p> Confidence Behavior High (90% and above) Auto-applied to your profile. No confirmation needed. Medium (60% to 90%) Applied to your profile. The bot may ask you to confirm. Low (below 60%) Stored as pending. The bot asks you to confirm before applying. <p>Confidence decays over time if not reinforced. After 30 days without reinforcement, confidence drops by 10%. After 90 days, it drops by 20%. If confidence falls below 20%, the bot asks you to re-confirm the information.</p>"},{"location":"user/memory-and-profiles/#managing-your-profile","title":"Managing Your Profile","text":""},{"location":"user/memory-and-profiles/#viewing-your-profile","title":"Viewing Your Profile","text":"<p>See everything the bot has learned about you, with confidence percentages for each entry.</p> <pre><code>@Zetherion AI show my profile\n@Zetherion AI show my preferences\n@Zetherion AI what do you know about my schedule?\n@Zetherion AI show my projects\n</code></pre>"},{"location":"user/memory-and-profiles/#updating-your-profile","title":"Updating Your Profile","text":"<p>Make explicit updates to any profile information. Explicit updates are stored at high confidence.</p> <pre><code>@Zetherion AI update my name to James\n@Zetherion AI set my timezone to AEDT\n@Zetherion AI I prefer detailed explanations\n@Zetherion AI my coding language is Python\n</code></pre>"},{"location":"user/memory-and-profiles/#deleting-information","title":"Deleting Information","text":"<p>Remove specific entries, entire categories, or your full profile.</p> <p>Single field:</p> <pre><code>@Zetherion AI forget my location\n@Zetherion AI remove my manager from profile\n</code></pre> <p>Entire category:</p> <pre><code>@Zetherion AI clear my relationships\n</code></pre> <p>Full profile deletion (requires confirmation):</p> <pre><code>@Zetherion AI delete my entire profile\n</code></pre> <p>The bot will ask you to confirm before permanently deleting your entire profile.</p>"},{"location":"user/memory-and-profiles/#pending-confirmations","title":"Pending Confirmations","text":"<p>When the bot has learned something at low confidence, it stores the information as a pending confirmation. You can review and respond to these:</p> <pre><code>@Zetherion AI show pending confirmations\n</code></pre> <p>The bot will list each pending item with its detected value, confidence score, and the source message. You can confirm, reject, or correct each one.</p>"},{"location":"user/memory-and-profiles/#response-adaptation","title":"Response Adaptation","text":"<p>The bot adapts its responses based on what it has learned about you.</p>"},{"location":"user/memory-and-profiles/#formality","title":"Formality","text":"<p>Responses range from casual to formal based on your preference setting:</p> <ul> <li>Casual: conversational tone, contractions, relaxed phrasing.</li> <li>Balanced: clear and direct, neutral tone.</li> <li>Formal: professional language, complete sentences, no contractions.</li> </ul>"},{"location":"user/memory-and-profiles/#verbosity","title":"Verbosity","text":"<p>The level of detail in responses adapts to your preference:</p> <ul> <li>Brief: short, direct answers with minimal explanation.</li> <li>Balanced: answers with enough context to be useful.</li> <li>Detailed: thorough explanations with examples, edge cases, and caveats.</li> </ul>"},{"location":"user/memory-and-profiles/#technical-level","title":"Technical Level","text":"<p>Based on your skills profile, the bot adjusts how it explains concepts:</p> <ul> <li>Beginner-friendly: analogies and simplified explanations.</li> <li>Technical: assumes familiarity, uses precise terminology.</li> </ul>"},{"location":"user/memory-and-profiles/#coding-style","title":"Coding Style","text":"<p>When providing code examples, the bot uses your preferred programming language when possible. If you have indicated a preference for Python, for example, code samples will default to Python unless the context requires a different language.</p>"},{"location":"user/memory-and-profiles/#observation-pipeline","title":"Observation Pipeline","text":"<p>Beyond explicit profile management, the bot passively extracts facts from your conversations through an observation pipeline:</p> <ul> <li>Tiered extraction -- regex patterns handle high-confidence facts, while   LLM analysis captures deeper contextual information.</li> <li>Personal understanding model -- builds a comprehensive picture of your   preferences, work patterns, and interests over time.</li> <li>Contact graph -- tracks relationships and people you mention, connecting   them to the appropriate profile categories.</li> </ul> <p>This pipeline runs automatically. You do not need to take any action for the bot to learn from your conversations.</p>"},{"location":"user/memory-and-profiles/#privacy-controls","title":"Privacy Controls","text":""},{"location":"user/memory-and-profiles/#view-your-data","title":"View Your Data","text":"<p>Export all stored personal data, including your profile, memories, tasks, and calendar events.</p> <pre><code>@Zetherion AI export my data\n</code></pre> <p>The bot compiles your data and provides a summary with a downloadable export.</p>"},{"location":"user/memory-and-profiles/#delete-your-data","title":"Delete Your Data","text":"<p>Permanently remove all personal data associated with your account. This includes your profile, memories, tasks, and calendar events.</p> <pre><code>@Zetherion AI delete all my data\n</code></pre> <p>This action requires confirmation. The bot will ask you to verify before proceeding. Once deleted, the data cannot be recovered.</p>"},{"location":"user/memory-and-profiles/#disable-learning","title":"Disable Learning","text":"<p>Stop the bot from learning new information about you. Existing profile data is preserved but no new entries are added.</p> <pre><code>@Zetherion AI disable profile learning\n</code></pre> <p>You can also disable learning globally through your <code>.env</code> file:</p> <pre><code>PROFILE_INFERENCE_ENABLED=false\n</code></pre> <p>To re-enable learning:</p> <pre><code>@Zetherion AI enable profile learning\n</code></pre>"},{"location":"user/memory-and-profiles/#encryption","title":"Encryption","text":"<p>All profile data and memories can be encrypted at rest. When enabled, sensitive fields are encrypted using AES-256-GCM before being written to the database.</p> <pre><code>ENCRYPTION_ENABLED=true\nENCRYPTION_PASSPHRASE=your-secure-passphrase\n</code></pre> <p>Encrypted fields include names, locations, relationship data, project details, and goals content. Even with direct database access, encrypted data is unreadable without the passphrase.</p>"},{"location":"user/memory-and-profiles/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user/memory-and-profiles/#profile-not-learning","title":"Profile Not Learning","text":"<p>Verify that profile inference is enabled:</p> <pre><code>PROFILE_INFERENCE_ENABLED=true\n</code></pre> <p>Check the bot logs for profile-related errors:</p> <pre><code>docker-compose logs zetherion-ai-bot | grep -i profile\n</code></pre>"},{"location":"user/memory-and-profiles/#wrong-information-learned","title":"Wrong Information Learned","text":"<p>Correct it directly:</p> <pre><code>@Zetherion AI that's not right, my name is actually James\n@Zetherion AI update my location to Sydney\n</code></pre> <p>Or delete the incorrect entry and re-add it:</p> <pre><code>@Zetherion AI forget my name\n@Zetherion AI my name is James\n</code></pre>"},{"location":"user/memory-and-profiles/#too-many-confirmation-prompts","title":"Too Many Confirmation Prompts","text":"<p>Lower the auto-apply threshold so more information is accepted without confirmation:</p> <pre><code>PROFILE_CONFIDENCE_THRESHOLD=0.5\n</code></pre> <p>Or restrict inference to Tier 1 only, which produces fewer low-confidence results:</p> <pre><code>PROFILE_TIER1_ONLY=true\n</code></pre>"},{"location":"user/memory-and-profiles/#profile-not-affecting-responses","title":"Profile Not Affecting Responses","text":"<p>Verify your profile has been populated:</p> <pre><code>@Zetherion AI show my profile\n</code></pre> <p>If preferences are missing, set them explicitly:</p> <pre><code>@Zetherion AI set my preference for detailed explanations\n</code></pre>"},{"location":"user/memory-and-profiles/#related-guides","title":"Related Guides","text":"<ul> <li>Getting Started -- installation and initial setup.</li> <li>Commands -- full list of available commands.</li> <li>Configuration -- environment variables for   profiles, memory, and encryption.</li> <li>Security -- encryption details and data   protection.</li> <li>Gmail Integration -- connect your Gmail account for   email management.</li> </ul>"},{"location":"user/tasks-and-calendar/","title":"Tasks and Calendar","text":"<p>Zetherion AI includes a built-in task manager and calendar assistant. You interact with both through natural language in Discord -- no special syntax or slash commands required.</p>"},{"location":"user/tasks-and-calendar/#task-management","title":"Task Management","text":"<p>The task system lets you create, track, and complete tasks without leaving Discord. Tasks are stored per user in the Postgres database and persist across bot restarts.</p>"},{"location":"user/tasks-and-calendar/#creating-tasks","title":"Creating Tasks","text":"<p>Mention the bot and describe what you need to do. The bot parses deadlines, priorities, and descriptions from natural language.</p> <pre><code>@Zetherion AI add task: Review PR #123\n@Zetherion AI add task: Write unit tests by Friday\n@Zetherion AI create a task to update the deployment docs by end of week\n@Zetherion AI remind me to check CI results tomorrow morning\n</code></pre> <p>The bot will confirm the task was created and show you its assigned number.</p>"},{"location":"user/tasks-and-calendar/#listing-tasks","title":"Listing Tasks","text":"<p>Ask the bot to show your tasks. It will return them grouped by status.</p> <pre><code>@Zetherion AI list my tasks\n@Zetherion AI show task summary\n@Zetherion AI what are my open tasks?\n@Zetherion AI do I have any overdue tasks?\n</code></pre> <p>The response includes each task's number, title, priority, deadline (if set), and current status.</p>"},{"location":"user/tasks-and-calendar/#completing-tasks","title":"Completing Tasks","text":"<p>Reference a task by its number to mark it as done.</p> <pre><code>@Zetherion AI complete task 1\n@Zetherion AI mark task 3 as done\n@Zetherion AI I finished task 7\n</code></pre> <p>Completed tasks are kept in your history so you can review what you have accomplished.</p>"},{"location":"user/tasks-and-calendar/#deleting-tasks","title":"Deleting Tasks","text":"<p>Remove tasks you no longer need.</p> <pre><code>@Zetherion AI delete task 2\n@Zetherion AI remove task 5\n@Zetherion AI cancel task 4\n</code></pre> <p>Deleted tasks are permanently removed and cannot be recovered.</p>"},{"location":"user/tasks-and-calendar/#task-properties","title":"Task Properties","text":"<p>Each task can have the following properties:</p> Property Description Example Title Short description of the task. \"Review PR #123\" Description Optional longer details. \"Focus on the auth module changes.\" Priority Urgency level: low, medium, or high. \"high priority\" Deadline Due date, parsed from natural language. \"by Friday\", \"tomorrow at 3pm\" Status Current state of the task. open, in progress, completed <p>You can set properties when creating a task:</p> <pre><code>@Zetherion AI add high priority task: Fix login bug by tomorrow\n@Zetherion AI create task: Update API docs, low priority, due next Monday\n</code></pre> <p>Or update them later:</p> <pre><code>@Zetherion AI set task 2 to high priority\n@Zetherion AI change deadline for task 1 to next Wednesday\n@Zetherion AI mark task 4 as in progress\n</code></pre>"},{"location":"user/tasks-and-calendar/#calendar","title":"Calendar","text":"<p>The calendar feature lets you check your schedule and availability through conversational queries.</p>"},{"location":"user/tasks-and-calendar/#checking-your-schedule","title":"Checking Your Schedule","text":"<pre><code>@Zetherion AI what's my schedule today?\n@Zetherion AI what do I have this week?\n@Zetherion AI am I free at 3pm?\n@Zetherion AI do I have any meetings tomorrow?\n</code></pre> <p>The bot aggregates your tasks with deadlines and any connected calendar sources to give you a unified view of your day or week.</p>"},{"location":"user/tasks-and-calendar/#availability-checks","title":"Availability Checks","text":"<p>When you ask if you are free at a specific time, the bot checks:</p> <ul> <li>Tasks with deadlines near that time.</li> <li>Any calendar events from connected integrations.</li> <li>Your configured work hours.</li> </ul> <p>It responds with a clear yes or no and shows any conflicts.</p>"},{"location":"user/tasks-and-calendar/#work-hours","title":"Work Hours","text":"<p>The bot can learn your typical work hours from your profile. This is used to:</p> <ul> <li>Schedule reminders during appropriate times.</li> <li>Provide context-aware responses (e.g., \"You have a task due before end of   business today\").</li> <li>Avoid sending notifications outside your working hours.</li> </ul> <p>To set your work hours:</p> <pre><code>@Zetherion AI my work hours are 9am to 5pm Monday through Friday\n@Zetherion AI I usually work 8am to 6pm\n</code></pre> <p>The bot stores this in your user profile and references it going forward.</p>"},{"location":"user/tasks-and-calendar/#proactive-reminders","title":"Proactive Reminders","text":"<p>The heartbeat scheduler runs in the background and can send you reminders without being asked. This keeps important deadlines visible without requiring you to manually check your task list.</p>"},{"location":"user/tasks-and-calendar/#what-gets-reminded","title":"What Gets Reminded","text":"<ul> <li>Upcoming deadlines -- the bot notifies you when a task deadline is   approaching, typically a few hours before it is due.</li> <li>Overdue tasks -- if a deadline passes without the task being completed,   the bot sends a follow-up reminder.</li> <li>Morning briefings -- a summary of your tasks and schedule for the day,   sent at the start of your configured work hours.</li> </ul>"},{"location":"user/tasks-and-calendar/#quiet-hours","title":"Quiet Hours","text":"<p>To prevent notifications during off-hours, configure quiet hours:</p> <pre><code>@Zetherion AI set quiet hours from 10pm to 8am\n@Zetherion AI don't send reminders on weekends\n</code></pre> <p>During quiet hours, the bot queues reminders and delivers them when quiet hours end. No notifications will be sent during this window.</p>"},{"location":"user/tasks-and-calendar/#disabling-reminders","title":"Disabling Reminders","text":"<p>If you prefer to check tasks manually:</p> <pre><code>@Zetherion AI turn off reminders\n@Zetherion AI disable proactive notifications\n</code></pre> <p>You can re-enable them at any time:</p> <pre><code>@Zetherion AI turn on reminders\n</code></pre>"},{"location":"user/tasks-and-calendar/#tips","title":"Tips","text":"<ul> <li>Natural language works best. You do not need to memorize exact commands.   The bot understands variations like \"add a task\", \"create a todo\", \"I need to   remember to\", and similar phrasings.</li> <li>Task numbers are stable. A task keeps its number until it is deleted, so   you can reference it reliably across conversations.</li> <li>Deadlines are timezone-aware. The bot uses the timezone from your user   profile. Set it with: <code>@Zetherion AI my timezone is America/New_York</code>.</li> <li>Combine with other features. Tasks integrate with the memory system. The   bot may reference your open tasks when answering questions about your workload   or priorities.</li> </ul>"},{"location":"user/tasks-and-calendar/#related-guides","title":"Related Guides","text":"<ul> <li>Getting Started -- installation and initial setup.</li> <li>Commands -- full list of available commands.</li> <li>Memory and Profiles -- how the bot stores your   preferences, work hours, and timezone.</li> <li>Configuration -- environment variables for   tuning reminder frequency and quiet hours.</li> </ul>"},{"location":"user/troubleshooting/","title":"Troubleshooting","text":"<p>This guide covers common issues and their solutions when running Zetherion AI. If your issue is not listed here, see the Getting Help section at the bottom.</p>"},{"location":"user/troubleshooting/#discord-issues","title":"Discord Issues","text":""},{"location":"user/troubleshooting/#bot-not-responding","title":"Bot Not Responding","text":"<p>Symptoms: The bot is online but does not respond to mentions or DMs.</p> <p>Check the following in order:</p> <ol> <li> <p>Message Content Intent: Ensure the Message Content Intent is enabled in the Discord Developer Portal under Bot &gt; Privileged Gateway Intents.</p> </li> <li> <p>Bot Permissions: The bot requires these channel permissions:</p> </li> <li>Send Messages</li> <li>Read Messages / View Channels</li> <li> <p>Embed Links</p> </li> <li> <p>User Allowlist: If <code>ALLOWED_USER_IDS</code> is set in <code>.env</code>, the user must be included. Leave it empty to allow all users.</p> </li> <li> <p>Rate Limits: The default rate limit is 10 messages per 60 seconds per user. If you are hitting this limit, wait before sending more messages.</p> </li> </ol>"},{"location":"user/troubleshooting/#slash-commands-not-appearing","title":"Slash Commands Not Appearing","text":"<p>Symptoms: Cannot see <code>/ask</code>, <code>/remember</code>, <code>/search</code>, or other commands.</p> <ol> <li> <p>Wait for sync: Global command sync can take up to 1 hour. Be patient after first startup.</p> </li> <li> <p>Reinvite with correct scope: The bot must be invited with the <code>applications.commands</code> scope. Go to OAuth2 &gt; URL Generator in the Discord Developer Portal, select both <code>bot</code> and <code>applications.commands</code>, and use the new invite URL.</p> </li> <li> <p>Restart Discord: Close and reopen the Discord application to force a command cache refresh.</p> </li> </ol>"},{"location":"user/troubleshooting/#privilegedintentsrequired-error","title":"PrivilegedIntentsRequired Error","text":"<p>Full error: <pre><code>discord.errors.PrivilegedIntentsRequired: Shard ID None is requesting privileged intents\nthat have not been explicitly enabled in the developer portal.\n</code></pre></p> <p>Solution: 1. Go to https://discord.com/developers/applications 2. Select your bot application. 3. Go to the Bot tab. 4. Scroll to Privileged Gateway Intents. 5. Enable MESSAGE CONTENT INTENT (toggle it ON). 6. Click Save Changes. 7. Restart the bot: <code>./stop.sh &amp;&amp; ./start.sh</code></p>"},{"location":"user/troubleshooting/#configuration-issues","title":"Configuration Issues","text":""},{"location":"user/troubleshooting/#invalid-allowed_user_ids","title":"Invalid ALLOWED_USER_IDS","text":"<p>Error: <pre><code>pydantic_settings.sources.SettingsError: error parsing value for field \"allowed_user_ids\"\n</code></pre></p> <p>The correct format is comma-separated IDs with no spaces and no brackets:</p> <pre><code>ALLOWED_USER_IDS=123456789,987654321\n</code></pre> <p>Common mistakes: <pre><code># WRONG - spaces after comma:\nALLOWED_USER_IDS=123456789, 987654321\n\n# WRONG - JSON format:\nALLOWED_USER_IDS=[123456789]\n\n# CORRECT - no spaces, no brackets:\nALLOWED_USER_IDS=123456789,987654321\n</code></pre></p> <p>To get your Discord user ID, enable Developer Mode in Discord (Settings &gt; Advanced &gt; Developer Mode), then right-click your username and select \"Copy User ID\".</p>"},{"location":"user/troubleshooting/#missing-environment-variables","title":"Missing Environment Variables","text":"<p>Required variables: - <code>DISCORD_TOKEN</code> -- your Discord bot token - <code>GEMINI_API_KEY</code> -- your Google Gemini API key</p> <p>Optional variables: - <code>ANTHROPIC_API_KEY</code> -- for Claude Sonnet 4.5 (complex tasks) - <code>OPENAI_API_KEY</code> -- for GPT-5.2 (alternative complex tasks) - <code>GITHUB_TOKEN</code> -- for GitHub integration - <code>ALLOWED_USER_IDS</code> -- defaults to allow all users - <code>QDRANT_HOST</code> -- defaults to \"qdrant\" in Docker Compose - <code>QDRANT_PORT</code> -- defaults to 6333</p> <p>If your <code>.env</code> file is missing, create one from the template: <pre><code>cp .env.example .env\n</code></pre></p>"},{"location":"user/troubleshooting/#docker-issues","title":"Docker Issues","text":""},{"location":"user/troubleshooting/#docker-not-running","title":"Docker Not Running","text":"<p>Error: <pre><code>Cannot connect to the Docker daemon\n</code></pre></p> <p>The <code>./start.sh</code> script auto-detects whether Docker is running and will attempt to launch Docker Desktop automatically. If automatic launch fails:</p> <ol> <li>Open Docker Desktop manually.</li> <li>Wait for the green icon in the menu bar (indicating the daemon is ready).</li> <li>Verify with <code>docker ps</code>.</li> <li>Retry: <code>./start.sh</code></li> </ol>"},{"location":"user/troubleshooting/#port-already-in-use","title":"Port Already in Use","text":"<p>Error: <pre><code>Error starting userland proxy: listen tcp 0.0.0.0:6333: bind: address already in use\n</code></pre></p> <p>Identify what is using the port: <pre><code>lsof -i :6333   # Qdrant default port\nlsof -i :11434  # Ollama default port\nlsof -i :5432   # PostgreSQL default port\n</code></pre></p> <p>Kill the conflicting process or change the port in your <code>.env</code> file.</p>"},{"location":"user/troubleshooting/#out-of-memory","title":"Out of Memory","text":"<p>Docker Desktop may not have enough memory allocated for all 6 services (bot, skills, qdrant, postgres, ollama, ollama-router). Increase the allocation in Docker Desktop under Settings &gt; Resources &gt; Advanced.</p> <p>Recommended memory allocation: - Gemini backend: 4GB minimum (no local inference) - Ollama with Llama 3.1 8B: 8GB minimum - Ollama with larger models: 12-24GB</p> <p>The <code>./start.sh</code> script handles memory detection and will prompt you to increase allocation if needed.</p>"},{"location":"user/troubleshooting/#qdrant-issues","title":"Qdrant Issues","text":""},{"location":"user/troubleshooting/#connection-refused","title":"Connection Refused","text":"<p>Error: <pre><code>ConnectionRefusedError: [Errno 61] Connection refused\n</code></pre></p> <ol> <li> <p>Check the container is running: <pre><code>docker ps | grep qdrant\n</code></pre></p> </li> <li> <p>Verify host setting: Use <code>QDRANT_HOST=localhost</code> for local development or <code>QDRANT_HOST=qdrant</code> when running inside Docker Compose.</p> </li> <li> <p>Health check: <pre><code>curl http://localhost:6333/healthz\n</code></pre>    Should return: <code>healthy</code></p> </li> <li> <p>Restart the container: <pre><code>docker restart zetherion-ai-qdrant\n</code></pre></p> </li> </ol>"},{"location":"user/troubleshooting/#data-persistence","title":"Data Persistence","text":"<p>If memories disappear after restart, check that volume mounts are configured correctly. Data is stored in the <code>qdrant_storage/</code> directory. Verify the mount: <pre><code>docker inspect zetherion-ai-qdrant | grep -A 5 Mounts\n</code></pre></p>"},{"location":"user/troubleshooting/#postgresql-issues","title":"PostgreSQL Issues","text":""},{"location":"user/troubleshooting/#connection-refused_1","title":"Connection Refused","text":"<p>Error: <pre><code>psycopg2.OperationalError: could not connect to server: Connection refused\n</code></pre></p> <ol> <li> <p>Check the container is running: <pre><code>docker ps | grep postgres\n</code></pre></p> </li> <li> <p>Verify settings in <code>.env</code>:</p> </li> <li><code>POSTGRES_HOST</code> -- use <code>localhost</code> for local development, <code>postgres</code> for Docker Compose</li> <li><code>POSTGRES_PORT</code> -- default is 5432</li> <li> <p><code>POSTGRES_DB</code> -- the database name</p> </li> <li> <p>Check container logs: <pre><code>docker-compose logs postgres\n</code></pre></p> </li> <li> <p>Test the connection: <pre><code>docker exec zetherion-ai-postgres pg_isready\n</code></pre></p> </li> </ol>"},{"location":"user/troubleshooting/#migration-issues","title":"Migration Issues","text":"<p>After updates, the database schema may need to be migrated. Check the logs for migration errors: <pre><code>docker-compose logs zetherion-ai-bot | grep -i migration\n</code></pre></p> <p>If migrations fail, check that the PostgreSQL container is fully initialized before the bot starts. The health check in Docker Compose should handle this, but on slow systems you may need to restart the bot after PostgreSQL is ready.</p>"},{"location":"user/troubleshooting/#ollama-issues","title":"Ollama Issues","text":""},{"location":"user/troubleshooting/#model-download-fails","title":"Model Download Fails","text":"<p>Symptoms: Ollama cannot pull the required model during startup.</p> <ol> <li> <p>Check internet connectivity and disk space. Models require 5-10GB of free disk space.</p> </li> <li> <p>Manually pull the model: <pre><code>docker exec zetherion-ai-ollama ollama pull llama3.1:8b\n</code></pre></p> </li> <li> <p>Fallback to Gemini: If local models are not working, switch to the cloud backend:    <pre><code>ROUTER_BACKEND=gemini\n</code></pre></p> </li> </ol>"},{"location":"user/troubleshooting/#slow-responses","title":"Slow Responses","text":"<p>If Ollama is taking 30+ seconds to respond:</p> <ol> <li> <p>Check Docker memory. If the model exceeds available memory, it will swap to disk and become extremely slow.    <pre><code>docker stats zetherion-ai-ollama\n</code></pre></p> </li> <li> <p>Try a smaller model. Llama 3.2 1B is used for routing and should be fast. If generation with Llama 3.1 8B is too slow, consider switching to Gemini for generation.</p> </li> <li> <p>GPU acceleration is automatic on NVIDIA GPUs (with Docker GPU support) and Apple Silicon Macs (via Metal).</p> </li> </ol>"},{"location":"user/troubleshooting/#out-of-memory_1","title":"Out of Memory","text":"<p>Error: <pre><code>Error: llama runner process has terminated: signal: killed\n</code></pre></p> <p>The model requires more memory than Docker has allocated. The <code>./start.sh</code> script detects this and offers to increase allocation automatically. To fix manually, increase Docker Desktop memory under Settings &gt; Resources &gt; Advanced.</p>"},{"location":"user/troubleshooting/#gmail-issues","title":"Gmail Issues","text":""},{"location":"user/troubleshooting/#gmail-is-not-configured","title":"\"Gmail is not configured\"","text":"<p>Gmail integration requires OAuth credentials to be set up. This is a separate configuration step beyond the basic bot setup. Refer to the Gmail integration documentation for instructions on obtaining and configuring OAuth credentials.</p>"},{"location":"user/troubleshooting/#oauth-authorization-fails","title":"OAuth Authorization Fails","text":"<ul> <li>Verify that your OAuth client credentials are valid and not expired.</li> <li>Ensure the redirect URI in your Google Cloud Console matches the URI configured in Zetherion AI.</li> <li>Try revoking access in your Google Account security settings and re-authorizing.</li> </ul>"},{"location":"user/troubleshooting/#no-accounts-connected","title":"No Accounts Connected","text":"<p>Connect a Gmail account by sending: <pre><code>@Zetherion AI connect gmail\n</code></pre> The bot will provide an authorization link. Follow the link to grant access.</p>"},{"location":"user/troubleshooting/#sync-issues","title":"Sync Issues","text":"<p>Check the status of your connected account: <pre><code>@Zetherion AI gmail status\n</code></pre></p> <p>If the OAuth token has expired, you may need to reconnect. The bot will prompt you if re-authorization is needed.</p>"},{"location":"user/troubleshooting/#github-issues","title":"GitHub Issues","text":""},{"location":"user/troubleshooting/#github-client-not-initialized","title":"\"GitHub client not initialized\"","text":"<p>The GitHub integration requires a personal access token. Set it in your <code>.env</code> file: <pre><code>GITHUB_TOKEN=ghp_your_token_here\n</code></pre></p>"},{"location":"user/troubleshooting/#authentication-failed","title":"Authentication Failed","text":"<p>Your token may be expired or missing required scopes. Generate a new token at GitHub &gt; Settings &gt; Developer settings &gt; Personal access tokens. Ensure it has the <code>repo</code> scope at minimum.</p>"},{"location":"user/troubleshooting/#no-repository-specified","title":"\"No repository specified\"","text":"<p>Set a default repository in your <code>.env</code> file: <pre><code>GITHUB_DEFAULT_REPO=owner/repo\n</code></pre></p> <p>Alternatively, specify the repository directly in your command: <pre><code>@Zetherion AI list issues in owner/repo\n</code></pre></p>"},{"location":"user/troubleshooting/#api-key-issues","title":"API Key Issues","text":""},{"location":"user/troubleshooting/#invalid-discord-token","title":"Invalid Discord Token","text":"<p>Error: <pre><code>discord.errors.LoginFailure: Improper token has been passed\n</code></pre></p> <p>Regenerate your token at the Discord Developer Portal &gt; Bot &gt; Reset Token. Copy the new token immediately and update your <code>.env</code> file.</p>"},{"location":"user/troubleshooting/#invalid-gemini-key","title":"Invalid Gemini Key","text":"<p>Error: <pre><code>google.api_core.exceptions.PermissionDenied: 403 API key not valid\n</code></pre></p> <p>Verify your key at Google AI Studio. Ensure the Gemini API is enabled for your project.</p>"},{"location":"user/troubleshooting/#rate-limiting-429-errors","title":"Rate Limiting (429 Errors)","text":"<p>Error: <pre><code>429 Too Many Requests\n</code></pre></p> <p>The bot has automatic retry with exponential backoff. Wait 1-2 minutes before trying again. Check your API dashboards for quota limits:</p> <ul> <li>Anthropic: https://console.anthropic.com/</li> <li>OpenAI: https://platform.openai.com/usage</li> <li>Google: https://aistudio.google.com/app/apikey</li> </ul>"},{"location":"user/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"user/troubleshooting/#slow-responses_1","title":"Slow Responses","text":"<p>Response times vary by provider:</p> <ul> <li>Simple queries route to Gemini 2.5 Flash (typically 1-3 seconds).</li> <li>Complex queries route to Claude Sonnet 4.5 or GPT-5.2 (typically 3-10 seconds).</li> </ul> <p>To improve response times: - Reduce the context window: set <code>CONTEXT_WINDOW_SIZE=5</code> in <code>.env</code>. - Reduce memory search results: set <code>MEMORY_SEARCH_LIMIT=3</code> in <code>.env</code>. - Ensure Qdrant is running on an SSD for fast vector lookups.</p>"},{"location":"user/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Check container resource consumption: <pre><code>docker stats\n</code></pre></p> <p>If Qdrant is using excessive memory, you can limit it with the <code>--memory</code> flag when running the container manually. For Docker Compose deployments, set memory limits in the <code>docker-compose.yml</code> file.</p>"},{"location":"user/troubleshooting/#observation-pipeline-issues","title":"Observation Pipeline Issues","text":""},{"location":"user/troubleshooting/#observations-not-being-stored","title":"Observations Not Being Stored","text":"<p>If the bot is not learning from conversations or updating user profiles:</p> <ol> <li> <p>Check that PostgreSQL is running -- the observation pipeline stores data in PostgreSQL.    <pre><code>docker ps | grep postgres\n</code></pre></p> </li> <li> <p>Check bot logs for errors: <pre><code>docker-compose logs -f zetherion-ai-bot | grep -i observation\n</code></pre></p> </li> <li> <p>Verify the pipeline is enabled in your configuration. The observation pipeline runs asynchronously after each conversation turn.</p> </li> </ol>"},{"location":"user/troubleshooting/#profile-not-updating","title":"Profile Not Updating","text":"<p>The profile system uses confidence scoring and requires multiple observations before updating a category. A single mention may not be enough to create a profile entry. Continue interacting naturally and the profile will populate over time.</p>"},{"location":"user/troubleshooting/#debug-information","title":"Debug Information","text":"<p>Use these commands to gather diagnostic information:</p> <pre><code>./status.sh                              # Overall system status\ndocker-compose logs -f zetherion-ai-bot  # Bot logs (live follow)\ndocker stats                             # Container resource usage\ncurl http://localhost:6333/healthz       # Qdrant health check\ndocker exec zetherion-ai-postgres pg_isready  # PostgreSQL health check\n</code></pre> <p>To enable verbose logging, set the log level in your <code>.env</code> file: <pre><code>LOG_LEVEL=DEBUG\n</code></pre></p> <p>Then restart the bot: <code>./stop.sh &amp;&amp; ./start.sh</code></p>"},{"location":"user/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If your issue is not covered in this guide:</p> <ol> <li>Review the FAQ for common questions.</li> <li>Search GitHub Issues for existing reports.</li> <li>Create a new issue and include:</li> <li>Your OS version and Docker version</li> <li>Output of <code>./status.sh</code></li> <li>Relevant log output (<code>docker-compose logs zetherion-ai-bot --tail 50</code>)</li> <li>Steps to reproduce the issue</li> <li>What you have already tried</li> </ol>"}]}