{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SecureClaw","text":"<p>Secure personal AI assistant with encrypted memory, multi-provider LLM routing, and privacy-first design.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Encrypted Memory - AES-256-GCM encryption for all stored data with PBKDF2 key derivation</li> <li>Multi-Provider Routing - Intelligent routing across Claude, OpenAI, Gemini, and Ollama</li> <li>Vector Memory - Long-term context using Qdrant with semantic search</li> <li>Security-First - Rate limiting, prompt injection detection, secrets management</li> <li>Self-Hosted - Run entirely on your own infrastructure with Ollama</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Clone the repository\ngit clone https://github.com/jimtin/sercureclaw.git\ncd sercureclaw\n\n# Configure environment\ncp .env.example .env\n# Edit .env with your API keys\n\n# Start with Docker\n./start.sh\n</code></pre> <p>See the Startup Walkthrough for detailed setup instructions.</p>"},{"location":"#documentation","title":"Documentation","text":"Section Description Commands Discord slash commands reference Architecture System design and components Security Security controls and best practices Testing Test suite and coverage Docker Container setup and networking CI/CD Continuous integration pipeline Troubleshooting Common issues and solutions FAQ Frequently asked questions"},{"location":"#project-status","title":"Project Status","text":"<ul> <li>Test Coverage: 87.58% (255 unit + 14 integration + 4 E2E tests)</li> <li>Current Phase: 5 (Encrypted memory, InferenceBroker complete)</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>Report Issues</li> <li>Wiki</li> </ul>"},{"location":"ARCHITECTURE/","title":"SecureClaw Architecture","text":"<p>This document provides a comprehensive overview of SecureClaw's system architecture, design decisions, and key components.</p>"},{"location":"ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>High-Level Architecture</li> <li>Core Components</li> <li>Data Flow</li> <li>Design Patterns</li> <li>Technology Stack</li> <li>Scalability &amp; Performance</li> <li>Security Architecture</li> <li>Future Roadmap</li> </ul>"},{"location":"ARCHITECTURE/#overview","title":"Overview","text":"<p>SecureClaw is a Discord bot with advanced AI capabilities, featuring: - Dual LLM backends for intelligent routing (Gemini + Ollama for routing, Claude/OpenAI for complex tasks) - Vector memory for long-term context using Qdrant - Comprehensive security with rate limiting, allowlists, and prompt injection detection - Full Docker containerization for reproducible deployment</p>"},{"location":"ARCHITECTURE/#key-design-principles","title":"Key Design Principles","text":"<ol> <li>Modularity - Clean separation of concerns (Discord, Agent, Memory, Security)</li> <li>Extensibility - Pluggable backends via factory pattern</li> <li>Resilience - Retry logic, fallbacks, graceful degradation</li> <li>Security-First - Defense in depth, least privilege, secrets management</li> <li>Performance - Async-first, parallel operations, efficient caching</li> <li>Maintainability - 87.58% test coverage, type hints, comprehensive logging</li> </ol>"},{"location":"ARCHITECTURE/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         User Interface                          \u2502\n\u2502                      Discord (discord.py)                       \u2502\n\u2502  Commands: /channels, /remember, /summarize                    \u2502\n\u2502  Interactions: DMs, @mentions, slash commands                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Security Layer                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502  Allowlist   \u2502  \u2502 Rate Limiter \u2502  \u2502 Injection Detect  \u2502    \u2502\n\u2502  \u2502  User IDs    \u2502  \u2502 10 msg/60s   \u2502  \u2502 17 Regex Patterns \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Agent Core                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Message Router (Factory Pattern)                       \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502   \u2502\n\u2502  \u2502  \u2502 Gemini Backend   \u2502  \u2502 Ollama Backend       \u2502        \u2502   \u2502\n\u2502  \u2502  \u2502 - Cloud API      \u2502  \u2502 - Local Container    \u2502        \u2502   \u2502\n\u2502  \u2502  \u2502 - Fast, reliable \u2502  \u2502 - Privacy-focused    \u2502        \u2502   \u2502\n\u2502  \u2502  \u2502 - Default        \u2502  \u2502 - Cost-effective     \u2502        \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502   \u2502\n\u2502  \u2502  Output: {intent: \"simple_query\" | \"complex_task\"}     \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Response Generation (Dual Generators)                  \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502   \u2502\n\u2502  \u2502  \u2502 Complex Task Handler \u2502  \u2502 Simple Query Handler \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 - Claude Sonnet 4.5  \u2502  \u2502 - Gemini 2.5 Flash   \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 - OpenAI GPT-4o      \u2502  \u2502 - Ollama Llama 3.1   \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 - Code, reasoning    \u2502  \u2502 - Facts, greetings   \u2502    \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Memory Manager                                         \u2502   \u2502\n\u2502  \u2502  - Context building from vector search                 \u2502   \u2502\n\u2502  \u2502  - Deduplication (search once, use twice)              \u2502   \u2502\n\u2502  \u2502  - Retry logic with exponential backoff                \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Memory Layer                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Qdrant Vector Database   \u2502  \u2502  Embeddings Service       \u2502  \u2502\n\u2502  \u2502  - AsyncQdrantClient      \u2502  \u2502  - Gemini text-embed-004  \u2502  \u2502\n\u2502  \u2502  - Collections per user   \u2502  \u2502  - 768-dim vectors        \u2502  \u2502\n\u2502  \u2502  - Semantic search        \u2502  \u2502  - Parallel batching      \u2502  \u2502\n\u2502  \u2502  - Docker container       \u2502  \u2502  - Caching (TODO)         \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Infrastructure                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502   Docker    \u2502  \u2502  Logging    \u2502  \u2502  Configuration      \u2502    \u2502\n\u2502  \u2502   Compose   \u2502  \u2502  Structlog  \u2502  \u2502  Pydantic Settings  \u2502    \u2502\n\u2502  \u2502   - qdrant  \u2502  \u2502  - Console  \u2502  \u2502  - SecretStr        \u2502    \u2502\n\u2502  \u2502   - ollama  \u2502  \u2502  - Files    \u2502  \u2502  - .env validation  \u2502    \u2502\n\u2502  \u2502   - bot     \u2502  \u2502  - JSON     \u2502  \u2502                     \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#core-components","title":"Core Components","text":""},{"location":"ARCHITECTURE/#1-discord-interface-srcsecureclawdiscord","title":"1. Discord Interface (<code>src/secureclaw/discord/</code>)","text":"<p>Purpose: Handle all Discord interactions and command routing.</p> <p>Key Files: - <code>bot.py</code> - Main bot class, event handlers - <code>commands.py</code> - Slash command definitions - <code>security.py</code> - Security controls (allowlist, rate limiting, injection detection)</p> <p>Features: - Slash commands: <code>/channels</code>, <code>/remember</code>, <code>/summarize</code> - DM and @mention support - Message splitting for 2000-char limit - Typing indicators for better UX - Error handling and user feedback</p> <p>Design Decisions: - Used <code>discord.py</code> for stable API and strong typing - Commands implemented as app_commands for modern Discord UI - Security checks run before any agent processing - Async throughout for non-blocking I/O</p>"},{"location":"ARCHITECTURE/#2-agent-core-srcsecureclawagent","title":"2. Agent Core (<code>src/secureclaw/agent/</code>)","text":"<p>Purpose: Intelligent message routing and response generation.</p> <p>Key Files: - <code>core.py</code> - Agent class (orchestrates routing and generation) - <code>router.py</code> - Gemini router backend - <code>router_ollama.py</code> - Ollama router backend - <code>router_factory.py</code> - Backend selection factory - <code>router_base.py</code> - Abstract router interface (Protocol)</p> <p>Message Flow: 1. Router classifies message intent (simple vs complex) 2. Agent searches memory for relevant context 3. Appropriate generator creates response 4. Response returned to Discord</p> <p>Routing Decision Logic: <pre><code>{\n  \"intent\": \"simple_query\",  # or \"complex_task\"\n  \"confidence\": 0.95,\n  \"use_claude\": false  # true for complex tasks\n}\n</code></pre></p> <p>Design Decisions: - Factory pattern allows runtime backend selection - Dual generators optimize cost and latency - Retry logic with exponential backoff (max 3 retries) - Context deduplication (search once, use for both generators)</p>"},{"location":"ARCHITECTURE/#3-memory-system-srcsecureclawmemory","title":"3. Memory System (<code>src/secureclaw/memory/</code>)","text":"<p>Purpose: Long-term semantic memory via vector embeddings.</p> <p>Key Files: - <code>qdrant.py</code> - Vector database client - <code>embeddings.py</code> - Gemini embedding generation</p> <p>Features: - Per-user collections in Qdrant - Semantic search for context retrieval - Parallel batch embeddings (10x faster) - Async operations throughout</p> <p>Vector Storage: - Model: <code>text-embedding-004</code> (Gemini) - Dimensions: 768 - Similarity: Cosine similarity - Storage: Qdrant Docker container</p> <p>Design Decisions: - AsyncQdrantClient prevents event loop blocking - Parallel embeddings via <code>asyncio.gather()</code> - Collections auto-created on first use - No embedding caching (TODO for Phase 5)</p>"},{"location":"ARCHITECTURE/#4-configuration-srcsecureclawconfigpy","title":"4. Configuration (<code>src/secureclaw/config.py</code>)","text":"<p>Purpose: Centralized settings with validation and secrets management.</p> <p>Features: - Pydantic Settings for type-safe configuration - <code>SecretStr</code> for all credentials (never logged) - Environment variable loading from <code>.env</code> - Field validators for critical settings - Computed properties for derived values</p> <p>Configuration Sources: 1. Environment variables 2. <code>.env</code> file (development) 3. Default values (fallback)</p> <p>Design Decisions: - <code>SecretStr</code> ensures credentials never leak to logs - LRU cache prevents repeated file reads - Validators catch misconfigurations early - Clear separation of dev vs prod settings</p>"},{"location":"ARCHITECTURE/#5-logging-srcsecureclawloggingpy","title":"5. Logging (<code>src/secureclaw/logging.py</code>)","text":"<p>Purpose: Structured logging for debugging and monitoring.</p> <p>Features: - Dual handlers (console + rotating files) - Structured logs with <code>structlog</code> - JSON format for files (parseable with <code>jq</code>) - Colored console output in development - Log rotation (10MB \u00d7 6 files)</p> <p>Log Levels: - DEBUG: Detailed diagnostics (development only) - INFO: Normal operations - WARNING: Potential issues - ERROR: Errors that don't crash the bot - CRITICAL: System failures</p> <p>Design Decisions: - Structlog for structured, performant logging - Separate formatters for console vs files - Reduced third-party noise (discord.py, httpx) - Rotation prevents disk filling</p>"},{"location":"ARCHITECTURE/#data-flow","title":"Data Flow","text":""},{"location":"ARCHITECTURE/#example-user-sends-what-is-async-programming","title":"Example: User Sends \"What is async programming?\"","text":"<pre><code>1. Discord Event\n   \u251c\u2500 User sends message in channel\n   \u2514\u2500 on_message() handler triggered\n\n2. Security Checks\n   \u251c\u2500 Allowlist: Is user authorized?\n   \u251c\u2500 Rate Limit: Within 10 msg/60s?\n   \u2514\u2500 Injection: Contains malicious patterns?\n\n3. Message Routing\n   \u251c\u2500 Router Backend (Gemini or Ollama) classifies\n   \u2514\u2500 Result: {intent: \"complex_task\", confidence: 0.92, use_claude: true}\n\n4. Memory Search (Parallel)\n   \u251c\u2500 Generate embedding: embed_text(\"What is async programming?\")\n   \u251c\u2500 Search Qdrant: top_k=5 similar memories\n   \u2514\u2500 Return context: [\"Previous async discussion...\", \"User prefers Python...\"]\n\n5. Response Generation (Claude)\n   \u251c\u2500 Build prompt: message + context\n   \u251c\u2500 Call Claude API: claude-sonnet-4-5-20250929\n   \u2514\u2500 Get response: \"Async programming is...\"\n\n6. Response Delivery\n   \u251c\u2500 Split if &gt; 2000 chars\n   \u251c\u2500 Send to Discord channel\n   \u2514\u2500 Store interaction in memory\n\n7. Memory Storage\n   \u251c\u2500 Embed user message + bot response\n   \u251c\u2500 Store in Qdrant collection (user-specific)\n   \u2514\u2500 Ready for future context retrieval\n</code></pre>"},{"location":"ARCHITECTURE/#design-patterns","title":"Design Patterns","text":""},{"location":"ARCHITECTURE/#1-factory-pattern-router-backend-selection","title":"1. Factory Pattern (Router Backend Selection)","text":"<p>Problem: Need to support multiple routing backends (Gemini, Ollama) without tight coupling.</p> <p>Solution: Factory function creates appropriate backend at runtime.</p> <pre><code>def create_router() -&gt; MessageRouter:\n    settings = get_settings()\n\n    if settings.router_backend == \"ollama\":\n        try:\n            backend = OllamaRouterBackend()\n            if await backend.health_check():\n                return MessageRouter(backend)\n        except Exception:\n            log.warning(\"Ollama failed, falling back to Gemini\")\n\n    # Default to Gemini\n    return MessageRouter(GeminiRouterBackend())\n</code></pre> <p>Benefits: - Easy to add new backends - Runtime configuration - Graceful fallbacks</p>"},{"location":"ARCHITECTURE/#2-strategy-pattern-llm-backends","title":"2. Strategy Pattern (LLM Backends)","text":"<p>Problem: Different LLMs excel at different tasks (Claude for code, Gemini for speed).</p> <p>Solution: Agent selects generator based on router decision.</p> <pre><code>if routing.use_claude:\n    response = await self._generate_claude(message, context)\nelse:\n    response = await self._generate_gemini(message, context)\n</code></pre> <p>Benefits: - Cost optimization - Performance tuning - Easy to swap implementations</p>"},{"location":"ARCHITECTURE/#3-repository-pattern-memory-abstraction","title":"3. Repository Pattern (Memory Abstraction)","text":"<p>Problem: Need to abstract vector database operations from business logic.</p> <p>Solution: <code>QdrantMemory</code> class provides high-level memory interface.</p> <pre><code>class QdrantMemory:\n    async def store(self, text: str, metadata: dict) -&gt; None:\n        \"\"\"Store text with metadata in vector DB.\"\"\"\n\n    async def search(self, query: str, top_k: int = 5) -&gt; list[str]:\n        \"\"\"Search for similar memories.\"\"\"\n</code></pre> <p>Benefits: - Easy to swap Qdrant for another vector DB - Business logic decoupled from storage - Testable with mocks</p>"},{"location":"ARCHITECTURE/#4-singleton-pattern-configuration","title":"4. Singleton Pattern (Configuration)","text":"<p>Problem: Settings should be loaded once and reused.</p> <p>Solution: LRU cache ensures single settings instance.</p> <pre><code>@lru_cache\ndef get_settings() -&gt; Settings:\n    return Settings()\n</code></pre> <p>Benefits: - Fast lookups (no repeated .env parsing) - Consistent configuration throughout app - Memory efficient</p>"},{"location":"ARCHITECTURE/#5-retry-pattern-api-resilience","title":"5. Retry Pattern (API Resilience)","text":"<p>Problem: Cloud APIs have transient failures (rate limits, timeouts).</p> <p>Solution: Exponential backoff retry logic.</p> <pre><code>retries = 0\nwhile retries &lt; 3:\n    try:\n        return await api_call()\n    except (ConnectionError, TimeoutError, RateLimitError):\n        await asyncio.sleep(2 ** retries)\n        retries += 1\nraise MaxRetriesExceeded()\n</code></pre> <p>Benefits: - Handles transient failures - Prevents retry storms - User-friendly (no immediate errors)</p>"},{"location":"ARCHITECTURE/#technology-stack","title":"Technology Stack","text":""},{"location":"ARCHITECTURE/#core-technologies","title":"Core Technologies","text":"Category Technology Version Purpose Language Python 3.12+ Modern async features, type hints Discord Library discord.py 2.4.0+ Discord bot API Vector DB Qdrant Latest Semantic memory storage Embeddings Gemini text-embedding-004 768-dim vectors LLMs Claude Sonnet 4.5 Complex reasoning, code OpenAI GPT-4o Alternative complex tasks Gemini 2.5 Flash Simple queries, routing Ollama Llama 3.1:8b Local routing (optional) Containerization Docker Latest Reproducible deployment Logging structlog Latest Structured, performant logs Config Pydantic 2.0+ Type-safe settings"},{"location":"ARCHITECTURE/#development-tools","title":"Development Tools","text":"Tool Purpose Ruff Linting, formatting (600+ rules) Mypy Type checking (strict mode) Pytest Testing framework Pre-commit Git hooks for quality checks Gitleaks Secret scanning Bandit Security scanning Hadolint Dockerfile linting GitHub Actions CI/CD pipeline Dependabot Dependency updates CodeQL Static analysis"},{"location":"ARCHITECTURE/#api-integrations","title":"API Integrations","text":"Provider API Purpose Anthropic Claude API Complex task generation OpenAI Chat Completions Alternative complex tasks Google Gemini API Routing, simple queries, embeddings Ollama HTTP API Local routing (optional) Discord Gateway &amp; REST Bot interactions"},{"location":"ARCHITECTURE/#scalability-performance","title":"Scalability &amp; Performance","text":""},{"location":"ARCHITECTURE/#current-performance-characteristics","title":"Current Performance Characteristics","text":"Operation Latency Notes Router Classification 200-500ms Gemini Flash (fast) Simple Response 500-1000ms Gemini Flash Complex Response 2-5s Claude Sonnet Memory Search 100-200ms Qdrant local Embedding Generation 200-400ms Parallel batching Discord Message Send 100-300ms Discord API"},{"location":"ARCHITECTURE/#optimization-strategies","title":"Optimization Strategies","text":"<ol> <li>Parallel Operations</li> <li>Embeddings: <code>asyncio.gather()</code> for batch processing</li> <li>Memory searches: Single search reused for both generators</li> <li> <p>Independent API calls: Concurrent execution</p> </li> <li> <p>Caching (TODO for Phase 5)</p> </li> <li>Embedding cache for repeated queries</li> <li>Response cache for identical messages</li> <li> <p>Memory cache for frequently accessed context</p> </li> <li> <p>Async-First Architecture</p> </li> <li>AsyncQdrantClient (non-blocking vector DB)</li> <li>Async Discord handlers</li> <li>Async LLM API calls</li> <li> <p>No blocking I/O in event loop</p> </li> <li> <p>Resource Limits</p> </li> <li>Rate limiting (10 msg/60s per user)</li> <li>Memory search top_k=5 (limits context size)</li> <li>Message splitting (prevents Discord rate limits)</li> </ol>"},{"location":"ARCHITECTURE/#scalability-considerations","title":"Scalability Considerations","text":"<p>Current Scale: - Single Discord server - ~10-50 concurrent users - ~100-500 messages/hour - Docker Compose on single host</p> <p>Future Scale (Phase 5+): - Multiple Discord servers - 100-1000 concurrent users - Kubernetes deployment - Distributed Qdrant cluster - Horizontal scaling of bot instances - Load balancing across LLM providers</p>"},{"location":"ARCHITECTURE/#security-architecture","title":"Security Architecture","text":"<p>See docs/SECURITY.md for comprehensive security documentation.</p>"},{"location":"ARCHITECTURE/#defense-in-depth","title":"Defense in Depth","text":"<pre><code>Layer 1: Network (Docker bridge network, no exposed ports)\n  \u2193\nLayer 2: Input Validation (Allowlist, rate limiting)\n  \u2193\nLayer 3: Content Filtering (Prompt injection detection)\n  \u2193\nLayer 4: Secrets Management (Pydantic SecretStr, env vars)\n  \u2193\nLayer 5: Monitoring (Structured logs, error tracking)\n</code></pre>"},{"location":"ARCHITECTURE/#key-security-controls","title":"Key Security Controls","text":"<ol> <li>User Allowlist - Only authorized Discord user IDs can interact</li> <li>Rate Limiting - 10 messages per 60 seconds per user</li> <li>Prompt Injection Detection - 17 regex patterns + Unicode obfuscation</li> <li>Secrets Management - SecretStr, never logged, .env gitignored</li> <li>Secret Scanning - Gitleaks pre-commit hook</li> <li>Dependency Scanning - Dependabot weekly updates</li> <li>Static Analysis - CodeQL weekly scans</li> <li>Container Security - Slim base image, health checks</li> </ol>"},{"location":"ARCHITECTURE/#security-gap-analysis","title":"Security Gap Analysis","text":"<p>See docs/SECURITY.md#12-gap-analysis for: - Container image scanning (Trivy) - SBOM generation - Signed commits - Read-only container filesystem - And 8 more recommendations</p>"},{"location":"ARCHITECTURE/#future-roadmap","title":"Future Roadmap","text":""},{"location":"ARCHITECTURE/#phase-5-advanced-features-planned","title":"Phase 5: Advanced Features (Planned)","text":"<p>See <code>memory/phase5-plan.md</code> for detailed plan.</p> <p>5A: Encrypted Memory - AES-256-GCM encryption for sensitive data - PyCA cryptography library - Encrypted fields in Qdrant metadata</p> <p>5B: User Profiling - Preferences tracking (language, timezone, interests) - Automatic profile updates from conversations - Profile-aware context building</p> <p>5C: Skills Framework - Pluggable command system - Separate Docker container for skills - Python sandbox for user-contributed skills</p> <p>5D: Smart Multi-Provider Routing - Provider capability matrix (Claude for code, OpenAI for reasoning, Gemini for docs) - Dynamic routing based on message analysis - Cost-aware provider selection</p> <p>5E: Heartbeat Scheduler - Proactive tasks (daily summaries, reminders) - Cron-like scheduling - Background task management</p> <p>5F: Advanced Memory - Embedding caching - Multi-modal memory (images, files) - Memory consolidation and pruning</p> <p>5G: Production Hardening - Kubernetes deployment - Distributed tracing (OpenTelemetry) - Metrics (Prometheus) - Alerting (PagerDuty/Slack)</p>"},{"location":"ARCHITECTURE/#long-term-vision","title":"Long-Term Vision","text":"<ul> <li>Multi-Channel Support - Slack, Teams, Telegram</li> <li>Web Dashboard - Admin UI for configuration</li> <li>Mobile App - React Native or Flutter</li> <li>Custom Model Fine-Tuning - Domain-specific models</li> <li>Federated Deployment - Multi-region for low latency</li> <li>Plugin Marketplace - Community-contributed skills</li> </ul>"},{"location":"ARCHITECTURE/#design-decisions-log","title":"Design Decisions Log","text":""},{"location":"ARCHITECTURE/#why-gemini-for-embeddings","title":"Why Gemini for Embeddings?","text":"<p>Decision: Use Gemini <code>text-embedding-004</code> instead of OpenAI <code>text-embedding-3-small</code>.</p> <p>Rationale: - Same API as routing (fewer integrations) - 768 dimensions (good balance of quality vs storage) - Free tier available - Proven quality in benchmarks</p> <p>Trade-offs: - Tied to Google ecosystem - Less flexibility than OpenAI</p>"},{"location":"ARCHITECTURE/#why-dual-routing-backends","title":"Why Dual Routing Backends?","text":"<p>Decision: Support both Gemini (cloud) and Ollama (local) for routing.</p> <p>Rationale: - Privacy: Some users prefer local inference - Cost: Ollama has no API costs - Reliability: Fallback if one provider fails - Flexibility: Users can choose based on needs</p> <p>Trade-offs: - Increased complexity - More testing required - Ollama requires GPU for good performance</p>"},{"location":"ARCHITECTURE/#why-discordpy-over-other-libraries","title":"Why Discord.py Over Other Libraries?","text":"<p>Decision: Use <code>discord.py</code> instead of alternatives like <code>discord.js</code> or <code>pycord</code>.</p> <p>Rationale: - Python ecosystem (same language as backend) - Strong typing support - Active maintenance - Excellent documentation - Mature slash command support</p> <p>Trade-offs: - Python slower than Node.js (not critical for this use case) - Fewer real-time features than discord.js</p>"},{"location":"ARCHITECTURE/#why-qdrant-over-alternatives","title":"Why Qdrant Over Alternatives?","text":"<p>Decision: Use Qdrant instead of Pinecone, Weaviate, or Milvus.</p> <p>Rationale: - Self-hosted (no vendor lock-in) - Docker-native (easy deployment) - Excellent async Python client - Good performance on consumer hardware - Open source</p> <p>Trade-offs: - Less managed than Pinecone - Smaller ecosystem than Weaviate - Manual scaling required</p>"},{"location":"ARCHITECTURE/#why-pydantic-settings-over-python-decouple","title":"Why Pydantic Settings Over python-decouple?","text":"<p>Decision: Use Pydantic Settings for configuration.</p> <p>Rationale: - Type validation at load time - SecretStr for credentials - Computed properties - Same library as data models - Better IDE support</p> <p>Trade-offs: - Heavier than python-decouple - Requires Pydantic knowledge</p>"},{"location":"ARCHITECTURE/#diagrams","title":"Diagrams","text":""},{"location":"ARCHITECTURE/#component-interaction-diagram","title":"Component Interaction Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Discord   \u2502\n\u2502    User     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Message\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          Security Layer                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502Allowlist\u2502\u2192\u2502Rate    \u2502\u2192\u2502Injection    \u2502 \u2502\n\u2502  \u2502Check    \u2502 \u2502Limit   \u2502 \u2502Detection    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Authorized\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          Agent Core                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Router Factory                 \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502  \u2502  \u2502 Gemini   \u2502 or\u2502 Ollama   \u2502   \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502       \u2502                                 \u2502\n\u2502       \u2502 Routing Decision                \u2502\n\u2502       \u25bc                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Memory Manager                 \u2502   \u2502\n\u2502  \u2502  Search Qdrant for context      \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502       \u2502                                 \u2502\n\u2502       \u2502 Context                         \u2502\n\u2502       \u25bc                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Generator Selection            \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502   \u2502\n\u2502  \u2502  \u2502 Claude  \u2502 or\u2502 Gemini   \u2502    \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Response\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          Memory Storage                 \u2502\n\u2502  Embed and store in Qdrant              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Discord   \u2502\n\u2502   Response  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#references","title":"References","text":"<ul> <li>Discord.py Documentation</li> <li>Qdrant Documentation</li> <li>Anthropic Claude API</li> <li>OpenAI API</li> <li>Google Gemini API</li> <li>Pydantic Documentation</li> <li>Docker Documentation</li> <li>Structlog Documentation</li> </ul>"},{"location":"ARCHITECTURE/#contact-support","title":"Contact &amp; Support","text":"<ul> <li>Issues: https://github.com/jimtin/sercureclaw/issues</li> <li>Discussions: https://github.com/jimtin/sercureclaw/discussions</li> <li>Documentation: See docs/ directory for detailed guides</li> </ul> <p>Last Updated: 2026-02-06 Version: 1.0.0 (Phases 1-4 complete, 87.58% test coverage)</p>"},{"location":"CI_CD/","title":"CI/CD Pipeline Documentation","text":"<p>Complete guide to SecureClaw's testing and continuous integration setup.</p>"},{"location":"CI_CD/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Local Development Workflow</li> <li>Git Hooks Setup</li> <li>Pre-Commit Hooks</li> <li>Pre-Push Hooks</li> <li>GitHub Actions CI/CD</li> <li>Running Tests Manually</li> <li>Troubleshooting</li> </ol>"},{"location":"CI_CD/#overview","title":"Overview","text":"<p>SecureClaw uses a three-tier testing approach to ensure code quality:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Tier 1: Pre-Commit Hooks (Lightweight)                     \u2502\n\u2502  \u2022 Runs before each commit                                  \u2502\n\u2502  \u2022 Linting (Ruff)                                           \u2502\n\u2502  \u2022 Formatting (Ruff Format)                                 \u2502\n\u2502  \u2022 File checks (trailing whitespace, large files, etc.)     \u2502\n\u2502  \u2022 Security scan (Bandit)                                   \u2502\n\u2502  Duration: ~5-10 seconds                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Tier 2: Pre-Push Hooks (Comprehensive)                     \u2502\n\u2502  \u2022 Runs before each push to remote                          \u2502\n\u2502  \u2022 Full linting                                             \u2502\n\u2502  \u2022 Type checking (mypy)                                     \u2502\n\u2502  \u2022 Complete test suite with coverage                        \u2502\n\u2502  Duration: ~30-60 seconds                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Tier 3: GitHub Actions CI/CD (Exhaustive)                  \u2502\n\u2502  \u2022 Runs on push/PR to main/develop                          \u2502\n\u2502  \u2022 Multi-version testing (Python 3.12, 3.13)               \u2502\n\u2502  \u2022 Integration tests with services (Qdrant)                 \u2502\n\u2502  \u2022 Docker build validation                                  \u2502\n\u2502  \u2022 Security scanning                                        \u2502\n\u2502  \u2022 Coverage reporting (Codecov)                             \u2502\n\u2502  Duration: ~5-10 minutes                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Philosophy: - Fast feedback locally (pre-commit catches simple issues in seconds) - Confidence before push (pre-push ensures tests pass) - Comprehensive CI (GitHub Actions catches integration issues)</p>"},{"location":"CI_CD/#local-development-workflow","title":"Local Development Workflow","text":""},{"location":"CI_CD/#recommended-workflow","title":"Recommended Workflow","text":"<pre><code># 1. Make your changes\nvim src/secureclaw/some_file.py\n\n# 2. Commit (pre-commit hooks run automatically)\ngit add src/secureclaw/some_file.py\ngit commit -m \"Add new feature\"\n# \u2192 Runs linting, formatting, security checks (~5-10s)\n\n# 3. Push (pre-push hooks run automatically)\ngit push origin main\n# \u2192 Runs full test suite (~30-60s)\n# \u2192 If tests pass, code is pushed to GitHub\n# \u2192 GitHub Actions CI/CD starts automatically\n</code></pre>"},{"location":"CI_CD/#what-happens-when","title":"What Happens When","text":"<p>On <code>git commit</code>: 1. Ruff linter checks code style 2. Ruff formatter auto-fixes formatting 3. File checks (trailing whitespace, large files) 4. Security scan (Bandit) 5. If all pass \u2192 commit succeeds 6. If any fail \u2192 commit blocked, fixes applied automatically</p> <p>On <code>git push</code>: 1. Full Ruff linting (comprehensive) 2. Type checking with mypy 3. Complete test suite with pytest 4. Coverage report 5. If all pass \u2192 push succeeds 6. If any fail \u2192 push blocked, errors shown</p> <p>On GitHub (after push): 1. Linting job 2. Type checking job 3. Security scanning job 4. Tests on Python 3.12 &amp; 3.13 5. Docker build validation 6. Integration tests with Qdrant 7. Summary report</p>"},{"location":"CI_CD/#git-hooks-setup","title":"Git Hooks Setup","text":""},{"location":"CI_CD/#initial-setup-one-time","title":"Initial Setup (One-Time)","text":"<p>After cloning the repository:</p> <pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Run setup script\n./scripts/setup-git-hooks.sh\n</code></pre> <p>What the script does: 1. Installs <code>pre-commit</code> framework 2. Installs pre-commit hooks from <code>.pre-commit-config.yaml</code> 3. Creates symlink for custom pre-push hook 4. Optionally runs checks on all files</p> <p>Manual Setup (if script fails):</p> <pre><code># 1. Install pre-commit\npip install pre-commit\n\n# 2. Install hooks\npre-commit install --hook-type pre-commit --hook-type pre-push\n\n# 3. Link custom pre-push hook\nln -sf ../../.git-hooks/pre-push .git/hooks/pre-push\n</code></pre>"},{"location":"CI_CD/#verify-installation","title":"Verify Installation","text":"<pre><code># Check that hooks are installed\nls -la .git/hooks/\n# Should show: pre-commit, pre-push (symlinks)\n\n# Test pre-commit hooks\npre-commit run --all-files\n</code></pre>"},{"location":"CI_CD/#pre-commit-hooks","title":"Pre-Commit Hooks","text":""},{"location":"CI_CD/#what-runs-on-every-commit","title":"What Runs on Every Commit","text":"<p>Defined in <code>.pre-commit-config.yaml</code>:</p> <ol> <li>Ruff Linter</li> <li>Checks: Code style (PEP 8), unused imports, complexity</li> <li>Auto-fixes: Import sorting, simple style issues</li> <li> <p>Config: <code>pyproject.toml</code></p> </li> <li> <p>Ruff Formatter</p> </li> <li>Checks: Code formatting (like Black)</li> <li>Auto-fixes: Reformats all Python files</li> <li> <p>Replaces: Black, isort</p> </li> <li> <p>General File Checks</p> </li> <li>Large files (&gt;1MB blocked)</li> <li>Trailing whitespace (auto-removed)</li> <li>File endings (ensures newline at EOF)</li> <li>YAML/TOML/JSON syntax</li> <li>Merge conflict markers</li> <li> <p>Private keys detection</p> </li> <li> <p>Bandit Security Scan</p> </li> <li>Checks: Common security issues (SQL injection, hardcoded passwords, etc.)</li> <li>Skips: Test files</li> <li> <p>Config: <code>pyproject.toml</code></p> </li> <li> <p>Gitleaks Secret Scanner</p> </li> <li>Checks: API keys, tokens, passwords, private keys, credentials</li> <li>Detects: Discord tokens, Google/Gemini keys, Anthropic keys, OpenAI keys, AWS keys, GitHub tokens, JWT tokens, high-entropy strings</li> <li>Config: <code>.gitleaks.toml</code></li> <li> <p>Prevents: Accidental commit of secrets to repository</p> </li> <li> <p>Hadolint (Dockerfile linting)</p> </li> <li>Checks: Dockerfile best practices</li> <li>Ignores: Apt-get pin warnings</li> </ol>"},{"location":"CI_CD/#bypassing-pre-commit-not-recommended","title":"Bypassing Pre-Commit (Not Recommended)","text":"<pre><code># Skip all pre-commit hooks (NOT RECOMMENDED)\ngit commit --no-verify -m \"Quick fix\"\n\n# Skip specific hook\nSKIP=ruff git commit -m \"Skip ruff only\"\n</code></pre> <p>\u26a0\ufe0f Warning: Bypassing hooks may cause CI to fail.</p>"},{"location":"CI_CD/#running-pre-commit-manually","title":"Running Pre-Commit Manually","text":"<pre><code># Run on all files\npre-commit run --all-files\n\n# Run on staged files only\npre-commit run\n\n# Run specific hook\npre-commit run ruff --all-files\n\n# Run only Gitleaks secret scanner\npre-commit run gitleaks --all-files\n\n# Update hooks to latest versions\npre-commit autoupdate\n</code></pre>"},{"location":"CI_CD/#secret-scanning-with-gitleaks","title":"Secret Scanning with Gitleaks","text":"<p>What Gitleaks Detects: - API Keys: Discord tokens, Google/Gemini keys, Anthropic (Claude) keys, OpenAI keys, AWS keys, GitHub tokens - Private Keys: RSA, SSH, PGP, OpenSSH private keys - Credentials: Passwords in URLs, JWT tokens, Slack tokens - High-Entropy Strings: Potential secrets based on randomness</p> <p>Configuration: - Rules defined in <code>.gitleaks.toml</code> - Custom rules for SecureClaw-specific secrets - Allowlist for false positives (e.g., <code>.env.example</code>, test fixtures)</p> <p>What's Excluded: - <code>.env.example</code> (template file with placeholders) - Test fixtures with <code>test_*</code> prefixes - Generated files (lock files, cache directories) - Logs and coverage reports</p> <p>If Gitleaks Finds a Secret: <pre><code># 1. DO NOT commit the file\n# 2. Remove the secret from the file\nvim .env  # Replace actual secret with placeholder\n\n# 3. If the secret was already committed (previous commits):\n# Option A: Use BFG Repo-Cleaner to remove from history\ngit clone --mirror git@github.com:user/repo.git\nbfg --replace-text passwords.txt repo.git\ncd repo.git\ngit reflog expire --expire=now --all &amp;&amp; git gc --prune=now --aggressive\ngit push\n\n# Option B: Interactive rebase (for recent commits)\ngit rebase -i HEAD~5  # Edit last 5 commits\n# Mark commit as 'edit', remove secret, continue\ngit rebase --continue\n\n# 4. Rotate the exposed secret immediately\n# - Discord: Generate new bot token\n# - API keys: Regenerate in provider dashboard\n</code></pre></p> <p>Testing Gitleaks: <pre><code># Scan all files\npre-commit run gitleaks --all-files\n\n# Scan specific file\ngitleaks detect --no-git --source=src/secureclaw/config.py\n\n# Generate detailed report\ngitleaks detect --no-git --report-path=gitleaks-report.json\n</code></pre></p>"},{"location":"CI_CD/#pre-push-hooks","title":"Pre-Push Hooks","text":""},{"location":"CI_CD/#what-runs-before-every-push","title":"What Runs Before Every Push","text":"<p>Defined in <code>.git-hooks/pre-push</code>:</p> <p>Step 1: Linting (Ruff) <pre><code>ruff check src/ tests/\n</code></pre> - Comprehensive linting of all source code - Fails if any issues found</p> <p>Step 2: Type Checking (mypy) <pre><code>mypy src/secureclaw --config-file=pyproject.toml\n</code></pre> - Static type checking - Ensures type safety - Skips: Tests, scripts</p> <p>Step 3: Full Test Suite <pre><code>pytest tests/ -v --tb=short --cov=src/secureclaw --cov-report=term-missing\n</code></pre> - Runs all tests - Generates coverage report - Shows missing coverage</p> <p>Total Time: ~30-60 seconds</p>"},{"location":"CI_CD/#bypassing-pre-push-not-recommended","title":"Bypassing Pre-Push (Not Recommended)","text":"<pre><code># Skip pre-push hook (NOT RECOMMENDED)\ngit push --no-verify origin main\n</code></pre> <p>\u26a0\ufe0f Warning: This will likely cause GitHub Actions to fail.</p>"},{"location":"CI_CD/#running-pre-push-checks-manually","title":"Running Pre-Push Checks Manually","text":"<pre><code># Run the pre-push hook manually\n.git-hooks/pre-push\n\n# Or run individual steps:\nruff check src/ tests/\nmypy src/secureclaw --config-file=pyproject.toml\npytest tests/ -v --cov=src/secureclaw\n</code></pre>"},{"location":"CI_CD/#github-actions-cicd","title":"GitHub Actions CI/CD","text":""},{"location":"CI_CD/#workflow-overview","title":"Workflow Overview","text":"<p>Defined in <code>.github/workflows/ci.yml</code></p> <p>Triggers: - Push to <code>main</code> or <code>develop</code> branches - Pull requests to <code>main</code> or <code>develop</code> - Manual trigger via GitHub UI (<code>workflow_dispatch</code>)</p> <p>Jobs:</p> <pre><code>lint (5s)\n  \u251c\u2500 Ruff linter\n  \u2514\u2500 Ruff formatter check\n\ntype-check (10s)\n  \u2514\u2500 mypy on src/secureclaw\n\nsecurity (10s)\n  \u2514\u2500 Bandit security scan\n\ntest (60s)\n  \u251c\u2500 Python 3.12 tests + coverage\n  \u2514\u2500 Python 3.13 tests + coverage\n\ndocker-build (30s)\n  \u251c\u2500 Build Docker image\n  \u2514\u2500 Validate docker-compose.yml\n\nintegration (2-3 min) \u26a1 RUNS BY DEFAULT\n  \u251c\u2500 Start Docker Compose (Qdrant + SecureClaw)\n  \u251c\u2500 Wait for services to be healthy\n  \u251c\u2500 Run full end-to-end integration tests\n  \u251c\u2500 Upload logs on failure\n  \u2514\u2500 Clean up Docker resources\n\nsummary (5s)\n  \u251c\u2500 Check all job results\n  \u2514\u2500 Post summary to PR\n</code></pre> <p>Total Time: ~5-10 minutes</p>"},{"location":"CI_CD/#integration-tests-run-automatically","title":"\u26a1 Integration Tests Run Automatically","text":"<p>NEW: Integration tests now run by default on every push/PR to ensure end-to-end functionality.</p> <p>To skip integration tests, add <code>[skip integration]</code> to your commit message:</p> <pre><code>git commit -m \"Update documentation [skip integration]\"\ngit push\n</code></pre> <p>When to skip: - Documentation-only changes - Minor typo fixes - README updates - Configuration changes that don't affect functionality</p> <p>When NOT to skip: - Code changes in <code>src/</code> - Changes to Docker configuration - Dependency updates - Any functional changes</p>"},{"location":"CI_CD/#viewing-ci-results","title":"Viewing CI Results","text":"<p>On GitHub: 1. Go to your repository 2. Click Actions tab 3. Click on the latest workflow run 4. View job results and logs</p> <p>On Pull Requests: - Status checks appear at bottom of PR - Required checks must pass before merging - Click \"Details\" to see full logs</p>"},{"location":"CI_CD/#coverage-reports","title":"Coverage Reports","text":"<p>Codecov Integration: - Coverage reports uploaded to codecov.io - Badge shows coverage percentage - PR comments show coverage changes</p> <p>Download Coverage Report: <pre><code># Coverage HTML report saved as artifact\n# Download from GitHub Actions \u2192 Workflow run \u2192 Artifacts\n</code></pre></p>"},{"location":"CI_CD/#manual-trigger","title":"Manual Trigger","text":"<pre><code># Via GitHub CLI\ngh workflow run ci.yml\n\n# Via GitHub UI\n# Actions \u2192 CI/CD Pipeline \u2192 Run workflow\n</code></pre>"},{"location":"CI_CD/#running-tests-manually","title":"Running Tests Manually","text":""},{"location":"CI_CD/#quick-tests-during-development","title":"Quick Tests (During Development)","text":"<pre><code># Run specific test file\npytest tests/test_router.py -v\n\n# Run specific test class\npytest tests/test_config.py::TestSettingsInitialization -v\n\n# Run specific test\npytest tests/test_config.py::TestSettingsInitialization::test_settings_from_env_minimal -v\n\n# Run with pattern matching\npytest tests/ -k \"test_router\" -v\n</code></pre>"},{"location":"CI_CD/#full-test-suite","title":"Full Test Suite","text":"<pre><code># With coverage\npytest tests/ --cov=src/secureclaw --cov-report=html\n\n# Open coverage report\nopen htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\n</code></pre>"},{"location":"CI_CD/#test-markers","title":"Test Markers","text":"<pre><code># Run only fast tests (exclude slow integration tests)\npytest tests/ -v -m \"not slow\"\n\n# Run only integration tests\npytest tests/ -v -m \"integration\"\n\n# Run only unit tests\npytest tests/ -v -m \"unit\"\n</code></pre>"},{"location":"CI_CD/#debugging-tests","title":"Debugging Tests","text":"<pre><code># Show print statements\npytest tests/ -v -s\n\n# Drop into debugger on failure\npytest tests/ -v --pdb\n\n# Show full traceback\npytest tests/ -v --tb=long\n\n# Stop at first failure\npytest tests/ -v -x\n</code></pre>"},{"location":"CI_CD/#troubleshooting","title":"Troubleshooting","text":""},{"location":"CI_CD/#pre-commit-hook-fails","title":"Pre-Commit Hook Fails","text":"<p>Error: <code>pre-commit: command not found</code> <pre><code># Solution: Install pre-commit\npip install pre-commit\npre-commit install\n</code></pre></p> <p>Error: Hook fails with ImportError <pre><code># Solution: Ensure dependencies installed\npip install -r requirements.txt\npip install -e \".[dev]\"\n</code></pre></p> <p>Error: Ruff not found <pre><code># Solution: Install dev dependencies\npip install ruff mypy bandit[toml]\n</code></pre></p>"},{"location":"CI_CD/#pre-push-hook-fails","title":"Pre-Push Hook Fails","text":"<p>Error: Tests fail locally <pre><code># 1. Run tests to see details\npytest tests/ -v --tb=short\n\n# 2. Fix failing tests\n\n# 3. Try again\ngit push\n</code></pre></p> <p>Error: mypy type errors <pre><code># 1. Run mypy to see details\nmypy src/secureclaw --config-file=pyproject.toml\n\n# 2. Fix type errors\n\n# 3. Try again\ngit push\n</code></pre></p> <p>Error: Coverage too low <pre><code># 1. Check which files lack coverage\npytest tests/ --cov=src/secureclaw --cov-report=term-missing\n\n# 2. Add tests for missing coverage\n\n# 3. Try again\ngit push\n</code></pre></p>"},{"location":"CI_CD/#github-actions-fails","title":"GitHub Actions Fails","text":"<p>Error: Tests pass locally but fail on GitHub</p> <p>Possible causes: 1. Environment differences    - Solution: Ensure <code>.env</code> secrets are set in GitHub    - Go to: Settings \u2192 Secrets and variables \u2192 Actions</p> <ol> <li>Dependency issues</li> <li>Solution: Check if <code>requirements.txt</code> is up to date</li> <li> <p>Run: <code>pip freeze &gt; requirements.txt</code></p> </li> <li> <p>Python version differences</p> </li> <li>Solution: Test locally with Python 3.12 and 3.13</li> <li> <p>Use: <code>pyenv</code> or Docker</p> </li> <li> <p>Service dependencies</p> </li> <li>Solution: Check if Qdrant service started correctly</li> <li>View logs in GitHub Actions</li> </ol> <p>Error: Docker build fails on GitHub <pre><code># Test Docker build locally\ndocker build -t secureclaw:test .\n\n# If fails, fix Dockerfile and try again\n</code></pre></p>"},{"location":"CI_CD/#bypassing-hooks-safely","title":"Bypassing Hooks Safely","text":"<p>When it's okay to bypass: - Emergency hotfix (fix immediately, create cleanup PR later) - Documentation-only changes - CI configuration changes</p> <p>How to bypass safely: <pre><code># Skip pre-commit only\ngit commit --no-verify -m \"docs: Update README\"\n\n# Skip pre-push only (commit hooks still run)\ngit push --no-verify origin main\n\n# Skip all (NOT RECOMMENDED)\ngit commit --no-verify -m \"Emergency fix\"\ngit push --no-verify origin main\n</code></pre></p> <p>\u26a0\ufe0f Best Practice: - Use <code>--no-verify</code> sparingly - Always create follow-up PR to fix issues - Never bypass on <code>main</code> branch</p>"},{"location":"CI_CD/#configuration-files","title":"Configuration Files","text":""},{"location":"CI_CD/#pre-commit-configuration","title":"Pre-Commit Configuration","text":"<p>File: <code>.pre-commit-config.yaml</code></p> <pre><code>repos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.2.2\n    hooks:\n      - id: ruff\n      - id: ruff-format\n</code></pre> <p>Update hooks: <pre><code>pre-commit autoupdate\n</code></pre></p>"},{"location":"CI_CD/#test-configuration","title":"Test Configuration","text":"<p>File: <code>pyproject.toml</code></p> <pre><code>[tool.pytest.ini_options]\nasyncio_mode = \"auto\"\ntestpaths = [\"tests\"]\naddopts = [\n    \"-v\",\n    \"--strict-markers\",\n    \"--tb=short\",\n    \"--cov=src/secureclaw\",\n]\n</code></pre>"},{"location":"CI_CD/#type-checking-configuration","title":"Type Checking Configuration","text":"<p>File: <code>pyproject.toml</code></p> <pre><code>[tool.mypy]\npython_version = \"3.12\"\nstrict = true\n</code></pre>"},{"location":"CI_CD/#best-practices","title":"Best Practices","text":""},{"location":"CI_CD/#commit-messages","title":"Commit Messages","text":"<p>Follow Conventional Commits:</p> <pre><code># Feature\ngit commit -m \"feat: Add Ollama router backend\"\n\n# Bug fix\ngit commit -m \"fix: Resolve Docker memory allocation bug\"\n\n# Documentation\ngit commit -m \"docs: Update CI/CD setup guide\"\n\n# Tests\ngit commit -m \"test: Add Ollama router tests\"\n\n# Chore\ngit commit -m \"chore: Update dependencies\"\n</code></pre>"},{"location":"CI_CD/#test-coverage","title":"Test Coverage","text":"<p>Target: 80%+ coverage</p> <pre><code># Check current coverage\npytest tests/ --cov=src/secureclaw --cov-report=term\n\n# View detailed report\npytest tests/ --cov=src/secureclaw --cov-report=html\nopen htmlcov/index.html\n</code></pre>"},{"location":"CI_CD/#code-quality","title":"Code Quality","text":"<p>Before committing: 1. Run <code>ruff check --fix src/ tests/</code> 2. Run <code>mypy src/secureclaw</code> 3. Run <code>pytest tests/</code> 4. Review changes: <code>git diff</code></p> <p>Before pushing: 1. Ensure tests pass 2. Update documentation if needed 3. Check coverage hasn't decreased 4. Rebase on latest main</p>"},{"location":"CI_CD/#quick-reference","title":"Quick Reference","text":""},{"location":"CI_CD/#common-commands","title":"Common Commands","text":"<pre><code># Setup git hooks (one-time)\n./scripts/setup-git-hooks.sh\n\n# Run pre-commit manually\npre-commit run --all-files\n\n# Run tests\npytest tests/ -v\n\n# Run tests with coverage\npytest tests/ --cov=src/secureclaw\n\n# Run linter\nruff check src/ tests/\n\n# Run formatter\nruff format src/ tests/\n\n# Run type checker\nmypy src/secureclaw\n\n# Update pre-commit hooks\npre-commit autoupdate\n\n# Skip hooks (emergency only)\ngit commit --no-verify\ngit push --no-verify\n</code></pre>"},{"location":"CI_CD/#github-actions-badge","title":"GitHub Actions Badge","text":"<p>Add to README.md:</p> <pre><code>[![CI](https://github.com/yourusername/secureclaw/actions/workflows/ci.yml/badge.svg)](https://github.com/yourusername/secureclaw/actions/workflows/ci.yml)\n</code></pre>"},{"location":"CI_CD/#additional-resources","title":"Additional Resources","text":"<ul> <li>Pre-commit Framework</li> <li>Ruff Documentation</li> <li>GitHub Actions Documentation</li> <li>Pytest Documentation</li> <li>Codecov Documentation</li> </ul>"},{"location":"COMMANDS/","title":"SecureClaw Command Reference","text":"<p>Complete list of all Discord commands and interactions for SecureClaw.</p>"},{"location":"COMMANDS/#quick-reference","title":"Quick Reference","text":"Command Type Description Usage <code>/ask</code> Slash Command Ask a question <code>/ask What is Python?</code> <code>/remember</code> Slash Command Store a memory <code>/remember I prefer dark mode</code> <code>/search</code> Slash Command Search memories <code>/search preferences</code> <code>/ping</code> Slash Command Check bot status <code>/ping</code> DM Direct Message Talk naturally Just send a message Mention Server Message Ask in server <code>@SecureClaw help me</code>"},{"location":"COMMANDS/#slash-commands","title":"Slash Commands","text":""},{"location":"COMMANDS/#ask-ask-a-question","title":"<code>/ask</code> - Ask a Question","text":"<p>Description: Ask SecureClaw a question or request help with a task.</p> <p>Syntax: <pre><code>/ask &lt;question&gt;\n</code></pre></p> <p>Parameters: - <code>question</code> (required) - Your question or request</p> <p>Examples: <pre><code>/ask What is the capital of France?\n/ask Explain async/await in Python\n/ask Write a function to reverse a string\n/ask What's the weather like? (bot doesn't have real-time data)\n/ask Help me debug this error: TypeError...\n</code></pre></p> <p>Behavior: - Bot analyzes intent and complexity - Simple questions \u2192 Answered by Gemini Flash (fast) - Complex tasks \u2192 Routed to Claude/GPT-4 (slower, better quality) - Searches recent conversation history and relevant memories - Response includes context from previous interactions</p> <p>Expected Response Time: - Simple queries: 1-3 seconds - Complex tasks: 5-15 seconds</p> <p>Security: - Checks user allowlist - Rate limited (10 messages per minute) - Prompt injection detection enabled</p>"},{"location":"COMMANDS/#remember-store-a-memory","title":"<code>/remember</code> - Store a Memory","text":"<p>Description: Ask SecureClaw to remember something for later retrieval.</p> <p>Syntax: <pre><code>/remember &lt;content&gt;\n</code></pre></p> <p>Parameters: - <code>content</code> (required) - What you want the bot to remember</p> <p>Examples: <pre><code>/remember I prefer dark mode in all applications\n/remember My birthday is March 15th\n/remember I'm a Python developer working on web apps\n/remember I don't like spicy food\n/remember Project deadline is next Friday\n</code></pre></p> <p>Behavior: - Stores content in Qdrant vector database - Content is embedded using Gemini text-embedding-004 - Searchable via semantic similarity - Persists across bot restarts - Automatically recalled in relevant future conversations</p> <p>Expected Response: <pre><code>\u2713 I'll remember that: \"I prefer dark mode in all applications\"\n</code></pre></p> <p>Response Time: &lt; 2 seconds</p> <p>Storage: - Stored in: <code>qdrant_storage/collections/long_term_memory/</code> - Persists until manually deleted - Encrypted at rest (if Qdrant configured with encryption)</p>"},{"location":"COMMANDS/#search-search-memories","title":"<code>/search</code> - Search Memories","text":"<p>Description: Search your stored memories by semantic similarity.</p> <p>Syntax: <pre><code>/search &lt;query&gt;\n</code></pre></p> <p>Parameters: - <code>query</code> (required) - What to search for</p> <p>Examples: <pre><code>/search preferences\n/search birthday\n/search Python projects\n/search food preferences\n/search deadlines\n</code></pre></p> <p>Behavior: - Searches long-term memory collection - Uses vector similarity (not keyword matching) - Returns top 5 most relevant memories - Shows similarity score (0-100%) - Sorted by relevance</p> <p>Expected Response: <pre><code>**Search Results:**\n\n1. [95%] I prefer dark mode in all applications\n2. [87%] I'm a Python developer working on web apps\n3. [72%] Project uses FastAPI framework\n</code></pre></p> <p>Response Time: &lt; 1 second</p> <p>No Results Response: <pre><code>No matching memories found.\n</code></pre></p>"},{"location":"COMMANDS/#ping-check-bot-status","title":"<code>/ping</code> - Check Bot Status","text":"<p>Description: Verify the bot is online and check latency.</p> <p>Syntax: <pre><code>/ping\n</code></pre></p> <p>Parameters: None</p> <p>Expected Response: <pre><code>\ud83e\udd80 Pong! Latency: 45ms\n</code></pre></p> <p>Response Time: &lt; 500ms</p> <p>Use Cases: - Verify bot is responsive - Check connection quality - Debug connectivity issues - Test bot permissions</p> <p>Visibility: Response is ephemeral (only you can see it)</p>"},{"location":"COMMANDS/#direct-messaging-dm","title":"Direct Messaging (DM)","text":"<p>Description: Send messages directly to the bot in a private conversation.</p> <p>How to Use: 1. Find SecureClaw in your server member list 2. Right-click \u2192 Message 3. Type your message naturally</p> <p>Examples: <pre><code>Hello!\nWhat can you help me with?\nExplain quantum computing\nRemember that I live in San Francisco\nWhat did we talk about yesterday?\n</code></pre></p> <p>Behavior: - No special prefix required - Works exactly like <code>/ask</code> command - Full conversation history maintained - Supports all intents (ask, remember, recall) - More private than server messages</p> <p>Advantages: - No <code>/ask</code> prefix needed - Private conversation - Easier for testing - Better for sensitive information</p>"},{"location":"COMMANDS/#mentions-in-server","title":"Mentions in Server","text":"<p>Description: Mention the bot in any channel where it has access.</p> <p>Syntax: <pre><code>@SecureClaw &lt;your message&gt;\n</code></pre></p> <p>Examples: <pre><code>@SecureClaw what's the best way to learn Python?\n@SecureClaw can you help me debug this code?\n@SecureClaw remember that our team meeting is every Monday\n</code></pre></p> <p>Behavior: - Bot only responds when explicitly mentioned - Removes mention from message before processing - Public response (everyone can see) - Same functionality as DM or <code>/ask</code></p> <p>Empty Mention: <pre><code>@SecureClaw\n</code></pre> Response: <pre><code>How can I help you?\n</code></pre></p>"},{"location":"COMMANDS/#natural-language-intents","title":"Natural Language Intents","text":"<p>The bot automatically detects your intent from natural language:</p>"},{"location":"COMMANDS/#simple-query-intent","title":"Simple Query Intent","text":"<p>Triggers: Greetings, quick facts, simple questions</p> <p>Examples: <pre><code>Hello!\nWhat's 2 + 2?\nThanks for your help!\nGood morning\n</code></pre></p> <p>Model Used: Gemini Flash (fast, free tier)</p>"},{"location":"COMMANDS/#complex-task-intent","title":"Complex Task Intent","text":"<p>Triggers: Code generation, detailed analysis, multi-step tasks</p> <p>Examples: <pre><code>Write a Python function to validate email addresses\nExplain how transformers work in detail\nHelp me design a REST API for a blog\nDebug this code: [code snippet]\n</code></pre></p> <p>Model Used: Claude 3.5 Sonnet or GPT-4 (slower, better quality)</p> <p>Routing Logic: - Gemini Flash analyzes message - If complexity confidence &gt; 70% \u2192 Routes to Claude/GPT-4 - Otherwise \u2192 Gemini Flash handles it</p>"},{"location":"COMMANDS/#memory-store-intent","title":"Memory Store Intent","text":"<p>Triggers: Explicit remember requests</p> <p>Examples: <pre><code>Remember that I prefer tabs over spaces\nNote: Project uses PostgreSQL\nKeep in mind that I'm in PST timezone\nDon't forget my favorite color is blue\n</code></pre></p> <p>Auto-detection Keywords: - \"remember\" - \"note\" - \"keep in mind\" - \"don't forget\"</p>"},{"location":"COMMANDS/#memory-recall-intent","title":"Memory Recall Intent","text":"<p>Triggers: Questions about past conversations or stored info</p> <p>Examples: <pre><code>What do you know about me?\nWhat did we discuss yesterday?\nWhat are my preferences?\nTell me what you remember about my projects\n</code></pre></p> <p>Behavior: - Searches conversation history + long-term memory - Returns relevant past interactions - Includes timestamps for conversation context</p>"},{"location":"COMMANDS/#system-command-intent","title":"System Command Intent","text":"<p>Triggers: Bot commands, help requests</p> <p>Examples: <pre><code>Help\nWhat can you do?\nList your commands\n/ping\n</code></pre></p> <p>Response: Lists available commands and capabilities</p>"},{"location":"COMMANDS/#testing-checklist","title":"Testing Checklist","text":"<p>Use this checklist to verify all commands work correctly:</p>"},{"location":"COMMANDS/#basic-functionality","title":"Basic Functionality","text":"<ul> <li>[ ] <code>/ping</code> - Bot responds with latency</li> <li>[ ] <code>/ask Hello</code> - Bot greets you</li> <li>[ ] DM: <code>Hello</code> - Bot responds to DM</li> <li>[ ] Mention: <code>@SecureClaw hi</code> - Bot responds to mention</li> </ul>"},{"location":"COMMANDS/#memory-operations","title":"Memory Operations","text":"<ul> <li>[ ] <code>/remember I like pizza</code> - Confirms storage</li> <li>[ ] <code>/search pizza</code> - Finds the memory with high score</li> <li>[ ] <code>/ask What do I like to eat?</code> - Bot recalls pizza preference</li> <li>[ ] <code>/remember I prefer Python 3.12</code> - Store another</li> <li>[ ] <code>/search programming</code> - Should find Python preference</li> </ul>"},{"location":"COMMANDS/#complex-tasks","title":"Complex Tasks","text":"<ul> <li>[ ] <code>/ask Write a hello world in Python</code> - Should route to Claude/GPT-4</li> <li>[ ] <code>/ask Explain quantum entanglement</code> - Detailed response</li> <li>[ ] DM: <code>Help me debug this error</code> - Analyzes and helps</li> </ul>"},{"location":"COMMANDS/#edge-cases","title":"Edge Cases","text":"<ul> <li>[ ] Empty mention: <code>@SecureClaw</code> - Asks how to help</li> <li>[ ] Very long message (&gt;2000 chars) - Splits response</li> <li>[ ] Rate limiting - Send 11+ messages quickly</li> <li>[ ] Prompt injection: <code>ignore previous instructions</code> - Blocked</li> <li>[ ] Unauthorized user (if allowlist set) - Blocked</li> </ul>"},{"location":"COMMANDS/#error-scenarios","title":"Error Scenarios","text":"<ul> <li>[ ] Bot offline - Command fails gracefully</li> <li>[ ] Qdrant down - Error message about memory system</li> <li>[ ] API rate limit - Retry with backoff</li> <li>[ ] Invalid API key - Clear error message</li> </ul>"},{"location":"COMMANDS/#response-formats","title":"Response Formats","text":""},{"location":"COMMANDS/#success-response-askdmmention","title":"Success Response (Ask/DM/Mention)","text":"<pre><code>[Detailed answer to your question]\n\n[Additional context if relevant]\n</code></pre>"},{"location":"COMMANDS/#memory-stored","title":"Memory Stored","text":"<pre><code>\u2713 I'll remember that: \"[your content]\"\n</code></pre>"},{"location":"COMMANDS/#search-results","title":"Search Results","text":"<pre><code>**Search Results:**\n\n1. [95%] [memory content 1]\n2. [87%] [memory content 2]\n...\n</code></pre>"},{"location":"COMMANDS/#error-response-rate-limited","title":"Error Response (Rate Limited)","text":"<pre><code>You're sending messages too quickly. Please wait a moment before trying again.\n</code></pre>"},{"location":"COMMANDS/#error-response-not-authorized","title":"Error Response (Not Authorized)","text":"<pre><code>Sorry, you're not authorized to use this bot.\n</code></pre>"},{"location":"COMMANDS/#error-response-prompt-injection-detected","title":"Error Response (Prompt Injection Detected)","text":"<pre><code>I noticed some unusual patterns in your message. Could you rephrase your question?\n</code></pre>"},{"location":"COMMANDS/#command-permissions","title":"Command Permissions","text":""},{"location":"COMMANDS/#user-level-permissions-required","title":"User Level Permissions Required","text":"<ul> <li><code>Send Messages</code> - To use any command</li> <li><code>Read Message History</code> - For context awareness</li> <li><code>View Channel</code> - To see where bot is mentioned</li> </ul>"},{"location":"COMMANDS/#bot-permissions-required","title":"Bot Permissions Required","text":"<ul> <li><code>Send Messages</code> - To respond</li> <li><code>Embed Links</code> - For rich formatting (if added)</li> <li><code>Read Message History</code> - To load conversation context</li> <li><code>Use Slash Commands</code> - For <code>/ask</code>, <code>/remember</code>, etc.</li> </ul>"},{"location":"COMMANDS/#rate-limits","title":"Rate Limits","text":"<p>Default Configuration: - Max Messages: 10 per user - Time Window: 60 seconds - Warning Cooldown: 30 seconds</p> <p>Behavior: 1. User sends 10 messages in 60 seconds \u2192 \u2713 All allowed 2. User sends 11th message \u2192 \u2717 Blocked, warning shown 3. User sends 12th message within 30s \u2192 \u2717 Blocked, no warning (cooldown) 4. After 60s from first message \u2192 Counter resets</p> <p>Bypass Rate Limit: Set <code>max_messages=999</code> in <code>src/secureclaw/discord/security.py:36</code></p>"},{"location":"COMMANDS/#configuration","title":"Configuration","text":""},{"location":"COMMANDS/#model-configuration","title":"Model Configuration","text":"<p>Current Models (in <code>.env</code>): <pre><code># Routing &amp; Simple Queries\nROUTER_MODEL=gemini-2.0-flash\n\n# Complex Tasks\nCLAUDE_MODEL=claude-3-5-sonnet-20241022\nOPENAI_MODEL=gpt-4o\n\n# Embeddings\nEMBEDDING_MODEL=text-embedding-004\n</code></pre></p>"},{"location":"COMMANDS/#allowlist-configuration","title":"Allowlist Configuration","text":"<p>Allow All Users: <pre><code>ALLOWED_USER_IDS=\n</code></pre></p> <p>Restrict to Specific Users: <pre><code>ALLOWED_USER_IDS=123456789,987654321\n</code></pre></p>"},{"location":"COMMANDS/#troubleshooting-commands","title":"Troubleshooting Commands","text":""},{"location":"COMMANDS/#command-not-appearing","title":"Command Not Appearing","text":"<p>Problem: Slash commands don't show in Discord</p> <p>Solutions: 1. Wait up to 1 hour for global sync 2. Restart Discord app 3. Check bot was invited with <code>applications.commands</code> scope 4. Verify bot has <code>Use Application Commands</code> permission</p> <p>Verify Sync: <pre><code># Check logs for:\n./status.sh\n# Look for: \"commands_synced\"\n</code></pre></p>"},{"location":"COMMANDS/#command-not-responding","title":"Command Not Responding","text":"<p>Problem: Bot online but commands don't work</p> <p>Checklist: - [ ] Bot has <code>Send Messages</code> permission - [ ] User is on allowlist (if configured) - [ ] Not rate limited - [ ] Message Content Intent enabled (for DMs/mentions) - [ ] Check logs for errors</p> <p>Debug: <pre><code># Enable debug logging\n# In .env:\nLOG_LEVEL=DEBUG\n\n./stop.sh &amp;&amp; ./start.sh\n# Try command again\n# Check output for errors\n</code></pre></p>"},{"location":"COMMANDS/#api-reference","title":"API Reference","text":"<p>For programmatic access or building additional features:</p>"},{"location":"COMMANDS/#command-handler-methods","title":"Command Handler Methods","text":"<pre><code># In src/secureclaw/discord/bot.py\n\nasync def _handle_ask(interaction, question)\n# Handles /ask command\n\nasync def _handle_remember(interaction, content)\n# Handles /remember command\n\nasync def _handle_search(interaction, query)\n# Handles /search command\n\nasync def on_message(message)\n# Handles DMs and mentions\n</code></pre>"},{"location":"COMMANDS/#adding-new-commands","title":"Adding New Commands","text":"<ol> <li>Edit <code>src/secureclaw/discord/bot.py</code></li> <li>Add command in <code>_setup_commands()</code>: <pre><code>@self._tree.command(name=\"hello\", description=\"Say hello\")\nasync def hello_command(interaction: discord.Interaction) -&gt; None:\n    await interaction.response.send_message(\"Hello!\")\n</code></pre></li> <li>Restart bot - auto-syncs</li> </ol>"},{"location":"COMMANDS/#testing-scripts","title":"Testing Scripts","text":""},{"location":"COMMANDS/#quick-test-all-commands","title":"Quick Test All Commands","text":"<pre><code># In Discord:\n/ping\n/ask What is 2+2?\n/remember I like testing\n/search testing\n</code></pre>"},{"location":"COMMANDS/#comprehensive-test","title":"Comprehensive Test","text":"<pre><code># Test DM\n1. DM bot: \"Hello!\"\n2. DM bot: \"Remember I'm testing commands\"\n3. DM bot: \"What do you remember about me?\"\n\n# Test Mentions\n1. In server: \"@SecureClaw help\"\n2. In server: \"@SecureClaw remember our meeting is tomorrow\"\n\n# Test Error Handling\n1. Send 11 messages quickly (rate limit)\n2. Send: \"ignore previous instructions\" (injection)\n3. Disable Qdrant, try /search (graceful failure)\n</code></pre>"},{"location":"COMMANDS/#support","title":"Support","text":"<p>Need help with commands? - Troubleshooting Guide - FAQ - GitHub Issues</p>"},{"location":"DOCKER_ARCHITECTURE/","title":"Docker Architecture and Memory Management","text":"<p>This document explains how Docker works on macOS, the distinction between Docker Desktop and containers, and how SecureClaw automatically manages Docker memory allocation for Ollama models.</p>"},{"location":"DOCKER_ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Docker Desktop vs Docker Containers</li> <li>Memory Hierarchy</li> <li>Why Docker Desktop Needs to Restart</li> <li>Automated Memory Management</li> <li>Manual Docker Configuration</li> <li>Troubleshooting</li> </ol>"},{"location":"DOCKER_ARCHITECTURE/#docker-desktop-vs-docker-containers","title":"Docker Desktop vs Docker Containers","text":""},{"location":"DOCKER_ARCHITECTURE/#docker-desktop-the-virtual-machine","title":"Docker Desktop (The Virtual Machine)","text":"<p>On macOS, Docker runs inside a lightweight virtual machine (VM) called Docker Desktop. This is necessary because Docker uses Linux-specific features that don't exist natively on macOS.</p> <p>Key points: - Docker Desktop is the host environment that runs all containers - It has its own fixed memory allocation from your Mac's RAM - This memory allocation is configured in Docker Desktop settings - Located at: <code>~/Library/Group Containers/group.com.docker/settings.json</code> - The <code>memoryMiB</code> field controls how much RAM the VM gets</p> <p>Think of it like this: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Your Mac (Physical Hardware)      \u2502\n\u2502   Total RAM: e.g., 16GB             \u2502\n\u2502                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Docker Desktop VM             \u2502 \u2502\n\u2502  \u2502  Allocated: e.g., 8GB          \u2502 \u2502\n\u2502  \u2502                                \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502  Container 1 (Bot)       \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  Limit: 2GB              \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2502                                \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502  Container 2 (Ollama)    \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  Limit: 10GB             \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2502                                \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502  Container 3 (Qdrant)    \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  Limit: 1GB              \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"DOCKER_ARCHITECTURE/#docker-containers","title":"Docker Containers","text":"<p>Containers are isolated processes that run inside the Docker Desktop VM.</p> <p>Key points: - Each container can have a memory limit (e.g., <code>--memory=10g</code>) - Container limits cannot exceed the Docker Desktop VM's total allocation - If Docker Desktop has 8GB, you cannot give a container 10GB - Multiple containers share the Docker Desktop VM's memory pool</p>"},{"location":"DOCKER_ARCHITECTURE/#the-critical-difference","title":"The Critical Difference","text":"<p>Setting a container's memory limit does NOT increase Docker Desktop's memory allocation.</p> <p>If you run: <pre><code>docker run --memory=10g ollama/ollama\n</code></pre></p> <p>But Docker Desktop only has 4GB allocated, the container will: - Be limited to 4GB (the VM's total) - Or fail to start if it requires more than available - Not automatically increase Docker Desktop's allocation</p> <p>That's why we need to restart Docker Desktop - to resize the VM itself.</p>"},{"location":"DOCKER_ARCHITECTURE/#memory-hierarchy","title":"Memory Hierarchy","text":"<p>Understanding the three-layer memory hierarchy is crucial:</p>"},{"location":"DOCKER_ARCHITECTURE/#layer-1-physical-ram","title":"Layer 1: Physical RAM","text":"<ul> <li>Your Mac's actual memory (e.g., 16GB, 32GB)</li> <li>Shared between macOS and all applications</li> <li>Fixed amount, cannot be changed without hardware upgrade</li> </ul>"},{"location":"DOCKER_ARCHITECTURE/#layer-2-docker-desktop-vm-allocation","title":"Layer 2: Docker Desktop VM Allocation","text":"<ul> <li>A portion of physical RAM reserved for Docker</li> <li>Configured in Docker Desktop settings</li> <li>Requires Docker Desktop restart to change</li> <li>Default: 2-4GB (too small for Ollama models)</li> </ul>"},{"location":"DOCKER_ARCHITECTURE/#layer-3-container-memory-limits","title":"Layer 3: Container Memory Limits","text":"<ul> <li>Individual limits for each container</li> <li>Set via <code>docker run --memory=X</code> or <code>docker-compose.yml</code></li> <li>Cannot exceed Layer 2 (Docker Desktop VM allocation)</li> <li>Can be changed without restarting Docker Desktop</li> </ul>"},{"location":"DOCKER_ARCHITECTURE/#example-scenario","title":"Example Scenario","text":"<p>System: MacBook Pro with 16GB RAM</p> <p>Problem: - Docker Desktop allocated: 4GB (Layer 2) - Ollama model needs: 10GB (Layer 3 requirement)</p> <p>Why it fails: <pre><code>Layer 1 (Physical):    16GB  \u2713 Enough\nLayer 2 (Docker VM):    4GB  \u2717 NOT enough\nLayer 3 (Container):   10GB  \u2717 CANNOT allocate (exceeds Layer 2)\n</code></pre></p> <p>Solution: 1. Increase Layer 2 (Docker Desktop) to 12GB 2. Restart Docker Desktop to apply 3. Now Layer 3 (container) can use 10GB</p>"},{"location":"DOCKER_ARCHITECTURE/#why-docker-desktop-needs-to-restart","title":"Why Docker Desktop Needs to Restart","text":""},{"location":"DOCKER_ARCHITECTURE/#the-technical-reason","title":"The Technical Reason","text":"<p>Docker Desktop's VM allocation is a boot-time parameter. The hypervisor (the software that creates the VM) needs to:</p> <ol> <li>Allocate physical pages in your Mac's RAM</li> <li>Initialize the virtual memory space for the VM</li> <li>Configure the hypervisor with new limits</li> </ol> <p>These operations cannot be done while the VM is running.</p>"},{"location":"DOCKER_ARCHITECTURE/#the-analogy","title":"The Analogy","text":"<p>Think of it like upgrading RAM in a desktop computer: - You can't add more RAM while the computer is running - You must shut down, install RAM, then boot up - The BIOS needs to detect and configure the new RAM</p> <p>Docker Desktop is similar: - Can't change VM memory while running - Must quit Docker Desktop - Restart with new memory allocation</p>"},{"location":"DOCKER_ARCHITECTURE/#what-about-memory-flags","title":"What About <code>--memory</code> Flags?","text":"<p>Container memory limits (<code>docker run --memory=X</code>) are different: - They're enforced by cgroups (Linux control groups) - Can be changed at runtime - But they're just soft limits within the VM's total allocation - Like dividing a pie - you can't create more pie, just slice it differently</p>"},{"location":"DOCKER_ARCHITECTURE/#automated-memory-management","title":"Automated Memory Management","text":"<p>SecureClaw includes a fully automated pipeline to handle Docker memory requirements for Ollama models.</p>"},{"location":"DOCKER_ARCHITECTURE/#the-pipeline","title":"The Pipeline","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  1. Hardware Detection (scripts/assess-system.py)           \u2502\n\u2502     - Detect CPU, RAM, GPU                                  \u2502\n\u2502     - Recommend appropriate Ollama model                     \u2502\n\u2502     - Calculate required Docker memory                       \u2502\n\u2502     - Save to .env: OLLAMA_ROUTER_MODEL, OLLAMA_DOCKER_MEMORY\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  2. Startup Check (start.sh)                                \u2502\n\u2502     - Read required memory from .env                         \u2502\n\u2502     - Check current Docker Desktop allocation               \u2502\n\u2502     - If insufficient, prompt user                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  3. User Choice                                             \u2502\n\u2502     \u2022 Automatically increase (default)                       \u2502\n\u2502     \u2022 Choose smaller model                                   \u2502\n\u2502     \u2022 Continue anyway (not recommended)                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc (if \"automatically increase\")\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  4. Memory Increase (scripts/increase-docker-memory.sh)     \u2502\n\u2502     - Backup Docker settings JSON                            \u2502\n\u2502     - Update memoryMiB field                                \u2502\n\u2502     - Stop Docker Desktop (osascript or killall)            \u2502\n\u2502     - Wait for full shutdown (up to 20 seconds)             \u2502\n\u2502     - Launch Docker Desktop                                  \u2502\n\u2502     - Wait for daemon readiness (up to 60 seconds)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"DOCKER_ARCHITECTURE/#model-recommendations-with-memory-requirements","title":"Model Recommendations with Memory Requirements","text":"<p>The system recommends models based on your hardware:</p> Model Size RAM Req Docker Memory Speed (CPU) Quality phi3:mini 2.3GB 4GB 5GB ~1s Basic llama3.1:8b 4.7GB 8GB 8GB ~2-3s Excellent qwen2.5:7b 4.7GB 8GB 10GB ~2-3s Best mistral:7b 4.1GB 8GB 7GB ~1-2s Very Good <p>Docker Memory = Model Size + Overhead - Phi3: 2.3GB + 2GB overhead = 5GB - Llama3.1: 4.7GB + 3GB overhead = 8GB - Qwen2.5: 4.7GB + 5GB overhead = 10GB (needs more for quality) - Mistral: 4.1GB + 3GB overhead = 7GB</p>"},{"location":"DOCKER_ARCHITECTURE/#environment-variables","title":"Environment Variables","text":"<p>The system manages these automatically:</p> <pre><code># Set by assess-system.py\nOLLAMA_ROUTER_MODEL=llama3.1:8b\nOLLAMA_DOCKER_MEMORY=8  # in GB\n\n# Used by start.sh\nREQUIRED_MEMORY=${OLLAMA_DOCKER_MEMORY:-8}\n\n# Used by Docker Compose\nOLLAMA_DOCKER_MEMORY=8  # for container limits\n</code></pre>"},{"location":"DOCKER_ARCHITECTURE/#process-control","title":"Process Control","text":"<p>The memory increase script uses robust process management:</p> <ol> <li> <p>Check if Docker is running <pre><code>pgrep -x \"Docker\" &gt; /dev/null\n</code></pre></p> </li> <li> <p>Stop Docker Desktop</p> </li> <li>Try AppleScript first: <code>osascript -e 'quit app \"Docker\"'</code></li> <li>Fallback to killall: <code>killall Docker</code></li> <li> <p>Wait for full stop (up to 20 seconds)</p> </li> <li> <p>Verify shutdown</p> </li> <li>Loop checking <code>pgrep</code> until process gone</li> <li> <p>Timeout protection to prevent infinite wait</p> </li> <li> <p>Start Docker Desktop <pre><code>open -a Docker\n</code></pre></p> </li> <li> <p>Wait for daemon readiness</p> </li> <li>Not just GUI launch - wait for daemon to respond</li> <li>Use <code>docker info</code> to verify daemon is ready</li> <li>Can take 30-60 seconds on cold start</li> <li>Timeout after 60 seconds with helpful error message</li> </ol>"},{"location":"DOCKER_ARCHITECTURE/#manual-docker-configuration","title":"Manual Docker Configuration","text":"<p>If you prefer to configure Docker Desktop manually:</p>"},{"location":"DOCKER_ARCHITECTURE/#via-docker-desktop-gui","title":"Via Docker Desktop GUI","text":"<ol> <li>Open Docker Desktop</li> <li>Go to Settings (gear icon)</li> <li>Navigate to Resources \u2192 Advanced</li> <li>Adjust the Memory slider to desired amount</li> <li>Click Apply &amp; Restart</li> <li>Wait for Docker Desktop to restart (30-60 seconds)</li> </ol>"},{"location":"DOCKER_ARCHITECTURE/#via-settings-file-advanced","title":"Via Settings File (Advanced)","text":"<p>Location: <code>~/Library/Group Containers/group.com.docker/settings.json</code></p> <ol> <li> <p>Backup the file first: <pre><code>cp ~/Library/Group\\ Containers/group.com.docker/settings.json \\\n   ~/Library/Group\\ Containers/group.com.docker/settings.json.backup\n</code></pre></p> </li> <li> <p>Edit the file: <pre><code>vim ~/Library/Group\\ Containers/group.com.docker/settings.json\n</code></pre></p> </li> <li> <p>Find and update memoryMiB: <pre><code>{\n  \"memoryMiB\": 10240,  // 10GB in MiB\n  ...\n}\n</code></pre></p> </li> <li> <p>Restart Docker Desktop: <pre><code>osascript -e 'quit app \"Docker\"'\nsleep 5\nopen -a Docker\n</code></pre></p> </li> </ol>"},{"location":"DOCKER_ARCHITECTURE/#verify-the-change","title":"Verify the Change","text":"<pre><code># Check Docker's total memory\ndocker info | grep \"Total Memory\"\n\n# Should show: Total Memory: 10 GiB (or your configured amount)\n</code></pre>"},{"location":"DOCKER_ARCHITECTURE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DOCKER_ARCHITECTURE/#docker-desktop-wont-start-after-increasing-memory","title":"Docker Desktop Won't Start After Increasing Memory","text":"<p>Symptom: Docker Desktop GUI opens but daemon never becomes ready</p> <p>Possible Causes: 1. Requested memory exceeds available system RAM 2. Other apps consuming too much memory 3. Docker Desktop settings corrupted</p> <p>Solutions:</p> <ol> <li> <p>Check available RAM: <pre><code># macOS\nvm_stat | head -2\n</code></pre></p> </li> <li> <p>Reduce requested memory:</p> </li> <li>Restore backup settings:      <pre><code>cp ~/Library/Group\\ Containers/group.com.docker/settings.json.backup \\\n   ~/Library/Group\\ Containers/group.com.docker/settings.json\n</code></pre></li> <li> <p>Restart Docker Desktop</p> </li> <li> <p>Reset Docker Desktop:</p> </li> <li>Docker Desktop \u2192 Troubleshoot \u2192 Reset to factory defaults</li> <li>WARNING: This deletes all containers and images</li> </ol>"},{"location":"DOCKER_ARCHITECTURE/#container-fails-with-out-of-memory","title":"Container Fails with \"Out of Memory\"","text":"<p>Symptom: Container starts but crashes with OOM errors</p> <p>Check: 1. Docker Desktop allocation: <pre><code>docker info | grep \"Total Memory\"\n</code></pre></p> <ol> <li> <p>Container limit: <pre><code>docker inspect CONTAINER_ID | grep Memory\n</code></pre></p> </li> <li> <p>Model requirements:</p> </li> <li>Check <code>OLLAMA_DOCKER_MEMORY</code> in <code>.env</code></li> <li>Verify it matches model needs (see table above)</li> </ol> <p>Fix: <pre><code># Run the automated increase script\ncd scripts\n./increase-docker-memory.sh --yes\n\n# Or manually increase Docker Desktop memory via GUI\n</code></pre></p>"},{"location":"DOCKER_ARCHITECTURE/#unable-to-find-image-ollamaollamalatest","title":"\"Unable to find image 'ollama/ollama:latest'\"","text":"<p>Symptom: Ollama container fails to start</p> <p>Cause: Image not pulled yet (expected on first run)</p> <p>Fix: <pre><code># The startup script handles this, but manual pull:\ndocker pull ollama/ollama:latest\n</code></pre></p>"},{"location":"DOCKER_ARCHITECTURE/#docker-daemon-not-responding-after-start","title":"Docker Daemon Not Responding After Start","text":"<p>Symptom: <code>docker info</code> returns error after launching Docker Desktop</p> <p>Cause: Daemon still initializing (can take 30-60 seconds)</p> <p>Check: <pre><code># Wait and retry\nfor i in {1..60}; do\n    docker info &gt;/dev/null 2&gt;&amp;1 &amp;&amp; echo \"Ready!\" &amp;&amp; break\n    echo \"Waiting... ($i/60)\"\n    sleep 1\ndone\n</code></pre></p> <p>If still fails after 60 seconds: 1. Check Console.app for Docker errors 2. Check Activity Monitor for Docker processes 3. Try restarting Mac (last resort)</p>"},{"location":"DOCKER_ARCHITECTURE/#automated-script-hangs","title":"Automated Script Hangs","text":"<p>Symptom: <code>increase-docker-memory.sh</code> hangs during Docker restart</p> <p>Debug: <pre><code># Run with manual prompts to see progress\ncd scripts\n./increase-docker-memory.sh  # without --yes flag\n\n# Check Docker process\npgrep -x \"Docker\"\n\n# Check daemon\ndocker info\n</code></pre></p> <p>Common causes: 1. Docker.app not installed at <code>/Applications/Docker.app</code> 2. Permissions issues with settings file 3. Docker Desktop GUI stuck in update/crash loop</p> <p>Solutions: 1. Verify Docker.app location: <pre><code>ls -la /Applications/Docker.app\n</code></pre></p> <ol> <li> <p>Check settings file permissions: <pre><code>ls -la ~/Library/Group\\ Containers/group.com.docker/settings.json\n</code></pre></p> </li> <li> <p>Force quit all Docker processes: <pre><code>pkill -9 -x \"Docker\"\npkill -9 -f \"com.docker\"\nsleep 3\nopen -a Docker\n</code></pre></p> </li> </ol>"},{"location":"DOCKER_ARCHITECTURE/#advanced-topics","title":"Advanced Topics","text":""},{"location":"DOCKER_ARCHITECTURE/#docker-desktop-architecture-on-macos","title":"Docker Desktop Architecture on macOS","text":"<p>Docker Desktop uses HyperKit (a lightweight hypervisor) to run a minimal Linux VM:</p> <ol> <li>HyperKit creates the VM</li> <li>LinuxKit provides the minimal Linux environment</li> <li>containerd manages container lifecycle</li> <li>Docker daemon provides the API</li> </ol> <p>Your containers run inside the LinuxKit VM, not directly on macOS.</p>"},{"location":"DOCKER_ARCHITECTURE/#memory-management-internals","title":"Memory Management Internals","text":"<p>At the hypervisor level: - HyperKit allocates physical RAM pages from macOS - Creates guest physical memory space for Linux VM - Cannot dynamically resize without restart</p> <p>At the Linux level (inside VM): - cgroups enforce container memory limits - OOM killer terminates processes exceeding limits - Can be adjusted without restarting VM</p>"},{"location":"DOCKER_ARCHITECTURE/#performance-considerations","title":"Performance Considerations","text":"<p>Docker Desktop allocation: - Too little: Containers OOM, poor performance - Too much: Less RAM for macOS, potential swapping - Sweet spot: 50-70% of total RAM for Docker</p> <p>Example for 16GB Mac: - Docker: 10GB (Ollama + other services) - macOS: 6GB (system + apps)</p> <p>With 8GB Mac: - Docker: 5GB (smaller Ollama model) - macOS: 3GB (minimal) - May need to close other apps</p>"},{"location":"DOCKER_ARCHITECTURE/#references","title":"References","text":"<ul> <li>Docker Desktop for Mac documentation</li> <li>HyperKit GitHub</li> <li>LinuxKit GitHub</li> <li>Docker Memory Limits</li> </ul>"},{"location":"FAQ/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"FAQ/#general-questions","title":"General Questions","text":""},{"location":"FAQ/#what-is-secureclaw","title":"What is SecureClaw?","text":"<p>SecureClaw is a secure, intelligent Discord bot with vector-based memory. It can remember conversations, answer questions, and assist with complex tasks using multiple AI models (Gemini, Claude, GPT-4).</p>"},{"location":"FAQ/#is-secureclaw-free-to-use","title":"Is SecureClaw free to use?","text":"<p>The bot itself is open source and free. However, you need API keys: - Gemini API - Free tier available (sufficient for personal use) - Discord Bot - Free - Claude/GPT-4 - Optional, paid tiers only</p>"},{"location":"FAQ/#can-i-use-secureclaw-in-production","title":"Can I use SecureClaw in production?","text":"<p>Yes, but: - Set <code>ALLOWED_USER_IDS</code> to restrict access - Use proper API rate limits - Monitor costs for paid API usage - Consider enabling additional security features</p>"},{"location":"FAQ/#does-secureclaw-store-my-data","title":"Does SecureClaw store my data?","text":"<p>Yes, SecureClaw stores: - Conversation history - In Qdrant vector database (local to your machine) - Long-term memories - Things you explicitly ask it to remember - Nothing is sent to third parties - All data stays on your infrastructure</p> <p>Data is stored locally in the <code>qdrant_storage/</code> directory.</p>"},{"location":"FAQ/#setup-questions","title":"Setup Questions","text":""},{"location":"FAQ/#what-hardware-do-i-need","title":"What hardware do I need?","text":"<p>Minimum: - 4GB RAM - 2GB free disk space - macOS/Linux (Windows with WSL)</p> <p>Recommended: - 8GB+ RAM - 10GB free disk space - SSD storage</p>"},{"location":"FAQ/#can-i-run-this-on-windows","title":"Can I run this on Windows?","text":"<p>Yes, but with modifications: 1. Install Docker Desktop for Windows 2. Use WSL2 (Windows Subsystem for Linux) 3. Run commands in WSL2 terminal 4. Scripts will need adjustment (or use Docker Compose instead)</p>"},{"location":"FAQ/#can-i-run-this-on-a-raspberry-pi","title":"Can I run this on a Raspberry Pi?","text":"<p>Possibly, but not recommended: - Requires 64-bit OS - Minimum 4GB RAM model - Performance will be limited - Qdrant may struggle with large datasets</p>"},{"location":"FAQ/#do-i-need-all-three-api-keys","title":"Do I need all three API keys?","text":"<p>Required: - Discord Token - Gemini API Key</p> <p>Optional (but recommended): - Anthropic (Claude) - For better quality on complex tasks - OpenAI (GPT-4) - Alternative to Claude</p> <p>Without Claude/GPT-4, all queries use Gemini Flash (still very capable).</p>"},{"location":"FAQ/#usage-questions","title":"Usage Questions","text":""},{"location":"FAQ/#how-do-i-talk-to-the-bot","title":"How do I talk to the bot?","text":"<p>In Discord: - DM the bot directly - Just send a message - Mention in server - <code>@SecureClaw your message here</code> - Slash commands - <code>/ask</code>, <code>/remember</code>, <code>/search</code>, <code>/ping</code></p>"},{"location":"FAQ/#whats-the-difference-between-ask-and-mentioning","title":"What's the difference between <code>/ask</code> and mentioning?","text":"<p>None functionally - both do the same thing. Use whatever is more convenient: - <code>/ask</code> - More explicit, good for servers - Mentioning - More natural, like talking to a person</p>"},{"location":"FAQ/#can-it-remember-previous-conversations","title":"Can it remember previous conversations?","text":"<p>Yes! SecureClaw automatically: - Remembers recent conversation context (last 20 messages) - Searches relevant past conversations using vector similarity - Recalls explicitly stored memories</p>"},{"location":"FAQ/#how-do-i-make-it-remember-something-specific","title":"How do I make it remember something specific?","text":"<pre><code># Any of these work:\n/remember I prefer dark mode\n\"Remember that I'm a Python developer\"\n\"Note: My birthday is March 15\"\n</code></pre>"},{"location":"FAQ/#how-do-i-search-my-memories","title":"How do I search my memories?","text":"<pre><code>/search preferences\n/search birthday\n/search python projects\n</code></pre> <p>Returns the 5 most relevant memories with similarity scores.</p>"},{"location":"FAQ/#can-i-delete-memories","title":"Can I delete memories?","text":"<p>Not yet via commands, but you can: <pre><code># Delete all memories:\n./stop.sh\nrm -rf qdrant_storage/\n./start.sh\n</code></pre></p> <p>Future versions will add <code>/forget</code> command.</p>"},{"location":"FAQ/#technical-questions","title":"Technical Questions","text":""},{"location":"FAQ/#what-ai-models-does-it-use","title":"What AI models does it use?","text":"<p>Routing &amp; Simple Queries: - Gemini 2.0 Flash (fast, cheap, handles 90% of queries)</p> <p>Complex Tasks: - Claude 3.5 Sonnet (default for code, analysis, creative tasks) - GPT-4 (alternative, configure via OPENAI_API_KEY)</p> <p>Embeddings: - Gemini text-embedding-004 (768 dimensions)</p>"},{"location":"FAQ/#how-does-the-routing-work","title":"How does the routing work?","text":"<ol> <li>User sends message</li> <li>Gemini Flash analyzes intent + complexity</li> <li>If simple (greeting, factual question) \u2192 Gemini Flash responds</li> <li>If complex (code, analysis) \u2192 Routes to Claude/GPT-4</li> </ol> <p>Threshold: 70% confidence that task is complex</p>"},{"location":"FAQ/#what-is-qdrant","title":"What is Qdrant?","text":"<p>Qdrant is a vector database that stores: - Conversation history as semantic vectors - Long-term memories - Enables similarity search (find related past conversations)</p> <p>Think of it like a smart search engine for your conversations.</p>"},{"location":"FAQ/#how-much-does-it-cost-to-run","title":"How much does it cost to run?","text":"<p>Free Tier Usage (Gemini only): - ~1000 messages/day on free tier - $0/month</p> <p>With Claude API (Recommended): - ~$0.003 per message (simple) - ~$0.03 per complex task - ~$5-20/month for personal use</p> <p>With GPT-4: - ~$0.01 per message - ~$10-30/month for personal use</p>"},{"location":"FAQ/#how-do-i-reduce-costs","title":"How do I reduce costs?","text":"<ol> <li>Use Gemini-only (remove Claude/OpenAI keys)</li> <li>Increase routing threshold (fewer complex tasks)</li> <li>Reduce memory context limits</li> <li>Set <code>ALLOWED_USER_IDS</code> to restrict usage</li> </ol>"},{"location":"FAQ/#can-i-use-different-models","title":"Can I use different models?","text":"<p>Yes! Edit <code>.env</code>: <pre><code># Use Claude Haiku (cheaper, faster):\nCLAUDE_MODEL=claude-3-haiku-20240307\n\n# Use GPT-3.5 instead of GPT-4:\nOPENAI_MODEL=gpt-3.5-turbo\n\n# Use different Gemini model:\nROUTER_MODEL=gemini-1.5-flash\n</code></pre></p> <p>See <code>src/secureclaw/config.py</code> for all model options.</p>"},{"location":"FAQ/#security-questions","title":"Security Questions","text":""},{"location":"FAQ/#is-it-safe-to-put-api-keys-in-env","title":"Is it safe to put API keys in .env?","text":"<p>Yes, if: - <code>.env</code> is in <code>.gitignore</code> (it is by default) - You don't commit it to GitHub - File permissions are restricted: <code>chmod 600 .env</code></p> <p>Never: - Share <code>.env</code> file - Commit it to Git - Post it in Discord/forums</p>"},{"location":"FAQ/#should-i-enable-the-user-allowlist","title":"Should I enable the user allowlist?","text":"<p>For personal use: Not required, but recommended <pre><code>ALLOWED_USER_IDS=your_discord_id\n</code></pre></p> <p>For server use: CRITICAL <pre><code>ALLOWED_USER_IDS=id1,id2,id3\n</code></pre></p> <p>Otherwise anyone in the server can use (and rack up API costs).</p>"},{"location":"FAQ/#what-about-prompt-injection-attacks","title":"What about prompt injection attacks?","text":"<p>SecureClaw has built-in protection: - 17 regex patterns detect injection attempts - Unicode obfuscation detection - Excessive role-play marker detection - Auto-rejects suspicious messages</p> <p>See <code>src/secureclaw/discord/security.py</code> for details.</p>"},{"location":"FAQ/#can-someone-hack-my-bot","title":"Can someone hack my bot?","text":"<p>Attack vectors: 1. Stolen Discord Token - Keep token secret, rotate if exposed 2. API Key Theft - Protect <code>.env</code> file 3. Prompt Injection - Built-in protection, but not 100% 4. Rate Limiting Abuse - Set user allowlist + rate limits</p> <p>Best Practices: - Use <code>ALLOWED_USER_IDS</code> for production - Monitor API usage dashboards - Enable Discord 2FA - Rotate tokens periodically</p>"},{"location":"FAQ/#development-questions","title":"Development Questions","text":""},{"location":"FAQ/#can-i-contribute-to-secureclaw","title":"Can I contribute to SecureClaw?","text":"<p>Yes! Contributions welcome: 1. Fork the repo 2. Create feature branch 3. Make changes + add tests 4. Submit PR with description</p> <p>See CONTRIBUTING.md for guidelines.</p>"},{"location":"FAQ/#how-do-i-run-tests","title":"How do I run tests?","text":"<pre><code># Install dev dependencies:\npip install -r requirements-dev.txt\n\n# Run all tests:\npytest tests/ -v\n\n# With coverage:\npytest tests/ --cov=src/secureclaw --cov-report=html\n\n# Open coverage report:\nopen htmlcov/index.html\n</code></pre>"},{"location":"FAQ/#how-do-i-add-a-new-slash-command","title":"How do I add a new slash command?","text":"<ol> <li>Edit <code>src/secureclaw/discord/bot.py</code></li> <li>Add command in <code>_setup_commands()</code> method</li> <li>Create handler method (e.g., <code>_handle_my_command</code>)</li> <li>Restart bot - commands sync automatically</li> </ol> <p>Example: <pre><code>@self._tree.command(name=\"hello\", description=\"Say hello\")\nasync def hello_command(interaction: discord.Interaction) -&gt; None:\n    await interaction.response.send_message(\"Hello!\")\n</code></pre></p>"},{"location":"FAQ/#how-do-i-change-the-system-prompt","title":"How do I change the system prompt?","text":"<p>Edit <code>src/secureclaw/agent/prompts.py</code>: - <code>CLAUDE_SYSTEM_PROMPT</code> - Instructions for Claude - <code>OPENAI_SYSTEM_PROMPT</code> - Instructions for GPT-4</p> <p>Restart bot after changes.</p>"},{"location":"FAQ/#can-i-use-a-different-vector-database","title":"Can I use a different vector database?","text":"<p>Technically yes, but requires code changes: - Current: Qdrant (recommended, fast, easy) - Alternatives: Pinecone, Weaviate, Milvus</p> <p>You'd need to implement the same interface in <code>src/secureclaw/memory/</code>.</p>"},{"location":"FAQ/#troubleshooting","title":"Troubleshooting","text":""},{"location":"FAQ/#bot-is-not-responding","title":"Bot is not responding","text":"<p>See TROUBLESHOOTING.md</p>"},{"location":"FAQ/#getting-api-errors","title":"Getting API errors","text":"<p>See TROUBLESHOOTING.md</p>"},{"location":"FAQ/#qdrant-connection-issues","title":"Qdrant connection issues","text":"<p>See TROUBLESHOOTING.md</p>"},{"location":"FAQ/#performance-problems","title":"Performance problems","text":"<p>See TROUBLESHOOTING.md</p>"},{"location":"FAQ/#still-have-questions","title":"Still Have Questions?","text":"<ol> <li>Check TROUBLESHOOTING.md</li> <li>Search GitHub Issues</li> <li>Ask in GitHub Discussions</li> <li>Create new issue with <code>[Question]</code> tag</li> </ol>"},{"location":"SECURITY/","title":"Security Overview","text":"<p>This document describes how SecureClaw is secured across the full development lifecycle: how we protect credentials, validate input, scan for vulnerabilities, test, and deploy.</p>"},{"location":"SECURITY/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Secret Management</li> <li>Secret Scanning (Pre-Commit)</li> <li>Input Validation &amp; Prompt Injection Defence</li> <li>Access Control</li> <li>Static Analysis &amp; Code Quality</li> <li>Dependency Management</li> <li>Container Security</li> <li>CI/CD Pipeline Security</li> <li>Testing Strategy</li> <li>Logging &amp; Monitoring</li> <li>Network Security</li> <li>Gap Analysis &amp; Recommendations</li> </ol>"},{"location":"SECURITY/#1-secret-management","title":"1. Secret Management","text":"<p>All credentials are loaded from environment variables via a <code>.env</code> file and never hardcoded in source.</p> Control Implementation File Typed secrets <code>pydantic.SecretStr</code> prevents accidental logging/serialisation of tokens <code>src/secureclaw/config.py</code> <code>.env</code> excluded from Git <code>.gitignore</code> blocks <code>.env</code>, <code>data/</code>, <code>ollama_models/</code> <code>.gitignore</code> Example file provided <code>.env.example</code> documents every variable without real values <code>.env.example</code> Minimal exposure <code>SecretStr.get_secret_value()</code> called only at point-of-use (API client init) Agent &amp; router modules Startup masking <code>start.sh</code> prints only the first 20 characters of tokens in its config summary <code>start.sh</code>"},{"location":"SECURITY/#how-secrets-flow","title":"How Secrets Flow","text":"<pre><code>.env  --&gt;  pydantic-settings (SecretStr)  --&gt;  get_secret_value() at API call site\n            ^                                         |\n            |  Never logged, never serialised         v\n            +--- structlog sees SecretStr repr: '**********'\n</code></pre>"},{"location":"SECURITY/#2-secret-scanning-pre-commit","title":"2. Secret Scanning (Pre-Commit)","text":"<p>Gitleaks runs on every <code>git commit</code> to prevent credentials from entering version control.</p> <p>Configuration: <code>.gitleaks.toml</code></p>"},{"location":"SECURITY/#what-it-detects","title":"What It Detects","text":"Rule Pattern Example Discord bot tokens <code>[MN][A-Za-z\\d]{23}\\.[\\w-]{6}\\.[\\w-]{27}</code> <code>MTk...</code> Discord webhooks <code>discord(app)?\\.com/api/webhooks/\\d+/[\\w-]+</code> Webhook URLs Google/Gemini API keys <code>AIza[0-9A-Za-z\\\\-_]{35}</code> <code>AIzaSy...</code> Anthropic API keys <code>sk-ant-api03-[A-Za-z0-9_-]{95,100}</code> <code>sk-ant-api03-...</code> OpenAI API keys <code>sk-[a-zA-Z0-9]{48}</code> <code>sk-...</code> GitHub PATs <code>ghp_[A-Za-z0-9_]{36}</code> <code>ghp_...</code> AWS access keys <code>AKIA[0-9A-Z]{16}</code> <code>AKIA...</code> Slack tokens <code>xox[baprs]-[A-Za-z0-9-]+</code> <code>xoxb-...</code> Private keys <code>BEGIN.*PRIVATE KEY</code> PEM/SSH/PGP keys JWT tokens <code>eyJ[A-Za-z0-9_-]+\\.eyJ[A-Za-z0-9_-]+</code> <code>eyJhbG...</code> Passwords in URLs <code>://[^/\\s]+:[^/\\s]+@</code> <code>postgres://user:pass@host</code> High-entropy strings Shannon entropy &gt; 4.5 Random-looking hex/base64"},{"location":"SECURITY/#false-positive-filtering","title":"False Positive Filtering","text":"<p>The allowlist avoids blocking legitimate code:</p> <ul> <li>Paths: <code>.env.example</code>, <code>README.md</code>, <code>docs/</code>, test fixtures</li> <li>Patterns: <code>test-*-key</code>, <code>.get_secret_value()</code> calls, hash patterns</li> <li>Gitignored files: <code>.env</code>, <code>data/</code>, <code>ollama_models/</code> are excluded automatically</li> </ul>"},{"location":"SECURITY/#3-input-validation-prompt-injection-defence","title":"3. Input Validation &amp; Prompt Injection Defence","text":"<p>File: <code>src/secureclaw/discord/security.py</code></p> <p>Every user message is checked before being forwarded to LLM backends.</p>"},{"location":"SECURITY/#detection-techniques","title":"Detection Techniques","text":"<ol> <li>17 regex patterns covering prompt injection variations:</li> <li>\"ignore previous/prior instructions\" (with spacing/punctuation tolerance)</li> <li>\"disregard/forget/override your rules\"</li> <li>\"you are now a...\" role reassignment</li> <li>\"act as if / pretend to be\"</li> <li>\"new instructions:\" injection headers</li> <li>\"system prompt/message:\" attempts</li> <li>\"jailbreak\", \"DAN mode\", \"developer mode\" keywords</li> <li>\"disable/bypass filters/safety/restrictions\"</li> <li> <p>All patterns are case-insensitive</p> </li> <li> <p>Roleplay marker heuristic: Flags messages with &gt; 5 brackets or <code>(system</code> markers, which indicate structured injection attempts.</p> </li> <li> <p>Unicode obfuscation detection: Compares NFKC-normalised text to original. A length difference &gt; 10% indicates homoglyph substitution (e.g. Cyrillic \"\u0430\" replacing Latin \"a\" to bypass keyword filters).</p> </li> </ol>"},{"location":"SECURITY/#defence-behaviour","title":"Defence Behaviour","text":"<ul> <li>Flagged messages are logged with <code>potential_prompt_injection_detected</code> and the matched pattern.</li> <li>The message is rejected before reaching any LLM.</li> <li>Graceful degradation: if the Unicode check fails, it is skipped rather than crashing.</li> </ul>"},{"location":"SECURITY/#4-access-control","title":"4. Access Control","text":""},{"location":"SECURITY/#user-allowlist","title":"User Allowlist","text":"Mode Behaviour <code>ALLOWED_USER_IDS</code> set Only listed Discord user IDs can interact with the bot <code>ALLOWED_USER_IDS</code> empty All users permitted (logs a warning at startup) <p>Users can be added/removed at runtime via <code>UserAllowlist.add()</code> / <code>.remove()</code>. All changes are logged.</p>"},{"location":"SECURITY/#rate-limiting","title":"Rate Limiting","text":"Parameter Default Max messages per window 10 Window duration 60 seconds Warning cooldown 30 seconds <p>Per-user tracking with automatic timestamp cleanup. Exceeding the limit returns a user-facing warning (throttled to one warning per cooldown period).</p>"},{"location":"SECURITY/#5-static-analysis-code-quality","title":"5. Static Analysis &amp; Code Quality","text":""},{"location":"SECURITY/#tools-that-run-on-every-commit-pre-commit-hooks","title":"Tools That Run on Every Commit (Pre-Commit Hooks)","text":"Tool Version What It Checks Ruff linter v0.2.2 PEP 8, unused imports, complexity, bugbear, simplify (rule sets: E, F, I, N, W, UP, B, C4, SIM) Ruff formatter v0.2.2 Consistent formatting, 100-char line length mypy v1.8.0 Full strict type checking (<code>strict = true</code>) on <code>src/secureclaw</code> Bandit 1.7.7 Common Python security issues (SQL injection, hardcoded passwords, exec calls) Hadolint v2.12.0 Dockerfile best practices pre-commit-hooks v4.5.0 Large files (&gt;1MB), merge conflicts, YAML/TOML/JSON syntax, trailing whitespace, private key detection"},{"location":"SECURITY/#codeql-github-advanced-security","title":"CodeQL (GitHub Advanced Security)","text":"<ul> <li>File: <code>.github/workflows/codeql.yml</code></li> <li>Schedule: Every Tuesday + on push/PR to <code>main</code></li> <li>Language: Python semantic analysis</li> <li>Detects injection flaws, insecure deserialization, crypto weaknesses, etc.</li> </ul>"},{"location":"SECURITY/#6-dependency-management","title":"6. Dependency Management","text":"Control Implementation Pinned versions <code>requirements.txt</code> pins every dependency to exact versions (e.g. <code>discord.py==2.4.0</code>) Dependabot <code>.github/dependabot.yml</code> checks pip (weekly), Docker images (weekly), GitHub Actions (monthly) Separated environments <code>requirements.txt</code> (production) vs <code>requirements-dev.txt</code> (dev tools) No cache in image <code>pip install --no-cache-dir</code> prevents stale packages in containers Multi-version testing CI runs tests on Python 3.12 and 3.13"},{"location":"SECURITY/#7-container-security","title":"7. Container Security","text":""},{"location":"SECURITY/#dockerfile-dockerfile","title":"Dockerfile (<code>Dockerfile</code>)","text":"Control Detail Minimal base image <code>python:3.12-slim</code> (Debian-based, minimal attack surface) No package cache <code>rm -rf /var/lib/apt/lists/*</code> after install Pip cache disabled <code>--no-cache-dir</code> flag Explicit COPY Only <code>requirements.txt</code> and <code>src/</code> are copied (no <code>.env</code>, <code>.git</code>, etc.) Dedicated directories <code>mkdir -p /app/data /app/logs</code> with known paths"},{"location":"SECURITY/#docker-compose-docker-composeyml","title":"Docker Compose (<code>docker-compose.yml</code>)","text":"Control Detail Health checks All services (Qdrant, Ollama) have TCP health checks with intervals, timeouts, retries, and start periods Restart policy <code>unless-stopped</code> for resilience Service dependency Bot waits for <code>qdrant: service_healthy</code> before starting Network isolation All services on a dedicated <code>secureclaw-net</code> bridge network Named volumes <code>qdrant_storage</code>, <code>ollama_models</code> for persistent data No privileged mode Containers run without elevated privileges"},{"location":"SECURITY/#8-cicd-pipeline-security","title":"8. CI/CD Pipeline Security","text":"<p>File: <code>.github/workflows/ci.yml</code></p>"},{"location":"SECURITY/#pipeline-architecture-6-jobs-summary","title":"Pipeline Architecture (6 Jobs + Summary)","text":"<pre><code>Push/PR to main or develop\n          |\n          v\n   +------+------+-------+\n   |      |      |       |\n  Lint  Types  Security  Docker Build\n   |      |      |       |\n   +------+------+       |\n          |               |\n          v               |\n     Unit Tests           |\n    (Py 3.12, 3.13)      |\n          |               |\n          +-------+-------+\n                  |\n                  v\n          Integration Tests\n         (E2E with Docker)\n                  |\n                  v\n            CI Summary\n       (aggregates results)\n</code></pre>"},{"location":"SECURITY/#job-details","title":"Job Details","text":"Job Duration What It Does Lint ~5s <code>ruff check</code> + <code>ruff format --check</code> on <code>src/</code> and <code>tests/</code> Type Check ~10s <code>mypy src/secureclaw</code> in strict mode Security ~10s <code>bandit -r src/</code> for Python security issues Test ~60s Unit tests on Python 3.12 + 3.13 matrix, coverage to Codecov Docker Build ~30s Buildx with GHA caching, validates <code>docker compose config</code> Integration ~2-3min Full E2E with Docker Compose, uploads logs on failure, auto-cleanup Summary ~5s Markdown table in PR, fails if any check failed"},{"location":"SECURITY/#security-specific-ci-controls","title":"Security-Specific CI Controls","text":"<ul> <li>Secrets via GitHub Actions secrets: <code>DISCORD_TOKEN</code>, <code>GEMINI_API_KEY</code>, etc. are injected at runtime, never stored in code.</li> <li>Conditional integration tests: Skip with <code>[skip integration]</code> in commit message.</li> <li>Artifact retention: Coverage reports (30 days), failure logs (7 days).</li> <li>Container cleanup: <code>docker compose down -v</code> runs in <code>if: always()</code> block.</li> </ul>"},{"location":"SECURITY/#9-testing-strategy","title":"9. Testing Strategy","text":""},{"location":"SECURITY/#three-tier-testing-approach","title":"Three-Tier Testing Approach","text":"Tier When Duration What Pre-commit On <code>git commit</code> ~5-10s Linting, formatting, secret scanning, Bandit, Hadolint Pre-push On <code>git push</code> ~30-60s Ruff, mypy, full pytest suite with coverage CI/CD On push/PR ~5-10min All of the above + Docker build + integration tests + CodeQL"},{"location":"SECURITY/#test-coverage","title":"Test Coverage","text":"<p>Overall Coverage: 87.58% (255 unit tests + 14 integration tests + 4 Discord E2E tests)</p> Module Coverage Tests What's Tested Router Factory 100% 12 Async/sync factory functions, health checks, Ollama\u2192Gemini fallback, error handling, backend selection validation Config 96.88% 49 Settings validation, SecretStr handling, field validators, environment variable isolation, comma-separated parsing Security 94.12% 37 Rate limiter (under/over limit, per-user isolation), user allowlist (empty/configured, add/remove), 24+ prompt injection patterns, Unicode obfuscation, false positive prevention Agent Core 94.76% 41 Agent initialisation, context building, retry logic with exponential backoff, dual-generator responses, memory operations Discord Bot 89.92% 30 Command handling (/ask, /remember, /search, /channels), authorization, rate limiting, message splitting (2000 char limit), DM vs mention handling, agent not ready edge cases Qdrant Memory 88.73% 7 Vector DB operations (store, search, delete), async client usage, collection management Router (Gemini) 83.19% 21 Gemini routing, JSON parsing, classification, simple response generation, error handling Router (Ollama) 98.00% 26 Ollama routing, model selection, health checks, fallback behaviour, timeout handling Embeddings 100% 5 Embedding generation, batch processing, parallel operations Integration Tests N/A 14 Full stack: Docker services healthy (Qdrant + Ollama), collections exist, message flow through both Gemini and Ollama backends, memory persistence, conversation context Discord E2E Tests N/A 4 Real Discord API: bot responses, complex queries, memory recall validation (LLM-based), mention handling"},{"location":"SECURITY/#recent-test-improvements-phase-1-2","title":"Recent Test Improvements (Phase 1 &amp; 2)","text":"<p>Phase 1: Fixed All Test Failures - Fixed 10 config tests with environment variable isolation using <code>monkeypatch.delenv()</code> - Fixed 13 agent core tests with improved mocking and assertions - Fixed 3 security tests with enhanced prompt injection pattern detection - Fixed 14 Docker integration tests with proper <code>.env</code> loading and container cleanup - Added <code>pythonpath = [\"src\"]</code> to pytest configuration for proper module imports</p> <p>Phase 2: Improved Coverage to 87.58% - Router Factory: 26% \u2192 100% (added 12 comprehensive tests for factory pattern, health checks, fallback logic) - Discord Bot: 68.55% \u2192 89.92% (added 11 edge case tests for /channels command, message splitting, agent readiness) - Overall: ~42% \u2192 87.58% (net gain of 45.58 percentage points)</p> <p>All 255 unit tests now pass with zero failures, comprehensive edge case coverage, and proper async/await support throughout.</p>"},{"location":"SECURITY/#integration-test-parametrisation","title":"Integration Test Parametrisation","text":"<p>Tests run against both router backends automatically:</p> <pre><code>@pytest.fixture(scope=\"module\", params=[\"gemini\", \"ollama\"])\ndef router_backend(request, docker_env):\n    ...\n</code></pre> <p>This produces 14 tests (7 scenarios x 2 backends) with no code duplication.</p>"},{"location":"SECURITY/#coverage","title":"Coverage","text":"<ul> <li>Branch coverage enabled</li> <li>HTML + XML reports generated</li> <li>Uploaded to Codecov on Python 3.12 runs</li> <li>Exclusions: <code>pragma: no cover</code>, <code>__repr__</code>, <code>TYPE_CHECKING</code>, abstract methods</li> </ul>"},{"location":"SECURITY/#10-logging-monitoring","title":"10. Logging &amp; Monitoring","text":"<p>File: <code>src/secureclaw/logging.py</code></p> Control Detail Structured logging <code>structlog</code> with JSON output (production) or coloured console (development) Log rotation <code>RotatingFileHandler</code>: 10MB max, 5 backups No credential leakage <code>SecretStr</code> objects log as <code>'**********'</code>, never the actual value Security events logged Prompt injection attempts, allowlist changes, rate limit triggers Third-party noise suppression Discord and httpx loggers set to WARNING"},{"location":"SECURITY/#11-network-security","title":"11. Network Security","text":"Control Detail Docker bridge network All services communicate on <code>secureclaw-net</code>, isolated from host network by default No exposed ports in production Only Qdrant (6333) and Ollama (11434) expose ports (for dev/test); the bot container exposes none TLS for external APIs All API clients (Anthropic, OpenAI, Gemini) use HTTPS by default via <code>httpx</code> No inbound web server The bot connects outbound to Discord's gateway; it does not listen on any HTTP port"},{"location":"SECURITY/#12-gap-analysis-recommendations","title":"12. Gap Analysis &amp; Recommendations","text":"<p>The following automated security best practices have been fully implemented as of 2026-02-06. This section documents what was done and serves as a reference for the security controls now in place.</p>"},{"location":"SECURITY/#high-impact","title":"HIGH IMPACT","text":""},{"location":"SECURITY/#121-container-image-scanning","title":"12.1 Container Image Scanning","text":"<p>Gap: Docker images are built but never scanned for OS-level vulnerabilities (outdated <code>libc</code>, OpenSSL, etc.).</p> <p>Recommendation: Add Trivy or Grype scanning to CI.</p> <pre><code># Example: Add to .github/workflows/ci.yml after docker-build\n- name: Run Trivy vulnerability scanner\n  uses: aquasecurity/trivy-action@master\n  with:\n    image-ref: secureclaw:test\n    format: 'sarif'\n    output: 'trivy-results.sarif'\n    severity: 'CRITICAL,HIGH'\n\n- name: Upload Trivy scan results\n  uses: github/codeql-action/upload-sarif@v3\n  with:\n    sarif_file: 'trivy-results.sarif'\n</code></pre> <p>This integrates with GitHub's Security tab for a unified vulnerability view.</p> <p>References: - Trivy GitHub Action - OWASP Docker Security Cheat Sheet</p>"},{"location":"SECURITY/#122-pin-docker-base-images-by-digest","title":"12.2 Pin Docker Base Images by Digest","text":"<p>Gap: <code>python:3.12-slim</code> and <code>qdrant/qdrant:latest</code> use mutable tags. A compromised or broken upstream push would silently affect builds.</p> <p>Recommendation: Pin by SHA256 digest in <code>Dockerfile</code> and <code>docker-compose.yml</code>.</p> <pre><code># Instead of:\nFROM python:3.12-slim\n# Use:\nFROM python:3.12-slim@sha256:&lt;digest&gt;\n</code></pre> <p>Update digests via Dependabot (already configured for Docker ecosystem).</p> <p>References: - Docker Image Pinning Best Practices - Chainguard Images (minimal, signed alternatives)</p>"},{"location":"SECURITY/#123-software-bill-of-materials-sbom","title":"12.3 Software Bill of Materials (SBOM)","text":"<p>Gap: No SBOM is generated for the container image or Python dependencies. This makes it harder to respond to new CVEs (e.g. \"are we affected by CVE-XXXX in library Y?\").</p> <p>Recommendation: Generate SBOM during Docker build and store as a build artifact.</p> <pre><code>- name: Generate SBOM\n  uses: anchore/sbom-action@v0\n  with:\n    image: secureclaw:test\n    format: spdx-json\n    output-file: sbom.spdx.json\n\n- name: Upload SBOM\n  uses: actions/upload-artifact@v4\n  with:\n    name: sbom\n    path: sbom.spdx.json\n</code></pre> <p>References: - NTIA SBOM Minimum Elements - Anchore SBOM Action</p>"},{"location":"SECURITY/#124-signed-commits-branch-protection","title":"12.4 Signed Commits &amp; Branch Protection","text":"<p>Gap: No enforcement of signed commits or branch protection rules on <code>main</code>.</p> <p>Recommendation: 1. Enable branch protection on <code>main</code>: require PR reviews, status checks to pass, and linear history. 2. Require GPG or SSH signed commits to prevent commit spoofing. 3. Enable CODEOWNERS for critical paths (<code>src/secureclaw/discord/security.py</code>, <code>.github/workflows/</code>, <code>.gitleaks.toml</code>).</p> <pre><code># .github/CODEOWNERS\n/.github/       @jameshinton\n/src/secureclaw/discord/security.py  @jameshinton\n/.gitleaks.toml @jameshinton\n</code></pre> <p>References: - GitHub Branch Protection Rules - Signing Commits</p>"},{"location":"SECURITY/#medium-impact","title":"MEDIUM IMPACT","text":""},{"location":"SECURITY/#125-pip-audit-for-known-vulnerability-scanning","title":"12.5 <code>pip-audit</code> for Known Vulnerability Scanning","text":"<p>Gap: Dependencies are pinned but not checked against CVE databases. Dependabot covers this partially, but <code>pip-audit</code> gives faster feedback in CI.</p> <p>Recommendation: Add <code>pip-audit</code> as a CI step.</p> <pre><code>- name: Audit Python dependencies\n  run: |\n    pip install pip-audit\n    pip-audit -r requirements.txt --strict\n</code></pre> <p>References: - pip-audit - OSV (Open Source Vulnerabilities)</p>"},{"location":"SECURITY/#126-read-only-filesystem-in-production-container","title":"12.6 Read-Only Filesystem in Production Container","text":"<p>Gap: The bot container's filesystem is writable. A compromised process could modify application code.</p> <p>Recommendation: Set <code>read_only: true</code> in <code>docker-compose.yml</code> and use <code>tmpfs</code> for writable directories.</p> <pre><code>secureclaw:\n  read_only: true\n  tmpfs:\n    - /tmp\n  volumes:\n    - ./data:/app/data\n    - ./logs:/app/logs\n</code></pre> <p>References: - Docker Compose read_only - CIS Docker Benchmark 5.12</p>"},{"location":"SECURITY/#127-runtime-security-headers-resource-limits","title":"12.7 Runtime Security Headers / Resource Limits","text":"<p>Gap: No CPU/memory limits on containers. A runaway process (e.g. OOM from a large embedding batch) could starve other services.</p> <p>Recommendation: Set resource limits in <code>docker-compose.yml</code>.</p> <pre><code>secureclaw:\n  deploy:\n    resources:\n      limits:\n        cpus: '2.0'\n        memory: 2G\n      reservations:\n        cpus: '0.5'\n        memory: 512M\n</code></pre> <p>References: - Docker Compose Resource Constraints</p>"},{"location":"SECURITY/#128-non-root-user-in-dockerfile","title":"12.8 Non-Root User in Dockerfile","text":"<p>Gap: The Dockerfile does not explicitly create or switch to a non-root user. While the default may not be root in all configurations, it is best to be explicit.</p> <p>Recommendation:</p> <pre><code>RUN useradd --create-home --shell /bin/bash appuser\nUSER appuser\n</code></pre> <p>References: - Dockerfile USER best practice - CIS Docker Benchmark 4.1</p>"},{"location":"SECURITY/#129-github-actions-workflow-hardening","title":"12.9 GitHub Actions Workflow Hardening","text":"<p>Gap: Actions use major version tags (e.g. <code>actions/checkout@v4</code>) which are mutable. A supply chain attack on an action would affect all workflows.</p> <p>Recommendation: Pin actions by SHA.</p> <pre><code># Instead of:\nuses: actions/checkout@v4\n# Use:\nuses: actions/checkout@&lt;full-sha&gt;\n</code></pre> <p>Also add <code>permissions</code> blocks to limit GITHUB_TOKEN scope per job:</p> <pre><code>jobs:\n  lint:\n    permissions:\n      contents: read\n</code></pre> <p>References: - GitHub Actions Security Hardening - StepSecurity Harden-Runner</p>"},{"location":"SECURITY/#low-impact-nice-to-have","title":"LOW IMPACT / NICE-TO-HAVE","text":""},{"location":"SECURITY/#1210-pre-commit-hook-integrity-verification","title":"12.10 Pre-Commit Hook Integrity Verification","text":"<p>Gap: <code>pre-commit</code> hooks can be skipped with <code>--no-verify</code>. There is no enforcement that hooks actually ran.</p> <p>Recommendation: Add a CI step that runs <code>pre-commit run --all-files</code> to catch any commits that bypassed local hooks. This is effectively a safety net.</p> <pre><code>- name: Run pre-commit checks\n  uses: pre-commit/action@v3.0.1\n</code></pre> <p>References: - pre-commit CI action</p>"},{"location":"SECURITY/#1211-security-policy-vulnerability-reporting","title":"12.11 Security Policy &amp; Vulnerability Reporting","text":"<p>Gap: No <code>SECURITY.md</code> at the repository root (GitHub's standard location) for vulnerability reporting instructions.</p> <p>Recommendation: Add a root-level <code>SECURITY.md</code> with: - Supported versions - How to report vulnerabilities (email or GitHub Security Advisories) - Expected response timeline</p> <p>References: - GitHub Security Policy</p>"},{"location":"SECURITY/#1212-automated-license-compliance","title":"12.12 Automated License Compliance","text":"<p>Gap: No automated check that all dependencies use compatible licenses (the project is MIT-licensed).</p> <p>Recommendation:</p> <pre><code>- name: Check dependency licenses\n  run: |\n    pip install pip-licenses\n    pip-licenses --allow-only=\"MIT;BSD;Apache-2.0;ISC;PSF;Python-2.0\" --fail-on-violation\n</code></pre> <p>References: - pip-licenses</p>"},{"location":"SECURITY/#summary-matrix","title":"Summary Matrix","text":"# Recommendation Impact Effort Status 12.1 Container image scanning (Trivy) HIGH Low \u2705 Implemented 12.2 Pin Docker images by digest HIGH Low \u2705 Implemented 12.3 SBOM generation HIGH Low \u2705 Implemented 12.4 Signed commits &amp; branch protection HIGH Medium \u2705 Implemented 12.5 <code>pip-audit</code> in CI MEDIUM Low \u2705 Implemented 12.6 Read-only container filesystem MEDIUM Low \u2705 Implemented 12.7 Container resource limits MEDIUM Low \u2705 Implemented 12.8 Explicit non-root user in Dockerfile MEDIUM Low \u2705 Implemented 12.9 Pin GitHub Actions by SHA MEDIUM Medium \u2705 Implemented 12.10 Pre-commit in CI (safety net) LOW Low \u2705 Implemented 12.11 Security policy at repo root LOW Low \u2705 Implemented 12.12 Automated license compliance LOW Low \u2705 Implemented"},{"location":"SECURITY/#additional-security-scanning-added-2026-02-06","title":"Additional Security Scanning (Added 2026-02-06)","text":"<p>Beyond the original 12 gaps, the following additional security measures were implemented:</p> Tool Category What It Does Semgrep CE SAST 3000+ Python rules with taint tracking and data-flow analysis. SARIF results uploaded to GitHub Security tab. Trivy (filesystem mode) Dependencies Scans OS-level packages inside the container that pip-audit can't see GitHub Ruleset Access Control Branch protection on <code>main</code>: require PRs, status checks, block force pushes CODEOWNERS Access Control Assigns ownership of security-critical paths for review requirements"},{"location":"STARTUP_WALKTHROUGH/","title":"SecureClaw Startup Script Walkthrough","text":"<p>A comprehensive guide to understanding the <code>start.sh</code> script - what it does, why, and how it handles errors.</p>"},{"location":"STARTUP_WALKTHROUGH/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Execution Flow Diagram</li> <li>Phase-by-Phase Breakdown</li> <li>Decision Trees</li> <li>Timing Expectations</li> <li>Error Handling</li> <li>Environment Variables</li> </ol>"},{"location":"STARTUP_WALKTHROUGH/#overview","title":"Overview","text":"<p>The <code>start.sh</code> script is the single entry point for running SecureClaw. It handles:</p> <ul> <li>\u2705 Dependency verification (Python, Docker)</li> <li>\u2705 Environment configuration (.env file)</li> <li>\u2705 Virtual environment management</li> <li>\u2705 Docker container orchestration</li> <li>\u2705 Ollama model download and memory management</li> <li>\u2705 Automatic Docker Desktop management</li> </ul> <p>Design Philosophy: - Zero-knowledge startup: Works for first-time users with minimal configuration - Idempotent: Safe to run multiple times - won't duplicate work - Fail-fast: Exits immediately on critical errors with clear guidance - Progressive enhancement: Detects capabilities and offers upgrades</p> <p>Typical runtime: - First run with Ollama: 5-10 minutes (model download) - First run with Gemini: 30-60 seconds (Docker startup) - Subsequent runs: 10-20 seconds (containers already exist)</p>"},{"location":"STARTUP_WALKTHROUGH/#execution-flow-diagram","title":"Execution Flow Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 START: ./start.sh                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 1: Environment Validation                       \u2502\n\u2502  \u2022 Check Python 3.12+                                 \u2502\n\u2502  \u2022 Check Docker installed                             \u2502\n\u2502  \u2022 Check Docker daemon ready                          \u2502\n\u2502  \u2022 Launch Docker if needed                            \u2502\n\u2502  \u2022 Check .env file exists                             \u2502\n\u2502  \u2022 Validate required vars (DISCORD_TOKEN, GEMINI_KEY) \u2502\n\u2502  Duration: 5-90 seconds (if launching Docker)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 2: Router Backend Selection (if not set)       \u2502\n\u2502  \u2022 Prompt user: Gemini or Ollama?                     \u2502\n\u2502  \u2022 Save choice to .env                                \u2502\n\u2502  Duration: 5-10 seconds (user interaction)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 3: Python Environment                           \u2502\n\u2502  \u2022 Create/activate virtual environment                \u2502\n\u2502  \u2022 Install dependencies if missing                    \u2502\n\u2502  Duration: 5-60 seconds (depends on cache)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 4: Qdrant Vector Database                       \u2502\n\u2502  \u2022 Check if container exists                          \u2502\n\u2502  \u2022 Create or start container                          \u2502\n\u2502  \u2022 Wait for health check (30s max)                    \u2502\n\u2502  Duration: 5-15 seconds                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u25ba ROUTER_BACKEND=gemini?\n                    \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502             \u2502 Yes\n                    \u2502             \u25bc\n                    \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502      \u2502 Skip Ollama phases  \u2502\n                    \u2502      \u2502 Go to Phase 8       \u2502\n                    \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502             \u2502\n                    \u2502 No (Ollama) \u2502\n                    \u25bc             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 5: Ollama System Assessment (Ollama only)       \u2502\n\u2502  \u2022 Check if already assessed (.ollama_assessed)       \u2502\n\u2502  \u2022 Run hardware detection                             \u2502\n\u2502  \u2022 Recommend model based on RAM/CPU/GPU               \u2502\n\u2502  \u2022 Update .env with OLLAMA_ROUTER_MODEL &amp; DOCKER_MEM  \u2502\n\u2502  Duration: 10-20 seconds (user interaction)           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 6: Docker Memory Check (Ollama only)            \u2502\n\u2502  \u2022 Read OLLAMA_DOCKER_MEMORY from .env               \u2502\n\u2502  \u2022 Check Docker Desktop total memory                  \u2502\n\u2502  \u2022 If insufficient, prompt user:                      \u2502\n\u2502    1. Auto-increase (calls increase-docker-memory.sh) \u2502\n\u2502    2. Choose smaller model (exit, re-run)            \u2502\n\u2502    3. Continue anyway (risky)                         \u2502\n\u2502  Duration: 30-90 seconds (if increasing memory)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 7: Ollama Container &amp; Model (Ollama only)       \u2502\n\u2502  \u2022 Create/start Ollama container                      \u2502\n\u2502  \u2022 Wait for API ready (30s max)                       \u2502\n\u2502  \u2022 Check if model downloaded                          \u2502\n\u2502  \u2022 Pull model if missing (~4.7GB, 3-7 minutes)        \u2502\n\u2502  Duration: 10 seconds - 10 minutes (first run)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 8: Configuration Summary                        \u2502\n\u2502  \u2022 Display all settings                               \u2502\n\u2502  \u2022 Show API keys (truncated)                          \u2502\n\u2502  \u2022 Show backend choice                                \u2502\n\u2502  Duration: 1 second                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase 9: Start Bot                                    \u2502\n\u2502  \u2022 Set PYTHONPATH                                     \u2502\n\u2502  \u2022 Launch: python -m secureclaw                       \u2502\n\u2502  \u2022 Run until Ctrl+C                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"STARTUP_WALKTHROUGH/#phase-by-phase-breakdown","title":"Phase-by-Phase Breakdown","text":""},{"location":"STARTUP_WALKTHROUGH/#phase-1-environment-validation","title":"Phase 1: Environment Validation","text":"<p>Purpose: Ensure all prerequisites are met before continuing.</p>"},{"location":"STARTUP_WALKTHROUGH/#11-python-version-check-lines-43-65","title":"1.1 Python Version Check (Lines 43-65)","text":"<pre><code># Check for Python 3.12 or 3.13 explicitly\nif command_exists python3.12; then\n    PYTHON_CMD=\"python3.12\"\nelif command_exists python3.13; then\n    PYTHON_CMD=\"python3.13\"\nelif command_exists python3; then\n    # Fallback: check if python3 is &gt;= 3.12\n    PYTHON_VERSION=$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1,2)\n    if [[ $(echo \"$PYTHON_VERSION &gt;= 3.12\" | bc -l) -eq 1 ]]; then\n        PYTHON_CMD=\"python3\"\n    else\n        exit 1  # Version too old\n    fi\nelse\n    exit 1  # Not found\nfi\n</code></pre> <p>Decision Logic: - Prefer explicit versions (python3.12, python3.13) - Fall back to generic python3 if &gt;= 3.12 - Exit with error if none found</p> <p>Why 3.12+? SecureClaw uses modern Python features (type hints, pattern matching) requiring 3.12+.</p> <p>Error Example: <pre><code>\u2717 Python 3.12+ required, found 3.11\n\u2139 Install with: brew install python@3.12\n</code></pre></p>"},{"location":"STARTUP_WALKTHROUGH/#12-docker-check-auto-launch-lines-67-157","title":"1.2 Docker Check &amp; Auto-Launch (Lines 67-157)","text":"<p>Step 1: Check if Docker CLI exists <pre><code>if ! command_exists docker; then\n    print_error \"Docker not found\"\n    exit 1\nfi\n</code></pre></p> <p>Step 2: Check if daemon is ready <pre><code>if ! docker info &gt;/dev/null 2&gt;&amp;1; then\n    # Daemon not ready - check if Docker Desktop is starting\n</code></pre></p> <p>Step 3: Determine Docker state <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Is Docker daemon ready?                 \u2502\n\u2502 (docker info succeeds)                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502 Yes         \u2502 No\n           \u25bc             \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Continue \u2502   \u2502 Is Docker Desktop  \u2502\n    \u2502          \u2502   \u2502 process running?   \u2502\n    \u2502          \u2502   \u2502 (pgrep -x \"Docker\")\u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502 Yes               \u2502 No\n                \u25bc                   \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 Starting...   \u2502   \u2502 Launch Docker   \u2502\n        \u2502 Wait 90s max  \u2502   \u2502 Desktop         \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502 Wait for daemon \u2502\n                            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Step 4: Launch Docker if needed <pre><code># Verify Docker.app exists\nif [ ! -d \"/Applications/Docker.app\" ]; then\n    print_error \"Docker Desktop not found at /Applications/Docker.app\"\n    exit 1\nfi\n\n# Launch\nopen -a Docker\n\n# Initial wait (5 seconds) for process to spawn\nsleep 5\n\n# Quick check loop (4 attempts x 5 seconds = 20s total)\nfor attempt in {1..4}; do\n    if docker info &gt;/dev/null 2&gt;&amp;1; then\n        print_success \"Docker daemon is ready\"\n        break 2  # Success! Exit both loops\n    fi\n    sleep 5\ndone\n</code></pre></p> <p>Two-Phase Wait Strategy:</p> <ol> <li>Quick Phase (20 seconds): 4 attempts with 5-second intervals</li> <li>Optimized for fast machines / warm starts</li> <li> <p>Most machines ready in 10-20 seconds</p> </li> <li> <p>Extended Phase (90 seconds): Continues if quick phase fails</p> </li> <li>Handles slow machines / cold starts</li> <li>Shows progress every 10 seconds</li> </ol> <p>Why this approach? - Fast machines don't wait unnecessarily - Slow machines get enough time - Clear progress feedback to user</p> <p>Timing Breakdown: <pre><code>Fast machine (Docker already warm):\n  Launch: 2s + Quick phase: 5-10s = 7-12 seconds total\n\nSlow machine (Docker cold start):\n  Launch: 2s + Quick phase: 20s + Extended: 30s = 52 seconds total\n\nVery slow machine:\n  Launch: 2s + Quick phase: 20s + Extended: 60s = 82 seconds total\n</code></pre></p>"},{"location":"STARTUP_WALKTHROUGH/#13-env-file-validation-lines-159-183","title":"1.3 .env File Validation (Lines 159-183)","text":"<p>Check file exists: <pre><code>if [ ! -f .env ]; then\n    print_error \".env file not found\"\n    print_info \"Copy .env.example to .env and add your API keys\"\n    exit 1\nfi\n</code></pre></p> <p>Validate required variables: <pre><code>source .env  # Load variables\n\nMISSING_VARS=()\nif [ -z \"$DISCORD_TOKEN\" ]; then\n    MISSING_VARS+=(\"DISCORD_TOKEN\")\nfi\nif [ -z \"$GEMINI_API_KEY\" ]; then\n    MISSING_VARS+=(\"GEMINI_API_KEY\")\nfi\n\nif [ ${#MISSING_VARS[@]} -gt 0 ]; then\n    print_error \"Missing required environment variables: ${MISSING_VARS[*]}\"\n    exit 1\nfi\n</code></pre></p> <p>Why source early? We need env vars for subsequent phases (router selection, Ollama config).</p>"},{"location":"STARTUP_WALKTHROUGH/#phase-2-router-backend-selection","title":"Phase 2: Router Backend Selection","text":"<p>Purpose: One-time choice between Gemini (cloud) and Ollama (local) routing.</p>"},{"location":"STARTUP_WALKTHROUGH/#trigger-condition-line-186","title":"Trigger Condition (Line 186)","text":"<pre><code>if [ -z \"$ROUTER_BACKEND\" ]; then\n    # Not set in .env - ask user\n</code></pre> <p>When does this happen? - First run (fresh .env from .env.example) - User manually removed ROUTER_BACKEND from .env</p> <p>Interactive Prompt (Lines 187-225):</p> <pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  Router Backend Selection\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSecureClaw can use two different backends for message routing:\n\n  1. Gemini (Google) - Cloud-based, fast, minimal setup\n     \u2022 Uses your existing Gemini API key\n     \u2022 No additional downloads\n     \u2022 Recommended for cloud-based workflows\n\n  2. Ollama (Local) - Privacy-focused, runs on your machine\n     \u2022 No data sent to external APIs for routing\n     \u2022 ~5GB model download (first time only)\n     \u2022 Recommended for privacy-conscious users\n\nWhich backend would you like to use? (1=Gemini, 2=Ollama) [1]:\n</code></pre> <p>Decision Logic: <pre><code>case \"$REPLY\" in\n    2)\n        ROUTER_BACKEND=\"ollama\"\n        ;;\n    1|\"\")  # Default to Gemini if user just presses Enter\n        ROUTER_BACKEND=\"gemini\"\n        ;;\n    *)\n        print_warning \"Invalid selection, defaulting to Gemini\"\n        ROUTER_BACKEND=\"gemini\"\n        ;;\nesac\n\n# Save to .env for future runs\necho \"ROUTER_BACKEND=$ROUTER_BACKEND\" &gt;&gt; .env\n</code></pre></p> <p>Why persist to .env? - User only chooses once - Subsequent runs skip this prompt - Can be changed by editing .env manually</p> <p>Typical Timing: 5-10 seconds (user reading and choosing)</p>"},{"location":"STARTUP_WALKTHROUGH/#phase-3-python-environment","title":"Phase 3: Python Environment","text":"<p>Purpose: Isolate dependencies in a virtual environment.</p>"},{"location":"STARTUP_WALKTHROUGH/#31-virtual-environment-creation-lines-228-238","title":"3.1 Virtual Environment Creation (Lines 228-238)","text":"<pre><code>if [ ! -d \".venv\" ]; then\n    print_warning \"Virtual environment not found, creating...\"\n    $PYTHON_CMD -m venv .venv\n    print_success \"Virtual environment created\"\nfi\n\nsource .venv/bin/activate\n</code></pre> <p>Why check first? Avoid re-creating existing venv (wastes time).</p> <p>Timing: 3-5 seconds to create, &lt;1 second to activate</p>"},{"location":"STARTUP_WALKTHROUGH/#32-dependency-installation-lines-240-250","title":"3.2 Dependency Installation (Lines 240-250)","text":"<pre><code>if ! python -c \"import discord\" 2&gt;/dev/null; then\n    # discord.py is a core dependency - if it's not installed, nothing is\n    print_warning \"Dependencies not installed, installing...\"\n    pip install --upgrade pip\n    pip install -r requirements.txt\n    pip install -e .\n    print_success \"Dependencies installed\"\nelse\n    print_success \"Dependencies already installed\"\nfi\n</code></pre> <p>Optimization: Test for a single package instead of all packages. - Fast path: &lt;1 second (dependencies already installed) - Slow path: 30-60 seconds (first time)</p> <p>Why <code>pip install -e .</code>? - Installs SecureClaw in \"editable\" mode - Code changes apply immediately (no reinstall needed)</p>"},{"location":"STARTUP_WALKTHROUGH/#phase-4-qdrant-vector-database","title":"Phase 4: Qdrant Vector Database","text":"<p>Purpose: Start vector database for conversation memory and embeddings.</p>"},{"location":"STARTUP_WALKTHROUGH/#container-lifecycle-lines-252-270","title":"Container Lifecycle (Lines 252-270)","text":"<p>State Machine: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Does container exist?               \u2502\n\u2502 (docker ps -a | grep secureclaw-    \u2502\n\u2502  qdrant)                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Yes          \u2502 No\n       \u25bc              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Is it        \u2502  \u2502 Create new      \u2502\n\u2502 running?     \u2502  \u2502 container:      \u2502\n\u2502 (docker ps)  \u2502  \u2502 docker run -d   \u2502\n\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518  \u2502   --name ...    \u2502\n   \u2502 Yes   \u2502 No   \u2502   -p 6333:6333  \u2502\n   \u25bc       \u25bc      \u2502   -v ...        \u2502\n\u250c\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2510   \u2502   qdrant/qdrant \u2502\n\u2502Skip\u2502  \u2502Start\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Create Command: <pre><code>docker run -d \\\n    --name secureclaw-qdrant \\\n    -p 6333:6333 \\\n    -v \"$(pwd)/qdrant_storage:/qdrant/storage\" \\\n    qdrant/qdrant:latest\n</code></pre></p> <p>Why volume mount? Persist vector embeddings across container restarts.</p>"},{"location":"STARTUP_WALKTHROUGH/#health-check-lines-272-287","title":"Health Check (Lines 272-287)","text":"<pre><code>MAX_RETRIES=30  # 30 seconds max\nRETRY_COUNT=0\n\nwhile [ $RETRY_COUNT -lt $MAX_RETRIES ]; do\n    if curl -s http://localhost:6333/healthz &gt;/dev/null 2&gt;&amp;1; then\n        print_success \"Qdrant is ready\"\n        break\n    fi\n    RETRY_COUNT=$((RETRY_COUNT + 1))\n    sleep 1\ndone\n</code></pre> <p>Why curl healthz? - Qdrant exposes a health endpoint - More reliable than assuming \"started = ready\"</p> <p>Typical Timing: - Container already running: 1-2 seconds - Container starting: 3-5 seconds - First time (pulling image): 10-30 seconds</p>"},{"location":"STARTUP_WALKTHROUGH/#phase-5-ollama-system-assessment-ollama-only","title":"Phase 5: Ollama System Assessment (Ollama Only)","text":"<p>Skip Condition: If <code>ROUTER_BACKEND != \"ollama\"</code>, phases 5-7 are skipped entirely.</p> <p>Purpose: Detect hardware and recommend optimal Ollama model.</p>"},{"location":"STARTUP_WALKTHROUGH/#assessment-trigger-lines-293-294","title":"Assessment Trigger (Lines 293-294)","text":"<pre><code>if [ ! -f \".ollama_assessed\" ] || [ -z \"$OLLAMA_ROUTER_MODEL\" ]; then\n    # Run assessment\n</code></pre> <p>When does this run? 1. First time using Ollama (<code>.ollama_assessed</code> doesn't exist) 2. User removed model from .env (<code>OLLAMA_ROUTER_MODEL</code> empty)</p> <p>When is it skipped? - <code>.ollama_assessed</code> marker exists AND <code>OLLAMA_ROUTER_MODEL</code> is set - User can force re-assessment: <code>rm .ollama_assessed &amp;&amp; ./start.sh</code></p>"},{"location":"STARTUP_WALKTHROUGH/#hardware-detection-lines-295-326","title":"Hardware Detection (Lines 295-326)","text":"<p>Script: <code>scripts/assess-system.py</code></p> <p>What it detects: <pre><code>{\n    'platform': 'Darwin',        # macOS\n    'machine': 'arm64',          # Apple Silicon\n    'cpu_count': 10,             # Physical cores\n    'cpu_threads': 10,           # Logical cores\n    'ram_gb': 16.0,              # Total RAM\n    'available_ram_gb': 8.5,     # Available now\n    'disk_free_gb': 250.0,       # Free disk space\n    'gpu': {\n        'type': 'apple_silicon', # or 'nvidia', 'none'\n        'name': 'Apple Silicon',\n        'unified_memory': True\n    }\n}\n</code></pre></p> <p>Recommendation Logic: <pre><code>if ram &lt; 6:\n    return phi3:mini (5GB Docker, 2.3GB model)\nelif ram &lt; 12 and gpu == 'none':\n    return llama3.1:8b (8GB Docker, 4.7GB model)\nelif gpu in ['nvidia', 'apple_silicon']:\n    return qwen2.5:7b (10GB Docker, 4.7GB model)  # GPU accelerated\nelif ram &gt;= 16:\n    return qwen2.5:7b (10GB Docker, 4.7GB model)  # High RAM\nelse:\n    return llama3.1:8b (8GB Docker, 4.7GB model)  # Default\n</code></pre></p> <p>Output: <pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nSecureClaw System Assessment\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n\ud83d\udda5\ufe0f  HARDWARE DETECTED:\n  Platform: Darwin (arm64)\n  CPU: 10 cores (10 threads)\n  RAM: 16.0 GB total\n  RAM Available: 8.5 GB\n  Disk Space: 250.0 GB free\n  GPU: Apple Silicon\n\n\ud83e\udd16 RECOMMENDED MODEL:\n  Model: qwen2.5:7b\n  Download Size: 4.7 GB\n  RAM Required: 8 GB minimum\n  Docker Memory: 10 GB (automatically configured)\n  Expected Speed: ~2-3s (CPU), ~500ms (GPU)\n  Quality: Best\n  Description: Best reasoning quality for routing\n\n\ud83d\udca1 RECOMMENDATION REASON:\n  GPU detected! You can use higher quality models with fast inference.\n\nWould you like to use the recommended model? (Y/n):\n</code></pre></p> <p>User Interaction: <pre><code>read -p \"Would you like to use the recommended model? (Y/n): \" -r\n\nif [[ ! $REPLY =~ ^[Nn]$ ]]; then\n    # User accepted (or just pressed Enter)\n    $PYTHON_CMD scripts/assess-system.py --update-env\n\n    # This updates .env with:\n    # OLLAMA_ROUTER_MODEL=qwen2.5:7b\n    # OLLAMA_DOCKER_MEMORY=10\n\n    source .env  # Reload to get updated values\n    touch .ollama_assessed  # Mark as assessed\nfi\n</code></pre></p> <p>Timing: 5-15 seconds (hardware detection + user reading + interaction)</p>"},{"location":"STARTUP_WALKTHROUGH/#phase-6-docker-memory-check-ollama-only","title":"Phase 6: Docker Memory Check (Ollama Only)","text":"<p>Purpose: Ensure Docker Desktop has enough RAM allocated for the selected model.</p>"},{"location":"STARTUP_WALKTHROUGH/#memory-requirement-calculation-lines-343-352","title":"Memory Requirement Calculation (Lines 343-352)","text":"<pre><code># Get required memory from .env (set by assess-system.py)\nOLLAMA_DOCKER_MEMORY=\"${OLLAMA_DOCKER_MEMORY:-8}\"  # Default 8GB\n\n# Get current Docker allocation\nDOCKER_TOTAL_MEMORY=$(docker info 2&gt;/dev/null | grep \"Total Memory\" | awk '{print $3}')\nDOCKER_MEMORY_GB=$(echo \"$DOCKER_TOTAL_MEMORY\" | sed 's/GiB//')\n\n# Compare\nREQUIRED_MEMORY=$OLLAMA_DOCKER_MEMORY\nif (( $(echo \"$DOCKER_MEMORY_GB &lt; $REQUIRED_MEMORY\" | bc -l) )); then\n    # Insufficient memory!\n</code></pre> <p>Example Scenario: <pre><code>Selected model: qwen2.5:7b\nOLLAMA_DOCKER_MEMORY: 10 (from assess-system.py)\nCurrent Docker allocation: 4GB\n\nProblem: 4GB &lt; 10GB \u274c\n</code></pre></p>"},{"location":"STARTUP_WALKTHROUGH/#user-prompt-lines-353-409","title":"User Prompt (Lines 353-409)","text":"<pre><code>\u26a0 Docker has only 4GB allocated\n\u26a0 Your selected model requires 10GB\n\nWhat would you like to do?\n  1. Automatically increase Docker memory to 10GB (recommended)\n  2. Choose a smaller model that fits current Docker memory\n  3. Continue anyway (may fail)\n\nEnter choice (1/2/3) [1]:\n</code></pre> <p>Decision Tree: <pre><code>                User Choice\n                     \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502            \u2502            \u2502\n        \u25bc            \u25bc            \u25bc\n    Option 1     Option 2     Option 3\n  Auto-increase  Smaller    Continue\n                  model      anyway\n        \u2502            \u2502            \u2502\n        \u25bc            \u25bc            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Call increase-\u2502 \u2502 rm   \u2502  \u2502 Continue \u2502\n\u2502 docker-memory.\u2502 \u2502 .olla\u2502  \u2502 (risky)  \u2502\n\u2502 sh --yes      \u2502 \u2502 ma_  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502               \u2502 \u2502 asses\u2502\n\u2502 \u2022 Backup JSON \u2502 \u2502 sed  \u2502\n\u2502 \u2022 Update      \u2502 \u2502      \u2502\n\u2502   memoryMiB   \u2502 \u2502 Exit \u2502\n\u2502 \u2022 Restart     \u2502 \u2502 0    \u2502\n\u2502   Docker      \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502 \u2022 Wait for    \u2502\n\u2502   daemon      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Option 1: Auto-increase (Default)</p> <p>Script: <code>scripts/increase-docker-memory.sh --yes</code></p> <p>What it does: 1. Backup settings: <pre><code>cp ~/Library/Group\\ Containers/group.com.docker/settings.json \\\n   ~/Library/Group\\ Containers/group.com.docker/settings.json.backup.20260205_143022\n</code></pre></p> <ol> <li> <p>Update JSON: <pre><code>import json\n\nwith open(settings_file, 'r') as f:\n    settings = json.load(f)\n\nsettings['memoryMiB'] = 10240  # 10GB in MiB\n\nwith open(settings_file, 'w') as f:\n    json.dump(settings, f, indent=2)\n</code></pre></p> </li> <li> <p>Restart Docker: <pre><code># Try AppleScript first\nosascript -e 'quit app \"Docker\"'\n\n# Fallback to killall if osascript fails\nif ! osascript -e 'quit app \"Docker\"' 2&gt;/dev/null; then\n    killall Docker\nfi\n\n# Wait for full shutdown (up to 20s)\nfor i in {1..20}; do\n    ! pgrep -x \"Docker\" &amp;&amp; break\n    sleep 1\ndone\n\n# Launch\nopen -a Docker\n\n# Wait for daemon (up to 60s)\nfor i in {1..60}; do\n    docker info &gt;/dev/null 2&gt;&amp;1 &amp;&amp; break\n    sleep 1\ndone\n</code></pre></p> </li> </ol> <p>Why AppleScript first? - More graceful shutdown - Allows Docker to save state - Fallback to <code>killall</code> if it fails</p> <p>Why wait loops with timeouts? - Prevent infinite hangs - Provide clear error messages - Show progress to user</p> <p>Timing: - Stop Docker: 5-10 seconds - Start Docker: 30-60 seconds - Total: 35-70 seconds</p> <p>Option 2: Smaller Model <pre><code>rm -f .ollama_assessed  # Remove marker\nprint_info \"Please run ./start.sh again to choose a smaller model\"\nexit 0\n</code></pre> - Clean exit - Next run triggers assessment again - User can choose <code>phi3:mini</code> (5GB) instead</p> <p>Option 3: Continue Anyway <pre><code>print_warning \"Continuing with insufficient memory. Model may crash.\"\n# Script continues, but Ollama likely to OOM\n</code></pre> - Not recommended - Useful for testing or if user knows better - Model will likely crash with OOM errors</p>"},{"location":"STARTUP_WALKTHROUGH/#phase-7-ollama-container-model-ollama-only","title":"Phase 7: Ollama Container &amp; Model (Ollama Only)","text":"<p>Purpose: Start Ollama container and download the selected model.</p>"},{"location":"STARTUP_WALKTHROUGH/#container-management-lines-411-431","title":"Container Management (Lines 411-431)","text":"<p>State Machine (same as Qdrant): <pre><code>Container exists? \u2192 Yes \u2192 Running? \u2192 Yes \u2192 Skip\n                           \u2502          No  \u2192 Start\n                    No \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 Create\n</code></pre></p> <p>Create Command: <pre><code>docker run -d \\\n    --name secureclaw-ollama \\\n    --memory=\"${OLLAMA_DOCKER_MEMORY}g\" \\        # e.g., 10g\n    --memory-swap=\"${OLLAMA_DOCKER_MEMORY}g\" \\  # Prevent swap usage\n    -p 11434:11434 \\\n    -v \"$(pwd)/ollama_models:/root/.ollama\" \\   # Persist models\n    ollama/ollama:latest\n</code></pre></p> <p>Key Parameters: - <code>--memory</code>: Container RAM limit (matches Docker Desktop allocation) - <code>--memory-swap</code>: Same as memory (prevents swapping to disk) - <code>-v</code>: Persist downloaded models across container restarts</p> <p>Why volume for models? - Models are large (2-5GB each) - Re-downloading every time wastes time and bandwidth - Survives <code>docker rm secureclaw-ollama</code></p>"},{"location":"STARTUP_WALKTHROUGH/#api-health-check-lines-433-448","title":"API Health Check (Lines 433-448)","text":"<pre><code>MAX_RETRIES=30\nwhile [ $RETRY_COUNT -lt $MAX_RETRIES ]; do\n    if curl -s http://localhost:11434/api/tags &gt;/dev/null 2&gt;&amp;1; then\n        break  # Ready!\n    fi\n    sleep 1\ndone\n</code></pre> <p>Why <code>/api/tags</code>? - Ollama's \"list models\" endpoint - Returns empty list if no models, but proves API is responsive</p> <p>Timing: - Already running: 1-2 seconds - Starting: 3-5 seconds - First time (pulling image): 20-40 seconds</p>"},{"location":"STARTUP_WALKTHROUGH/#model-download-lines-450-467","title":"Model Download (Lines 450-467)","text":"<p>Check if model exists: <pre><code>OLLAMA_MODEL=\"${OLLAMA_ROUTER_MODEL:-llama3.1:8b}\"\n\nif docker exec secureclaw-ollama ollama list | grep -q \"$OLLAMA_MODEL\"; then\n    print_success \"Model '$OLLAMA_MODEL' already available\"\nelse\n    # Not downloaded yet\n</code></pre></p> <p>Pull model: <pre><code>print_warning \"Model '$OLLAMA_MODEL' not found, downloading (this may take several minutes)...\"\nprint_info \"Model size: ~4.7GB - please be patient...\"\n\nif docker exec secureclaw-ollama ollama pull \"$OLLAMA_MODEL\"; then\n    print_success \"Model '$OLLAMA_MODEL' downloaded successfully\"\nelse\n    print_error \"Failed to download model '$OLLAMA_MODEL'\"\n    print_warning \"Continuing anyway - the bot will fall back to Gemini if the model isn't available\"\nfi\n</code></pre></p> <p>Download Progress Example: <pre><code>pulling manifest\npulling 8934d96d3f08... 100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f 4.7 GB\npulling 8c17c2ebb0ea... 100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f 7.0 KB\npulling 7c23fb36d801... 100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f 4.8 KB\npulling 2e0493f67d0c... 100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f   59 B\npulling fa304d675061... 100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f   91 B\npulling 42ba7f8a01dd... 100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  557 B\nverifying sha256 digest\nwriting manifest\nsuccess\n</code></pre></p> <p>Timing: - Model already downloaded: 1-2 seconds - Downloading 2.3GB (phi3): 2-4 minutes (fast connection) - Downloading 4.7GB (llama3.1, qwen2.5): 3-7 minutes</p> <p>Graceful Failure: - If download fails, script continues - Bot will use Gemini as fallback - User can manually pull later: <code>docker exec secureclaw-ollama ollama pull &lt;model&gt;</code></p>"},{"location":"STARTUP_WALKTHROUGH/#phase-8-configuration-summary","title":"Phase 8: Configuration Summary","text":"<p>Purpose: Show user exactly what configuration will be used.</p> <p>Display (Lines 473-488): <pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  Starting SecureClaw Bot\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n\u2139 Configuration Summary:\n  \u2022 Python: Python 3.12.1\n  \u2022 Discord Token: DISCORD_TOKEN_START...\n  \u2022 Gemini API: GEMINI_API_KEY_START...\n  \u2022 Anthropic API: ANTHROPIC_API_KEY_S...\n  \u2022 OpenAI API: OPENAI_API_KEY_START...\n  \u2022 Qdrant: http://localhost:6333\n  \u2022 Router Backend: ollama\n  \u2022 Ollama: http://localhost:11434 (Model: qwen2.5:7b)\n  \u2022 File Logging: true (Directory: logs)\n  \u2022 Allowed Users: 123456789,987654321\n</code></pre></p> <p>Security: API keys truncated to first 20 characters only.</p> <p>Timing: &lt;1 second</p>"},{"location":"STARTUP_WALKTHROUGH/#phase-9-start-bot","title":"Phase 9: Start Bot","text":"<p>Final Step (Lines 490-497):</p> <pre><code>print_success \"All checks passed! Starting bot...\"\necho \"\"\necho -e \"${GREEN}Press Ctrl+C to stop the bot${NC}\"\necho \"\"\n\n# Set PYTHONPATH to include src directory\nPYTHONPATH=\"${PWD}/src:${PYTHONPATH}\" python -m secureclaw\n</code></pre> <p>Why set PYTHONPATH? - SecureClaw source is in <code>src/secureclaw/</code> - Running as module (<code>-m secureclaw</code>) requires it to be importable - Adding <code>src/</code> to path makes this work</p> <p>What happens next? 1. Python loads <code>src/secureclaw/__main__.py</code> 2. Initializes logging, settings, memory systems 3. Connects to Discord 4. Bot runs until Ctrl+C</p>"},{"location":"STARTUP_WALKTHROUGH/#decision-trees","title":"Decision Trees","text":""},{"location":"STARTUP_WALKTHROUGH/#docker-launch-decision-tree","title":"Docker Launch Decision Tree","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Does `docker` command exist?        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Yes          \u2502 No\n       \u25bc              \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502Continue\u2502    \u2502 ERROR: Install      \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 Docker Desktop      \u2502\n                \u2502 EXIT 1              \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Is daemon ready? (docker info)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Yes          \u2502 No\n       \u25bc              \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502Continue\u2502    \u2502 Is Docker.app running\u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 (pgrep -x \"Docker\")? \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n                       \u2502 Yes      \u2502 No\n                       \u25bc          \u25bc\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n               \u2502 Wait for  \u2502  \u2502 Launch Docker\u2502\n               \u2502 daemon    \u2502  \u2502 Desktop      \u2502\n               \u2502 90s max   \u2502  \u2502 (open -a)    \u2502\n               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n                                     \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 Wait 5s for  \u2502\n                              \u2502 process spawn\u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n                                     \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 Quick loop:  \u2502\n                              \u2502 4 x 5s = 20s \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n                                     \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 Extended:    \u2502\n                              \u2502 90s total    \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502 Ready?                  \u2502\n                        \u25bc                         \u25bc\n                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502Continue \u2502            \u2502 ERROR: Timed\u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502 out after   \u2502\n                                          \u2502 90 seconds  \u2502\n                                          \u2502 EXIT 1      \u2502\n                                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"STARTUP_WALKTHROUGH/#router-backend-selection-tree","title":"Router Backend Selection Tree","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Is ROUTER_BACKEND set in .env?     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Yes            \u2502 No\n       \u25bc                \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 Use it \u2502      \u2502 Prompt user:     \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502 1=Gemini 2=Ollama\u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u25bc                 \u25bc\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 User: 2  \u2502      \u2502 User: 1  \u2502\n            \u2502 or       \u2502      \u2502 or &lt;Enter\u2502\n            \u2502 &lt;invalid&gt;\u2502      \u2502 &gt;        \u2502\n            \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n                 \u2502                  \u2502\n                 \u25bc                  \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502 ROUTER_      \u2502    \u2502 ROUTER_     \u2502\n         \u2502 BACKEND=     \u2502    \u2502 BACKEND=    \u2502\n         \u2502 ollama       \u2502    \u2502 gemini      \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                   \u2502\n                \u2502                   \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n               \u2502 echo ROUTER_BACKEND\u2502\n               \u2502 to .env            \u2502\n               \u2502 (persist choice)   \u2502\n               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"STARTUP_WALKTHROUGH/#ollama-memory-management-tree","title":"Ollama Memory Management Tree","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ROUTER_BACKEND == \"ollama\"?           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Yes            \u2502 No\n       \u25bc                \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502Continue\u2502      \u2502 Skip all \u2502\n  \u2502 to     \u2502      \u2502 Ollama   \u2502\n  \u2502 Ollama \u2502      \u2502 phases   \u2502\n  \u2502 phases \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Check Docker memory vs requirement    \u2502\n\u2502 docker info | grep \"Total Memory\"     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                \u2502\n       \u2502 Sufficient     \u2502 Insufficient\n       \u25bc                \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502Continue\u2502      \u2502 Prompt user:         \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502 1. Auto-increase     \u2502\n                  \u2502 2. Smaller model     \u2502\n                  \u2502 3. Continue anyway   \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n             \u2502             \u2502             \u2502\n             \u25bc             \u25bc             \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 Call   \u2502   \u2502 rm      \u2502   \u2502Continue\u2502\n        \u2502increase\u2502   \u2502.ollama_ \u2502   \u2502(risky) \u2502\n        \u2502-docker-\u2502   \u2502assessed \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502memory  \u2502   \u2502         \u2502\n        \u2502.sh     \u2502   \u2502EXIT 0   \u2502\n        \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u25bc\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502 Backup JSON \u2502\n     \u2502 Update mem  \u2502\n     \u2502 Restart     \u2502\n     \u2502 Docker      \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Success?       \u2502\n    \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Continue\u2502      \u2502 ERROR    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502 Give user\u2502\n                \u2502 options  \u2502\n                \u2502 EXIT 1   \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"STARTUP_WALKTHROUGH/#timing-expectations","title":"Timing Expectations","text":""},{"location":"STARTUP_WALKTHROUGH/#first-run-ollama-no-containers","title":"First Run (Ollama, No Containers)","text":"Phase Task Time 1.1 Python check 1s 1.2 Docker launch (cold) 60s 1.3 .env validation 1s 2 Router selection (user) 10s 3 Venv + deps install 60s 4 Qdrant pull + start 30s 5 System assessment (user) 15s 6 Docker memory increase 60s 7 Ollama pull + start 40s 7 Model download (4.7GB) 300s 8 Summary 1s TOTAL ~9 minutes"},{"location":"STARTUP_WALKTHROUGH/#first-run-gemini-no-containers","title":"First Run (Gemini, No Containers)","text":"Phase Task Time 1-2 Validation + router 72s 3 Venv + deps 60s 4 Qdrant pull + start 30s 5-7 (Skipped - Gemini) 0s 8 Summary 1s TOTAL ~3 minutes"},{"location":"STARTUP_WALKTHROUGH/#subsequent-runs-warm","title":"Subsequent Runs (Warm)","text":"Phase Task Time 1 Validation (Docker warm) 5s 2 (Skipped - already set) 0s 3 Venv activate 2s 4 Qdrant start 3s 5 (Skipped - assessed) 0s 6 (Skipped - sufficient) 2s 7 Ollama start 5s 8 Summary 1s TOTAL ~18 seconds"},{"location":"STARTUP_WALKTHROUGH/#cold-docker-start-worst-case","title":"Cold Docker Start (Worst Case)","text":"Phase Task Time 1.2 Docker launch 90s 4 Qdrant first start 10s 7 Ollama first start 10s TOTAL ADDED +110s"},{"location":"STARTUP_WALKTHROUGH/#error-handling","title":"Error Handling","text":""},{"location":"STARTUP_WALKTHROUGH/#exit-codes","title":"Exit Codes","text":"Code Meaning Example Trigger 0 Success Normal completion 1 Fatal error Missing dependency, .env invalid, timeout"},{"location":"STARTUP_WALKTHROUGH/#error-categories","title":"Error Categories","text":""},{"location":"STARTUP_WALKTHROUGH/#1-missing-prerequisites","title":"1. Missing Prerequisites","text":"<p><pre><code>\u2717 Python 3.12+ required, found 3.11\n\u2139 Install with: brew install python@3.12\n</code></pre> Action: Install suggested package, re-run</p>"},{"location":"STARTUP_WALKTHROUGH/#2-configuration-errors","title":"2. Configuration Errors","text":"<p><pre><code>\u2717 Missing required environment variables: DISCORD_TOKEN GEMINI_API_KEY\n\u2139 Please add them to your .env file\n</code></pre> Action: Edit .env, add missing keys, re-run</p>"},{"location":"STARTUP_WALKTHROUGH/#3-docker-errors","title":"3. Docker Errors","text":"<p><pre><code>\u2717 Docker daemon did not become ready after 90 seconds\n\u2139 Check Docker Desktop status in menu bar and try again\n\u2139 You may need to restart Docker Desktop manually\n</code></pre> Action: - Check Docker Desktop icon in menu bar - Look for error messages in Docker Desktop GUI - Try manually restarting: Docker menu \u2192 Restart - Check Console.app for Docker crashes</p>"},{"location":"STARTUP_WALKTHROUGH/#4-container-errors","title":"4. Container Errors","text":"<p><pre><code>\u2717 Qdrant failed to start\n</code></pre> Action: - Check if port already in use: <code>lsof -i :6333</code> - Check container logs: <code>docker logs secureclaw-qdrant</code> - Remove and retry: <code>docker rm -f secureclaw-qdrant &amp;&amp; ./start.sh</code></p>"},{"location":"STARTUP_WALKTHROUGH/#5-model-download-errors","title":"5. Model Download Errors","text":"<p><pre><code>\u2717 Failed to download model 'qwen2.5:7b'\n\u2139 You can manually pull it later with: docker exec secureclaw-ollama ollama pull qwen2.5:7b\n\u26a0 Continuing anyway - the bot will fall back to Gemini if the model isn't available\n</code></pre> Action: - Script continues (non-fatal) - Bot uses Gemini for routing instead - Manually pull later when network is better - Or choose smaller model: <code>rm .ollama_assessed &amp;&amp; ./start.sh</code></p>"},{"location":"STARTUP_WALKTHROUGH/#environment-variables","title":"Environment Variables","text":""},{"location":"STARTUP_WALKTHROUGH/#required-must-be-in-env","title":"Required (Must be in .env)","text":"Variable Example Purpose <code>DISCORD_TOKEN</code> <code>MTA...</code> Discord bot authentication <code>GEMINI_API_KEY</code> <code>AIza...</code> Google Gemini API (embeddings, routing)"},{"location":"STARTUP_WALKTHROUGH/#optional-configuration","title":"Optional Configuration","text":"Variable Default Purpose <code>ROUTER_BACKEND</code> <code>gemini</code> Router: <code>gemini</code> or <code>ollama</code> <code>ANTHROPIC_API_KEY</code> <code>None</code> Claude for complex tasks <code>OPENAI_API_KEY</code> <code>None</code> GPT for complex tasks <code>ALLOWED_USER_IDS</code> <code>[]</code> Discord user ID allowlist <code>LOG_TO_FILE</code> <code>true</code> Enable file logging <code>LOG_DIRECTORY</code> <code>logs</code> Log file location"},{"location":"STARTUP_WALKTHROUGH/#ollama-specific","title":"Ollama-Specific","text":"Variable Default Set By Purpose <code>OLLAMA_HOST</code> <code>ollama</code> <code>start.sh</code> Ollama container host <code>OLLAMA_PORT</code> <code>11434</code> Manual Ollama API port <code>OLLAMA_ROUTER_MODEL</code> <code>llama3.1:8b</code> <code>assess-system.py</code> Model to use <code>OLLAMA_DOCKER_MEMORY</code> <code>8</code> <code>assess-system.py</code> Docker RAM (GB) <code>OLLAMA_TIMEOUT</code> <code>30</code> Manual API timeout (seconds)"},{"location":"STARTUP_WALKTHROUGH/#auto-configured","title":"Auto-Configured","text":"Variable When Set By Whom <code>ROUTER_BACKEND</code> Phase 2 (first run) User prompt \u2192 <code>start.sh</code> <code>OLLAMA_HOST</code> Phase 7 (if <code>ollama</code>) <code>start.sh</code> (sets to <code>localhost</code>) <code>OLLAMA_ROUTER_MODEL</code> Phase 5 (if accepted) <code>assess-system.py --update-env</code> <code>OLLAMA_DOCKER_MEMORY</code> Phase 5 (if accepted) <code>assess-system.py --update-env</code>"},{"location":"STARTUP_WALKTHROUGH/#appendix-script-structure","title":"Appendix: Script Structure","text":""},{"location":"STARTUP_WALKTHROUGH/#helper-functions-lines-11-39","title":"Helper Functions (Lines 11-39)","text":"<pre><code>print_success() {\n    echo -e \"${GREEN}\u2713${NC} $1\"\n}\n\nprint_error() {\n    echo -e \"${RED}\u2717${NC} $1\"\n}\n\nprint_warning() {\n    echo -e \"${YELLOW}\u26a0${NC} $1\"\n}\n\nprint_info() {\n    echo -e \"${BLUE}\u2139${NC} $1\"\n}\n\nprint_header() {\n    echo -e \"${BLUE}\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550${NC}\"\n    echo -e \"${BLUE}  $1${NC}\"\n    echo -e \"${BLUE}\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550${NC}\"\n}\n\ncommand_exists() {\n    command -v \"$1\" &gt;/dev/null 2&gt;&amp;1\n}\n</code></pre> <p>Why standardize output? - Consistent UX - Colored output for clarity - Easy to scan for errors (red \u2717) vs success (green \u2713)</p>"},{"location":"STARTUP_WALKTHROUGH/#error-handling-pattern","title":"Error Handling Pattern","text":"<pre><code>set -e  # Exit on any error\n\n# For non-fatal errors:\nif ! some_command; then\n    print_warning \"Command failed, continuing...\"\nfi\n\n# For fatal errors:\nif ! critical_command; then\n    print_error \"Critical failure\"\n    print_info \"How to fix: ...\"\n    exit 1\nfi\n</code></pre>"},{"location":"STARTUP_WALKTHROUGH/#summary","title":"Summary","text":"<p>The startup script handles: - \u2705 Environment validation (Python, Docker, .env) - \u2705 User choices (router backend, model selection) - \u2705 Dependency management (venv, pip packages) - \u2705 Container orchestration (Qdrant, Ollama) - \u2705 Docker memory automation (detect, prompt, increase) - \u2705 Model downloads (Ollama pull) - \u2705 Clear feedback (colored output, progress messages) - \u2705 Graceful failures (timeouts, fallbacks, suggestions)</p> <p>First run: 3-9 minutes (depending on backend and network)</p> <p>Subsequent runs: 10-20 seconds (all containers already exist)</p> <p>User interaction points: 1. Router backend choice (first run) 2. Model recommendation acceptance (Ollama first run) 3. Docker memory increase approval (if needed)</p> <p>Exit points: - Fatal: Missing Python, Docker, .env keys - Soft: User chooses smaller model (can re-run immediately)</p>"},{"location":"TESTING/","title":"Testing Guide","text":"<p>Complete guide to SecureClaw's three-layer testing approach.</p>"},{"location":"TESTING/#test-types","title":"Test Types","text":"<p>SecureClaw uses a three-layer testing pyramid for comprehensive coverage:</p> <ol> <li>Unit Tests - Fast, isolated tests with mocked dependencies (Discord bot, Agent, Router, Memory)</li> <li>Integration Tests - Full stack tests with Docker services (bypasses Discord API)</li> <li>Discord E2E Tests - True end-to-end tests using real Discord API</li> <li>Pre-commit Hooks - Automated linting and type checking before commits</li> </ol> <pre><code>              \ud83d\udd3a\n           Discord E2E\n        (Real Discord API)\n      Slowest | Most Realistic\n    \u2571                           \u2572\n   \u2571   Integration Tests          \u2572\n  \u2571 (Docker + Services + Agent)    \u2572\n \u2571    Medium Speed | Component      \u2572\n\u2571          Integration               \u2572\n\u2572_______________________________________\u2571\n \u2572           Unit Tests               \u2571\n  \u2572   (Mocked, Fast Feedback)        \u2571\n   \u2572________________________________\u2571\n    Fastest | Most Isolated | Largest\n\n---\n\n## Unit Tests\n\n### Running Unit Tests\n\n```bash\n# Run all unit tests (excluding integration tests)\npytest -m \"not integration\"\n\n# Run with coverage\npytest --cov=src/secureclaw --cov-report=html\n\n# Run specific test file\npytest tests/test_agent_core.py\n\n# Run with verbose output\npytest -v\n</code></pre>"},{"location":"TESTING/#writing-unit-tests","title":"Writing Unit Tests","text":"<p>Unit tests go in <code>tests/</code> directory:</p> <pre><code>import pytest\nfrom secureclaw.agent.core import Agent\n\ndef test_agent_initialization():\n    \"\"\"Test that agent initializes correctly.\"\"\"\n    agent = Agent(memory=mock_memory)\n    assert agent is not None\n</code></pre>"},{"location":"TESTING/#integration-tests","title":"Integration Tests","text":"<p>Integration tests start the entire Docker environment and simulate real user interactions.</p>"},{"location":"TESTING/#prerequisites","title":"Prerequisites","text":"<ol> <li>Docker must be running</li> <li>Environment variables must be set in <code>.env</code>:</li> <li><code>GEMINI_API_KEY</code> (required)</li> <li><code>DISCORD_TOKEN</code> (required)</li> <li>Other API keys (optional, but recommended for full testing)</li> </ol>"},{"location":"TESTING/#running-integration-tests","title":"Running Integration Tests","text":"<pre><code># Easy way - use the provided script\n./scripts/run-integration-tests.sh\n\n# Manual way\npytest tests/integration/test_e2e.py -v -s -m integration\n</code></pre>"},{"location":"TESTING/#what-integration-tests-do","title":"What Integration Tests Do","text":"<ol> <li>Start Docker Compose with test project name</li> <li>Wait for services to be healthy (Qdrant, SecureClaw)</li> <li>Run test scenarios:</li> <li>Simple questions</li> <li>Memory storage and recall</li> <li>Complex tasks</li> <li>Conversation context</li> <li>Help commands</li> <li>Service health checks</li> <li>Clean up - Stop and remove containers</li> </ol>"},{"location":"TESTING/#integration-test-output","title":"Integration Test Output","text":"<pre><code>\ud83d\udc33 Starting Docker Compose environment...\n\u23f3 Waiting for services to be healthy...\n\u2705 Qdrant is healthy\n\u2705 SecureClaw is running\n\ntest_simple_question PASSED\ntest_memory_store_and_recall PASSED\ntest_complex_task PASSED\ntest_conversation_context PASSED\ntest_help_command PASSED\ntest_docker_services_running PASSED\ntest_qdrant_collections_exist PASSED\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  All Integration Tests Passed! \u2713\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n</code></pre>"},{"location":"TESTING/#skipping-integration-tests","title":"Skipping Integration Tests","text":"<p>Integration tests can be slow (2-3 minutes). To skip them:</p> <pre><code># Skip in pytest\npytest -m \"not integration\"\n\n# Skip via environment variable\nexport SKIP_INTEGRATION_TESTS=true\npytest\n</code></pre>"},{"location":"TESTING/#discord-e2e-tests","title":"Discord E2E Tests","text":"<p>NEW: True end-to-end tests that send real messages through Discord API.</p> <p>Location: <code>tests/integration/test_discord_e2e.py</code> What: Tests real Discord bot message handling with actual Discord API Speed: Fast (~1 minute once bot is running) Marker: <code>discord_e2e</code></p>"},{"location":"TESTING/#whats-different-from-integration-tests","title":"What's Different from Integration Tests?","text":"Feature Integration Tests Discord E2E Tests Discord API \u274c Mocked (MockDiscordBot) \u2705 Real Discord messages Agent Logic \u2705 Full stack tested \u2705 Full stack tested Services \u2705 Qdrant + Ollama \u2705 Qdrant + Ollama Use Case Verify agent/router/memory Verify Discord bot integration"},{"location":"TESTING/#setup-requirements","title":"Setup Requirements","text":""},{"location":"TESTING/#1-create-test-bot-in-discord-developer-portal","title":"1. Create Test Bot in Discord Developer Portal","text":"<ol> <li>Go to https://discord.com/developers/applications</li> <li>Click \"New Application\" \u2192 Name: \"SecureClaw Test Bot\"</li> <li>Navigate to \"Bot\" tab</li> <li>Click \"Reset Token\" \u2192 Copy token (you'll need this)</li> <li>Enable Required Privileged Gateway Intents:</li> <li>\u2705 Message Content Intent - Allows bot to read message content</li> <li>\u2705 Server Members Intent - Allows bot to see member information</li> <li>Configure Bot Permissions:</li> <li>\u2705 View Channels - See channels in the server</li> <li>\u2705 Send Messages - Send responses to users</li> <li>\u2705 Read Message History - Read previous messages</li> <li>\u2705 Use Application Commands - Enable slash commands</li> <li>\u2705 Mention Everyone, Here, and All Roles - For @mentions in responses</li> <li>Save changes</li> </ol>"},{"location":"TESTING/#2-create-test-discord-server-channel","title":"2. Create Test Discord Server &amp; Channel","text":"<ol> <li>Create a new Discord server (or use existing test server)</li> <li>Generate Bot Invite URL (choose one method):</li> </ol> <p>Method A - Manual URL: <pre><code>https://discord.com/api/oauth2/authorize?client_id=YOUR_CLIENT_ID&amp;permissions=274878285888&amp;scope=bot%20applications.commands\n</code></pre>    - Replace <code>YOUR_CLIENT_ID</code> with your bot's Application ID (from General Information tab)    - <code>permissions=274878285888</code> = View Channels + Send Messages + Read Message History + Use Application Commands + Mention Everyone</p> <p>Method B - Discord Developer Portal:    - In Discord Developer Portal, go to \"OAuth2\" \u2192 \"URL Generator\"    - Select scopes: <code>bot</code> and <code>applications.commands</code>    - Select bot permissions:      - View Channels      - Send Messages      - Read Message History      - Use Application Commands      - Mention Everyone, Here, and All Roles    - Copy generated URL at bottom of page</p> <ol> <li>Invite bot to test server using the generated URL</li> <li>Create a dedicated test channel (e.g., <code>#bot-testing</code>)</li> <li>Get Channel ID:</li> <li>Enable Developer Mode in Discord: Settings \u2192 Advanced \u2192 Developer Mode</li> <li>Right-click the test channel \u2192 \"Copy Channel ID\"</li> </ol>"},{"location":"TESTING/#3-configure-environment-variables","title":"3. Configure Environment Variables","text":"<p>Add to your <code>.env</code> file:</p> <pre><code># Discord E2E Testing (separate from main bot)\nTEST_DISCORD_BOT_TOKEN=your_test_bot_token_here\nTEST_DISCORD_CHANNEL_ID=1234567890123456789\n\n# Allow bot-to-bot messages (required for E2E tests)\nALLOW_BOT_MESSAGES=true\n</code></pre> <p>\u26a0\ufe0f Important: - Use a separate test bot, not your production bot! - Never commit <code>TEST_DISCORD_BOT_TOKEN</code> to git - Test bot should only have access to test servers - <code>ALLOW_BOT_MESSAGES=true</code> is required for Discord E2E tests to work   - By default, SecureClaw ignores messages from other bots (to prevent bot-to-bot spam)   - Setting this to <code>true</code> allows the test bot to send messages to your production bot   - Keep this <code>false</code> in production unless you specifically need bot-to-bot communication</p>"},{"location":"TESTING/#running-discord-e2e-tests","title":"Running Discord E2E Tests","text":"<pre><code># Easy way - use the provided script\n./scripts/run-discord-e2e-tests.sh\n\n# Manual way\npytest tests/integration/test_discord_e2e.py -v -s -m discord_e2e\n\n# Skip Discord E2E tests (if not configured)\npytest tests/ -m \"not discord_e2e\" -v\n</code></pre>"},{"location":"TESTING/#what-discord-e2e-tests-cover","title":"What Discord E2E Tests Cover","text":"<ol> <li>\u2705 Message Handling - Bot receives and processes messages</li> <li>\u2705 Response Generation - Bot sends responses back to Discord</li> <li>\u2705 Memory Operations - Store and recall through Discord</li> <li>\u2705 Mentions - Bot responds to @mentions</li> <li>\u2705 Slash Commands - Commands registered and functional</li> <li>\u2705 Complex Queries - Multi-turn conversations</li> </ol>"},{"location":"TESTING/#example-discord-e2e-test","title":"Example Discord E2E Test","text":"<pre><code>@pytest.mark.discord_e2e\n@pytest.mark.asyncio\nasync def test_bot_responds_to_message(discord_test_client):\n    \"\"\"Test bot responds to a real Discord message.\"\"\"\n    # Send actual message through Discord API\n    test_message = await discord_test_client.send_message(\n        \"Hello SecureClaw, what is 2+2?\"\n    )\n\n    # Wait for bot response (real Discord event)\n    response = await discord_test_client.wait_for_bot_response(\n        test_message, timeout=30.0\n    )\n\n    assert response is not None\n    assert len(response.content) &gt; 0\n\n    # Cleanup test messages\n    await discord_test_client.delete_message(test_message)\n    await discord_test_client.delete_message(response)\n</code></pre>"},{"location":"TESTING/#troubleshooting-discord-e2e-tests","title":"Troubleshooting Discord E2E Tests","text":"<p>Error: <code>TEST_DISCORD_BOT_TOKEN not set</code> <pre><code># Add to .env\necho \"TEST_DISCORD_BOT_TOKEN=your_token\" &gt;&gt; .env\necho \"TEST_DISCORD_CHANNEL_ID=123456789\" &gt;&gt; .env\n</code></pre></p> <p>Error: Bot not responding <pre><code># Check bot is online in Discord\n# Check bot logs\ndocker logs secureclaw-bot\n</code></pre></p> <p>Verify bot has required permissions in test channel: 1. Right-click test channel \u2192 \"Edit Channel\" \u2192 \"Permissions\" 2. Find your test bot in the permissions list 3. Ensure these permissions are enabled (green checkmarks):    - \u2705 View Channels    - \u2705 Send Messages    - \u2705 Read Message History    - \u2705 Use Application Commands 4. If permissions are missing, add them and try again</p> <p>Verify bot intents are enabled: 1. Go to Discord Developer Portal \u2192 Your Application \u2192 Bot 2. Scroll to \"Privileged Gateway Intents\" 3. Ensure both are enabled:    - \u2705 Message Content Intent    - \u2705 Server Members Intent 4. Save changes and restart bot if you made changes</p> <p>Error: Timeout waiting for response <pre><code># Possible causes:\n# 1. Bot not in test server - reinvite bot\n# 2. Bot lacks permissions - check channel permissions\n# 3. Rate limiting - wait 60 seconds between test runs\n# 4. Discord API issues - check https://discordstatus.com\n</code></pre></p>"},{"location":"TESTING/#required-permissions-summary","title":"Required Permissions Summary","text":"<p>Privileged Gateway Intents (Bot tab in Developer Portal): | Intent | Required | Purpose | |--------|----------|---------| | Message Content Intent | \u2705 Yes | Read message content for processing | | Server Members Intent | \u2705 Yes | Access member information |</p> <p>Bot Permissions (OAuth2 \u2192 URL Generator): | Permission | Required | Purpose | |-----------|----------|---------| | View Channels | \u2705 Yes | See test channel | | Send Messages | \u2705 Yes | Send responses | | Read Message History | \u2705 Yes | Read previous messages for context | | Use Application Commands | \u2705 Yes | Enable slash commands (/ask, /remember, etc.) | | Mention Everyone, Here, and All Roles | \u26a0\ufe0f Optional | Allow @mentions in responses |</p> <p>Permission Integer for OAuth URL: <code>274878285888</code></p>"},{"location":"TESTING/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Git hooks run automatically before commits and pushes.</p>"},{"location":"TESTING/#setup","title":"Setup","text":"<pre><code>./scripts/setup-git-hooks.sh\n</code></pre>"},{"location":"TESTING/#what-runs-on-commit","title":"What Runs on Commit","text":"<p>Pre-commit hook runs: - Ruff - Linting and formatting - Mypy - Type checking - Bandit - Security scanning - YAML/TOML checks - Trailing whitespace removal - Private key detection</p>"},{"location":"TESTING/#what-runs-on-push","title":"What Runs on Push","text":"<p>Pre-push hook runs: - All pre-commit checks - Unit tests (excluding integration)</p>"},{"location":"TESTING/#bypass-hooks-not-recommended","title":"Bypass Hooks (Not Recommended)","text":"<pre><code># Skip pre-commit hook\ngit commit --no-verify -m \"message\"\n\n# Skip pre-push hook\ngit push --no-verify\n</code></pre>"},{"location":"TESTING/#continuous-integration-github-actions","title":"Continuous Integration (GitHub Actions)","text":"<p>When you push to GitHub, the full CI pipeline runs:</p> <ol> <li>Lint &amp; Format (Ruff)</li> <li>Type Check (Mypy)</li> <li>Security Scan (Bandit)</li> <li>Unit Tests (Python 3.12 &amp; 3.13)</li> <li>Docker Build (Verify images build)</li> <li>Integration Tests (MockDiscordBot + full agent stack)</li> <li>Discord E2E Tests (Real Discord API - only if secrets configured)</li> </ol> <p>See .github/workflows/ci.yml for details.</p>"},{"location":"TESTING/#github-actions-secrets-setup","title":"GitHub Actions Secrets Setup","text":"<p>To enable Discord E2E tests in CI, add these secrets to your GitHub repository:</p> <ol> <li>Go to your repository on GitHub</li> <li>Navigate to Settings \u2192 Secrets and variables \u2192 Actions</li> <li>Click New repository secret and add:</li> </ol> Secret Name Description Example <code>DISCORD_TOKEN</code> Main bot token (production) <code>MTIzNDU2...</code> <code>GEMINI_API_KEY</code> Google AI API key <code>AIza...</code> <code>TEST_DISCORD_BOT_TOKEN</code> Test bot token (separate bot) <code>MTIzNDU2...</code> <code>TEST_DISCORD_CHANNEL_ID</code> Test channel ID <code>1234567890123456789</code> <code>ANTHROPIC_API_KEY</code> Anthropic API key (optional) <code>sk-ant-api03-...</code> <code>OPENAI_API_KEY</code> OpenAI API key (optional) <code>sk-...</code> <p>Important: - Use a separate test bot for <code>TEST_DISCORD_BOT_TOKEN</code>, not your production bot - Create a dedicated test server/channel for <code>TEST_DISCORD_CHANNEL_ID</code> - If <code>TEST_DISCORD_BOT_TOKEN</code> or <code>TEST_DISCORD_CHANNEL_ID</code> are not set, Discord E2E tests will be gracefully skipped - Test bot must have same permissions as production bot:   - Privileged Intents: Message Content + Server Members   - Bot Permissions: View Channels, Send Messages, Read Message History, Use Application Commands   - See Required Permissions Summary below for details</p>"},{"location":"TESTING/#ci-pipeline-behavior","title":"CI Pipeline Behavior","text":"<p>Discord E2E Tests: - \u2705 Run: If both <code>TEST_DISCORD_BOT_TOKEN</code> and <code>TEST_DISCORD_CHANNEL_ID</code> secrets are configured - \u23ed\ufe0f Skip: If either secret is missing (graceful skip, CI still passes) - \ud83d\udeab Fail: If tests run but fail (e.g., bot doesn't respond, assertions fail)</p> <p>Integration Tests: - \u2705 Run: Always (uses MockDiscordBot, doesn't require real Discord API) - \u23ed\ufe0f Skip: Only if commit message contains <code>[skip integration]</code></p>"},{"location":"TESTING/#test-coverage","title":"Test Coverage","text":""},{"location":"TESTING/#generate-coverage-report","title":"Generate Coverage Report","text":"<pre><code># HTML report\npytest --cov=src/secureclaw --cov-report=html\nopen htmlcov/index.html\n\n# Terminal report\npytest --cov=src/secureclaw --cov-report=term-missing\n\n# XML report (for CI)\npytest --cov=src/secureclaw --cov-report=xml\n</code></pre>"},{"location":"TESTING/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Minimum: 70% overall coverage</li> <li>Target: 85%+ for core modules</li> <li>Critical paths: 95%+ (authentication, security, data handling)</li> </ul>"},{"location":"TESTING/#debugging-test-failures","title":"Debugging Test Failures","text":""},{"location":"TESTING/#view-integration-test-logs","title":"View Integration Test Logs","text":"<p>If integration tests fail, check Docker logs:</p> <pre><code># View SecureClaw logs\ndocker compose -p secureclaw-test logs secureclaw\n\n# View Qdrant logs\ndocker compose -p secureclaw-test logs qdrant\n\n# Follow logs in real-time\ndocker compose -p secureclaw-test logs -f\n</code></pre>"},{"location":"TESTING/#common-issues","title":"Common Issues","text":"<p>Issue: \"Services failed to become healthy\" - Solution: Check if ports 6333 or 8000 are already in use - Solution: Verify .env has valid API keys - Solution: Increase timeout in test (default 120s)</p> <p>Issue: \"Missing required environment variables\" - Solution: Copy <code>.env.example</code> to <code>.env</code> and fill in values</p> <p>Issue: \"Docker is not running\" - Solution: Start Docker Desktop</p> <p>Issue: Tests pass but bot doesn't respond in Discord - Solution: Integration tests use mock bot, not real Discord - Solution: For real Discord testing, use <code>./start.sh</code> instead</p>"},{"location":"TESTING/#test-markers","title":"Test Markers","text":"<p>Use pytest markers to run specific test categories:</p> <pre><code># Run only integration tests\npytest -m integration\n\n# Run everything except integration tests\npytest -m \"not integration\"\n\n# Run slow tests\npytest -m slow\n\n# Run fast tests only\npytest -m \"not slow and not integration\"\n</code></pre>"},{"location":"TESTING/#available-markers","title":"Available Markers","text":"<ul> <li><code>integration</code> - Service integration tests with Docker (MockDiscordBot)</li> <li><code>discord_e2e</code> - True E2E tests with real Discord API</li> <li><code>slow</code> - Tests that take &gt;5 seconds</li> <li>Custom markers can be added in <code>pyproject.toml</code></li> </ul> <pre><code># Run only Discord E2E tests\npytest -m discord_e2e\n\n# Run everything except Discord E2E\npytest -m \"not discord_e2e\"\n\n# Run integration but not Discord E2E\npytest -m \"integration and not discord_e2e\"\n</code></pre>"},{"location":"TESTING/#best-practices","title":"Best Practices","text":"<ol> <li>Run unit tests frequently during development</li> <li>Run integration tests before creating PRs</li> <li>Don't commit with failing tests</li> <li>Don't bypass hooks without good reason</li> <li>Keep tests fast - mock external APIs in unit tests</li> <li>Add tests for new features</li> <li>Update tests when changing behavior</li> </ol>"},{"location":"TESTING/#quick-reference","title":"Quick Reference","text":"<pre><code># Fast feedback loop during development\npytest -m \"not integration\" --tb=short\n\n# Full local test suite\npytest\n\n# Pre-commit check (manual)\npre-commit run --all-files\n\n# Integration tests\n./scripts/run-integration-tests.sh\n\n# Coverage report\npytest --cov=src/secureclaw --cov-report=html &amp;&amp; open htmlcov/index.html\n</code></pre>"},{"location":"TESTING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"TESTING/#test-discovery-issues","title":"Test Discovery Issues","text":"<p>If pytest can't find tests:</p> <pre><code># Ensure PYTHONPATH includes src/\nexport PYTHONPATH=\"${PWD}/src:${PYTHONPATH}\"\n\n# Or use pytest.ini/pyproject.toml configuration\n</code></pre>"},{"location":"TESTING/#import-errors-in-tests","title":"Import Errors in Tests","text":"<pre><code># Install in editable mode\npip install -e .\n\n# Or use test dependencies\npip install -r requirements-dev.txt\n</code></pre>"},{"location":"TESTING/#docker-cleanup","title":"Docker Cleanup","text":"<p>If test containers don't clean up:</p> <pre><code># Manual cleanup\ndocker compose -p secureclaw-test down -v\n\n# Nuclear option (removes ALL stopped containers)\ndocker system prune -a\n</code></pre>"},{"location":"TESTING/#writing-new-tests","title":"Writing New Tests","text":""},{"location":"TESTING/#unit-test-template","title":"Unit Test Template","text":"<pre><code>\"\"\"Tests for new feature.\"\"\"\n\nimport pytest\nfrom secureclaw.feature import NewFeature\n\n\n@pytest.fixture\ndef feature():\n    \"\"\"Fixture for feature instance.\"\"\"\n    return NewFeature()\n\n\ndef test_new_feature(feature):\n    \"\"\"Test new feature behavior.\"\"\"\n    result = feature.do_something()\n    assert result == expected\n</code></pre>"},{"location":"TESTING/#integration-test-template","title":"Integration Test Template","text":"<pre><code>\"\"\"Integration test for new feature.\"\"\"\n\nimport pytest\n\n\n@pytest.mark.asyncio\n@pytest.mark.integration\nasync def test_new_feature_e2e(mock_bot):\n    \"\"\"Test new feature end-to-end.\"\"\"\n    response = await mock_bot.simulate_message(\"test message\")\n    assert \"expected\" in response.lower()\n</code></pre>"},{"location":"TESTING/#related-documentation","title":"Related Documentation","text":"<ul> <li>CI/CD Pipeline - GitHub Actions workflow</li> <li>Contributing - Development guidelines</li> <li>Architecture - System design</li> </ul>"},{"location":"TROUBLESHOOTING/","title":"SecureClaw Troubleshooting Guide","text":"<p>Common issues and their solutions for running SecureClaw.</p>"},{"location":"TROUBLESHOOTING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Discord Errors</li> <li>Configuration Issues</li> <li>Docker Issues</li> <li>Ollama Issues</li> <li>Qdrant Connection Issues</li> <li>Python Version Issues</li> <li>API Key Issues</li> <li>Performance Issues</li> </ul>"},{"location":"TROUBLESHOOTING/#discord-errors","title":"Discord Errors","text":""},{"location":"TROUBLESHOOTING/#error-privilegedintentsrequired","title":"Error: <code>PrivilegedIntentsRequired</code>","text":"<p>Full Error: <pre><code>discord.errors.PrivilegedIntentsRequired: Shard ID None is requesting privileged intents\nthat have not been explicitly enabled in the developer portal.\n</code></pre></p> <p>Cause: The bot needs the Message Content Intent to read messages, but it's not enabled in Discord.</p> <p>Solution: 1. Go to https://discord.com/developers/applications 2. Select your bot application 3. Go to Bot tab 4. Scroll to Privileged Gateway Intents 5. Enable \"MESSAGE CONTENT INTENT\" (toggle it ON) 6. Click Save Changes 7. Restart the bot: <code>./stop.sh &amp;&amp; ./start.sh</code></p> <p>Why Required: Discord requires explicit permission to read message content for privacy/security.</p>"},{"location":"TROUBLESHOOTING/#bot-not-responding-in-server","title":"Bot Not Responding in Server","text":"<p>Symptoms: - Bot is online but doesn't respond to mentions - Slash commands work but messages don't</p> <p>Solutions:</p> <ol> <li>Check Bot Permissions:</li> <li>Bot needs <code>Send Messages</code>, <code>Read Messages</code>, <code>Embed Links</code> permissions</li> <li> <p>Right-click the bot in server \u2192 Manage \u2192 Check role permissions</p> </li> <li> <p>Verify Message Content Intent:</p> </li> <li> <p>See PrivilegedIntentsRequired above</p> </li> <li> <p>Check if Bot is Being Mentioned:</p> </li> <li> <p>Bot only responds to DMs or when mentioned: <code>@BotName your message</code></p> </li> <li> <p>Check Allowlist:</p> </li> <li>If <code>ALLOWED_USER_IDS</code> is set in <code>.env</code>, your user ID must be included</li> <li>To allow all users: <code>ALLOWED_USER_IDS=</code> (leave empty)</li> </ol>"},{"location":"TROUBLESHOOTING/#slash-commands-not-appearing","title":"Slash Commands Not Appearing","text":"<p>Symptoms: - Can't see <code>/ask</code>, <code>/remember</code>, <code>/search</code> commands</p> <p>Solutions:</p> <ol> <li>Wait for Sync:</li> <li>Commands can take up to 1 hour to appear globally</li> <li> <p>Restart Discord app to force refresh</p> </li> <li> <p>Check Bot Scope:</p> </li> <li>When you invited the bot, did you select <code>applications.commands</code> scope?</li> <li> <p>If not, generate new invite URL with both <code>bot</code> and <code>applications.commands</code></p> </li> <li> <p>Reinvite Bot:</p> </li> <li>Go to OAuth2 \u2192 URL Generator in Discord Developer Portal</li> <li>Select: <code>bot</code> + <code>applications.commands</code></li> <li> <p>Use new URL to invite bot</p> </li> <li> <p>Check Logs: <pre><code># Look for \"commands_synced\" message\n./status.sh\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#configuration-issues","title":"Configuration Issues","text":""},{"location":"TROUBLESHOOTING/#error-error-parsing-value-for-field-allowed_user_ids","title":"Error: <code>error parsing value for field \"allowed_user_ids\"</code>","text":"<p>Full Error: <pre><code>pydantic_settings.sources.SettingsError: error parsing value for field \"allowed_user_ids\"\n</code></pre></p> <p>Cause: Invalid format for <code>ALLOWED_USER_IDS</code> in <code>.env</code> file.</p> <p>Solution: <pre><code># Correct formats:\nALLOWED_USER_IDS=                        # Allow all users (empty)\nALLOWED_USER_IDS=123456789               # Single user\nALLOWED_USER_IDS=123456789,987654321     # Multiple users (comma-separated, no spaces)\n\n# Wrong formats:\nALLOWED_USER_IDS=123456789, 987654321    # Extra spaces after comma\nALLOWED_USER_IDS=[123456789]             # JSON format (not supported)\n</code></pre></p> <p>Get Your Discord User ID: 1. Enable Developer Mode in Discord: Settings \u2192 Advanced \u2192 Developer Mode 2. Right-click your username anywhere 3. Select \"Copy User ID\" 4. Paste into <code>.env</code>: <code>ALLOWED_USER_IDS=your_id_here</code></p>"},{"location":"TROUBLESHOOTING/#missing-environment-variables","title":"Missing Environment Variables","text":"<p>Error: <pre><code>Field required [type=missing]\n</code></pre></p> <p>Solution:</p> <ol> <li>Check Required Variables:</li> <li><code>DISCORD_TOKEN</code> (required)</li> <li> <p><code>GEMINI_API_KEY</code> (required)</p> </li> <li> <p>Optional Variables:</p> </li> <li><code>ANTHROPIC_API_KEY</code> (for Claude)</li> <li><code>OPENAI_API_KEY</code> (for GPT-4)</li> <li><code>ALLOWED_USER_IDS</code> (defaults to allow all)</li> <li><code>QDRANT_HOST</code> (defaults to \"qdrant\")</li> <li> <p><code>QDRANT_PORT</code> (defaults to 6333)</p> </li> <li> <p>Verify <code>.env</code> File Exists: <pre><code>ls -la .env\n# If missing:\ncp .env.example .env\n</code></pre></p> </li> <li> <p>Check for Trailing Spaces: <pre><code># Bad:\nDISCORD_TOKEN=abc123\n\n# Good:\nDISCORD_TOKEN=abc123\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#qdrant-connection-issues","title":"Qdrant Connection Issues","text":""},{"location":"TROUBLESHOOTING/#error-connection-refused-to-qdrant","title":"Error: Connection Refused to Qdrant","text":"<p>Full Error: <pre><code>ConnectionRefusedError: [Errno 61] Connection refused\nhttpcore._exceptions.ConnectError: [Errno 61] Connection refused\n</code></pre></p> <p>Cause: Bot can't connect to Qdrant vector database.</p> <p>Solutions:</p> <ol> <li> <p>Check Qdrant is Running: <pre><code>docker ps | grep qdrant\n# Should show secureclaw-qdrant running\n</code></pre></p> </li> <li> <p>Start Qdrant if Stopped: <pre><code>docker start secureclaw-qdrant\n# Or use the start script:\n./start.sh\n</code></pre></p> </li> <li> <p>Check <code>QDRANT_HOST</code> Setting:</p> </li> </ol> <p>For Local Development (./start.sh): <pre><code># In .env:\nQDRANT_HOST=localhost\nQDRANT_PORT=6333\n</code></pre></p> <p>For Docker Compose: <pre><code># In .env:\nQDRANT_HOST=qdrant\nQDRANT_PORT=6333\n</code></pre></p> <ol> <li> <p>Verify Qdrant Health: <pre><code>curl http://localhost:6333/healthz\n# Should return: healthy\n</code></pre></p> </li> <li> <p>Check Port Availability: <pre><code>lsof -i :6333\n# Should show Docker using port 6333\n</code></pre></p> </li> <li> <p>Restart Qdrant: <pre><code>docker restart secureclaw-qdrant\n# Wait 10 seconds\ncurl http://localhost:6333/healthz\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#qdrant-data-persistence","title":"Qdrant Data Persistence","text":"<p>Symptoms: - Bot loses all memories after restart - Collections disappear</p> <p>Cause: Qdrant data not being persisted to disk.</p> <p>Solution:</p> <ol> <li> <p>Check Volume Mount: <pre><code>docker inspect secureclaw-qdrant | grep -A 5 Mounts\n# Should show volume mounted to /qdrant/storage\n</code></pre></p> </li> <li> <p>Verify Data Directory: <pre><code>ls -la qdrant_storage/\n# Should contain Qdrant database files\n</code></pre></p> </li> <li> <p>Recreate with Proper Volume: <pre><code>docker stop secureclaw-qdrant\ndocker rm secureclaw-qdrant\n./start.sh  # Will recreate with volume\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#python-version-issues","title":"Python Version Issues","text":""},{"location":"TROUBLESHOOTING/#error-package-requires-a-different-python","title":"Error: <code>Package requires a different Python</code>","text":"<p>Full Error: <pre><code>ERROR: Package 'secureclaw' requires a different Python: 3.11.6 not in '&gt;=3.12'\n</code></pre></p> <p>Cause: SecureClaw requires Python 3.12+, but you have an older version.</p> <p>Solutions:</p> <ol> <li> <p>Install Python 3.12+ (macOS with Homebrew): <pre><code>brew install python@3.12\n</code></pre></p> </li> <li> <p>Verify Installation: <pre><code>python3.12 --version\n# Should show: Python 3.12.x\n</code></pre></p> </li> <li> <p>Recreate Virtual Environment: <pre><code>rm -rf .venv\npython3.12 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\npip install -e .\n</code></pre></p> </li> <li> <p>Use start.sh (Automatic): <pre><code>./start.sh\n# Automatically finds Python 3.12+\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#multiple-python-versions","title":"Multiple Python Versions","text":"<p>Symptoms: - <code>python3 --version</code> shows old version - But <code>python3.12</code> exists</p> <p>Solution: The start script handles this automatically. If you need to manually use Python 3.12:</p> <pre><code># Always use explicit version:\npython3.12 -m venv .venv\nsource .venv/bin/activate\n\n# Or use the start script:\n./start.sh\n</code></pre>"},{"location":"TROUBLESHOOTING/#api-key-issues","title":"API Key Issues","text":""},{"location":"TROUBLESHOOTING/#invalid-discord-token","title":"Invalid Discord Token","text":"<p>Error: <pre><code>discord.errors.LoginFailure: Improper token has been passed\n</code></pre></p> <p>Solutions:</p> <ol> <li>Regenerate Token:</li> <li>Go to Discord Developer Portal \u2192 Bot tab</li> <li>Click \"Reset Token\"</li> <li>Copy new token immediately</li> <li> <p>Update <code>.env</code>: <code>DISCORD_TOKEN=new_token_here</code></p> </li> <li> <p>Check for Extra Spaces: <pre><code># Bad:\nDISCORD_TOKEN= abc123\nDISCORD_TOKEN=abc123\n\n# Good:\nDISCORD_TOKEN=abc123\n</code></pre></p> </li> <li> <p>Verify Token Format:</p> </li> <li>Three parts separated by dots (Base64-encoded)</li> <li>Format: <code>&lt;FIRST_PART&gt;.&lt;SECOND_PART&gt;.&lt;THIRD_PART&gt;</code></li> <li>Each part contains alphanumeric characters, hyphens, and underscores</li> <li>Real tokens are much longer (70+ characters total)</li> <li>No quotes needed in <code>.env</code></li> <li>Never share your actual token!</li> </ol>"},{"location":"TROUBLESHOOTING/#invalid-gemini-api-key","title":"Invalid Gemini API Key","text":"<p>Error: <pre><code>google.api_core.exceptions.PermissionDenied: 403 API key not valid\n</code></pre></p> <p>Solutions:</p> <ol> <li>Verify API Key:</li> <li>Go to https://aistudio.google.com/app/apikey</li> <li>Check if key exists and is enabled</li> <li> <p>Generate new key if needed</p> </li> <li> <p>Check Gemini API Quotas:</p> </li> <li>Free tier has limits</li> <li> <p>Check quota at: https://aistudio.google.com/app/apikey</p> </li> <li> <p>Enable Gemini API:</p> </li> <li>Some Google accounts need to enable the API first</li> <li>Visit: https://makersuite.google.com/</li> </ol>"},{"location":"TROUBLESHOOTING/#rate-limiting","title":"Rate Limiting","text":"<p>Error: <pre><code>429 Too Many Requests\nanthropic.RateLimitError: rate_limit_error\n</code></pre></p> <p>Cause: Too many API requests in short time.</p> <p>Solutions:</p> <ol> <li>Wait Before Retrying:</li> <li>The bot has automatic retry with backoff</li> <li> <p>Wait 1-2 minutes before trying again</p> </li> <li> <p>Reduce Usage:</p> </li> <li>Gemini Flash: 15 requests/minute (free tier)</li> <li>Claude: Depends on your tier</li> <li> <p>OpenAI: Depends on your tier</p> </li> <li> <p>Check API Dashboard:</p> </li> <li>Anthropic: https://console.anthropic.com/</li> <li> <p>OpenAI: https://platform.openai.com/usage</p> </li> <li> <p>Upgrade API Tier:</p> </li> <li>Most rate limits are per-tier</li> <li>Free \u2192 Paid tier often increases limits significantly</li> </ol>"},{"location":"TROUBLESHOOTING/#performance-issues","title":"Performance Issues","text":""},{"location":"TROUBLESHOOTING/#slow-response-times","title":"Slow Response Times","text":"<p>Symptoms: - Bot takes 10+ seconds to respond - Timeouts in Discord</p> <p>Solutions:</p> <ol> <li>Check Which Model is Being Used:</li> <li>Simple queries \u2192 Gemini Flash (fast)</li> <li> <p>Complex tasks \u2192 Claude/GPT-4 (slower)</p> </li> <li> <p>Adjust Router Threshold:</p> </li> <li>Edit <code>src/secureclaw/agent/router.py</code></li> <li> <p>Line 136: Change <code>confidence &gt; 0.7</code> to <code>0.8</code> to use Flash more often</p> </li> <li> <p>Check Qdrant Performance: <pre><code>curl http://localhost:6333/metrics\n# Check for slow queries\n</code></pre></p> </li> <li> <p>Reduce Memory Context:</p> </li> <li>Edit <code>src/secureclaw/agent/core.py</code></li> <li>Line ~145: Reduce <code>memory_limit</code> and <code>history_limit</code></li> </ol>"},{"location":"TROUBLESHOOTING/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptoms: - Bot using multiple GB of RAM - System slowing down</p> <p>Solutions:</p> <ol> <li> <p>Check Qdrant Memory: <pre><code>docker stats secureclaw-qdrant\n</code></pre></p> </li> <li> <p>Limit Qdrant Memory: <pre><code># Stop and recreate with memory limit:\ndocker stop secureclaw-qdrant\ndocker rm secureclaw-qdrant\ndocker run -d \\\n  --name secureclaw-qdrant \\\n  -p 6333:6333 \\\n  --memory=\"2g\" \\\n  -v $(pwd)/qdrant_storage:/qdrant/storage \\\n  qdrant/qdrant:latest\n</code></pre></p> </li> <li> <p>Clear Old Memories: <pre><code># Delete qdrant_storage and restart:\nrm -rf qdrant_storage\n./start.sh\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#docker-issues","title":"Docker Issues","text":""},{"location":"TROUBLESHOOTING/#docker-not-running","title":"Docker Not Running","text":"<p>Error: <pre><code>Cannot connect to the Docker daemon\n</code></pre></p> <p>Solution:</p> <p>Automatic (Recommended): <pre><code>./start.sh\n# The script will detect Docker is not running and:\n# 1. Launch Docker Desktop automatically\n# 2. Wait for daemon to be ready (up to 90 seconds)\n# 3. Continue with setup\n</code></pre></p> <p>Manual: 1. Open Docker Desktop application 2. Wait for it to fully start (green icon in menu bar) 3. Verify: <code>docker ps</code> 4. Retry: <code>./start.sh</code></p> <p>If Docker Desktop won't start: - Check Activity Monitor for stuck Docker processes - Try: <code>killall Docker</code> then relaunch - Check Console.app for Docker error logs - Reinstall Docker Desktop if necessary</p>"},{"location":"TROUBLESHOOTING/#docker-daemon-not-ready-after-launch","title":"Docker Daemon Not Ready After Launch","text":"<p>Symptoms: - Docker Desktop GUI is open - <code>docker info</code> returns connection error - startup script times out waiting for daemon</p> <p>Causes: - Docker still initializing (can take 30-60 seconds on cold start) - Docker settings corrupted - Insufficient system resources</p> <p>Solutions:</p> <ol> <li> <p>Wait Longer: <pre><code># The start script waits up to 90 seconds\n# If you manually started Docker, wait before running commands:\nfor i in {1..60}; do\n  docker info &gt;/dev/null 2&gt;&amp;1 &amp;&amp; echo \"Ready!\" &amp;&amp; break\n  echo \"Waiting... ($i/60)\"\n  sleep 1\ndone\n</code></pre></p> </li> <li> <p>Check Docker Desktop Status:</p> </li> <li>Look at menu bar icon</li> <li>Should show green icon with no error messages</li> <li> <p>If yellow or red, click for details</p> </li> <li> <p>Restart Docker Desktop: <pre><code>osascript -e 'quit app \"Docker\"'\nsleep 5\nopen -a Docker\n</code></pre></p> </li> <li> <p>Check Available Resources: <pre><code># macOS:\nvm_stat | head -3\ndf -h /  # Disk space\n\n# Ensure you have:\n# - At least 2GB free RAM\n# - At least 10GB free disk space\n</code></pre></p> </li> <li> <p>Reset Docker (if stuck):</p> </li> <li>Docker Desktop \u2192 Troubleshoot \u2192 Reset to factory defaults</li> <li>WARNING: Deletes all containers/images</li> <li>Run <code>./start.sh</code> to rebuild</li> </ol>"},{"location":"TROUBLESHOOTING/#docker-desktop-memory-allocation","title":"Docker Desktop Memory Allocation","text":"<p>How much memory should Docker have?</p> <p>Depends on router backend:</p> <p>Gemini (Cloud): - Minimum: 2GB (for Qdrant only) - Recommended: 4GB (safe buffer)</p> <p>Ollama (Local): - Depends on model selected - See recommendations:   - <code>phi3:mini</code>: 5GB   - <code>llama3.1:8b</code>: 8GB   - <code>qwen2.5:7b</code>: 10GB   - <code>mistral:7b</code>: 7GB</p> <p>Automated Management: <pre><code># The startup script handles this automatically:\n./start.sh\n\n# It will:\n# 1. Detect your selected model\n# 2. Check Docker's current allocation\n# 3. Prompt to increase if needed\n# 4. Automatically update Docker settings\n# 5. Restart Docker if required\n</code></pre></p> <p>Manual Check: <pre><code># Check current allocation:\ndocker info | grep \"Total Memory\"\n\n# Check what's required:\ngrep OLLAMA_DOCKER_MEMORY .env\n</code></pre></p> <p>See also: Docker Architecture for detailed explanation.</p>"},{"location":"TROUBLESHOOTING/#port-already-in-use","title":"Port Already in Use","text":"<p>Error: <pre><code>Error starting userland proxy: listen tcp 0.0.0.0:6333: bind: address already in use\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Find What's Using Port 6333: <pre><code>lsof -i :6333\n</code></pre></p> </li> <li> <p>Kill the Process: <pre><code># Get PID from lsof, then:\nkill &lt;PID&gt;\n</code></pre></p> </li> <li> <p>Use Different Port: <pre><code># In .env:\nQDRANT_PORT=6334\n\n# Recreate Qdrant:\ndocker rm -f secureclaw-qdrant\ndocker run -d \\\n  --name secureclaw-qdrant \\\n  -p 6334:6333 \\\n  -v $(pwd)/qdrant_storage:/qdrant/storage \\\n  qdrant/qdrant:latest\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#ollama-issues","title":"Ollama Issues","text":""},{"location":"TROUBLESHOOTING/#ollama-container-fails-with-out-of-memory","title":"Ollama Container Fails with \"Out of Memory\"","text":"<p>Error: <pre><code>Error: llama runner process has terminated: signal: killed\nServer error: '500 Internal Server Error'\n</code></pre></p> <p>Cause: Docker Desktop doesn't have enough RAM allocated for the Ollama model.</p> <p>Solution:</p> <p>The startup script should handle this automatically, but if you encounter it manually:</p> <ol> <li> <p>Check Docker Desktop Memory: <pre><code>docker info | grep \"Total Memory\"\n# Example output: Total Memory: 4 GiB\n</code></pre></p> </li> <li> <p>Increase Docker Desktop Memory: <pre><code># Automated approach (recommended):\ncd scripts\n./increase-docker-memory.sh\n\n# This will:\n# - Detect required memory from .env\n# - Update Docker Desktop settings\n# - Restart Docker automatically\n</code></pre></p> </li> <li> <p>Manual Approach (if script fails):</p> </li> <li>Open Docker Desktop</li> <li>Go to Settings \u2192 Resources \u2192 Advanced</li> <li>Increase Memory slider to match your model's requirement:<ul> <li><code>phi3:mini</code> \u2192 5GB minimum</li> <li><code>llama3.1:8b</code> \u2192 8GB minimum</li> <li><code>qwen2.5:7b</code> \u2192 10GB minimum</li> <li><code>mistral:7b</code> \u2192 7GB minimum</li> </ul> </li> <li>Click Apply &amp; Restart</li> <li> <p>Wait for Docker to restart (30-60 seconds)</p> </li> <li> <p>Verify the Change: <pre><code>docker info | grep \"Total Memory\"\n# Should show your new allocation\n</code></pre></p> </li> </ol> <p>See also: Docker Architecture for understanding Docker Desktop vs container memory.</p>"},{"location":"TROUBLESHOOTING/#ollama-model-download-fails","title":"Ollama Model Download Fails","text":"<p>Error: <pre><code>Failed to download model 'qwen2.5:7b'\npulling manifest: Get \"https://registry.ollama.ai/v2/library/qwen2.5/manifests/7b\": EOF\n</code></pre></p> <p>Causes: - Network connectivity issues - Registry temporarily unavailable - Insufficient disk space</p> <p>Solutions:</p> <ol> <li> <p>Check Internet Connection: <pre><code>curl -I https://ollama.ai\n# Should return: HTTP/2 200\n</code></pre></p> </li> <li> <p>Check Disk Space: <pre><code>df -h .\n# Ensure at least 10GB free for large models\n</code></pre></p> </li> <li> <p>Manually Pull Model: <pre><code># If automatic pull failed, try manually:\ndocker exec secureclaw-ollama ollama pull qwen2.5:7b\n\n# For smaller model:\ndocker exec secureclaw-ollama ollama pull phi3:mini\n</code></pre></p> </li> <li> <p>Use Different Model: <pre><code># Switch to smaller model:\nrm .ollama_assessed\n# Edit .env to prefer smaller model\necho \"OLLAMA_ROUTER_MODEL=phi3:mini\" &gt;&gt; .env\n./start.sh\n</code></pre></p> </li> <li> <p>Fallback to Gemini:</p> </li> <li>The bot automatically falls back to Gemini if Ollama model unavailable</li> <li>Change router backend in <code>.env</code>:      <pre><code>ROUTER_BACKEND=gemini\n</code></pre></li> </ol>"},{"location":"TROUBLESHOOTING/#ollama-connection-error","title":"Ollama Connection Error","text":"<p>Error: <pre><code>[Errno 8] nodename nor servname provided, or not known\nhttpx.ConnectError: [Errno 61] Connection refused\n</code></pre></p> <p>Cause: Bot can't connect to Ollama container.</p> <p>Solutions:</p> <ol> <li> <p>Check Ollama Container is Running: <pre><code>docker ps | grep ollama\n# Should show: secureclaw-ollama\n</code></pre></p> </li> <li> <p>Start Ollama Container: <pre><code>docker start secureclaw-ollama\n# Or use the start script:\n./start.sh\n</code></pre></p> </li> <li> <p>Check <code>OLLAMA_HOST</code> Setting:</p> </li> </ol> <p>For Local Development (./start.sh): <pre><code># In .env:\nOLLAMA_HOST=localhost\nOLLAMA_PORT=11434\n</code></pre></p> <p>For Docker Compose: <pre><code># In .env:\nOLLAMA_HOST=ollama\nOLLAMA_PORT=11434\n</code></pre></p> <ol> <li> <p>Verify Ollama API: <pre><code>curl http://localhost:11434/api/tags\n# Should return JSON with list of models\n</code></pre></p> </li> <li> <p>Check Container Logs: <pre><code>docker logs secureclaw-ollama\n# Look for errors or OOM messages\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#ollama-slow-response-times","title":"Ollama Slow Response Times","text":"<p>Symptoms: - Ollama takes 30+ seconds to respond - Slower than expected inference</p> <p>Solutions:</p> <ol> <li> <p>Check CPU Usage: <pre><code>docker stats secureclaw-ollama\n# Look at CPU% - should be 100-400% during inference\n</code></pre></p> </li> <li> <p>Verify Model Size: <pre><code>docker exec secureclaw-ollama ollama list\n# Smaller models (phi3:mini) are faster than large ones\n</code></pre></p> </li> <li> <p>Switch to Smaller Model: <pre><code># Remove assessment marker to choose again:\nrm .ollama_assessed\n./start.sh\n# Select phi3:mini or mistral:7b when prompted\n</code></pre></p> </li> <li> <p>Check Docker Memory: <pre><code>docker stats secureclaw-ollama\n# MEM USAGE should be well below LIMIT\n# If at limit, model is swapping (very slow)\n</code></pre></p> </li> <li> <p>Add More Docker Memory: <pre><code># See \"Ollama Container Fails with Out of Memory\" above\n./scripts/increase-docker-memory.sh\n</code></pre></p> </li> <li> <p>Use GPU Acceleration (if available):</p> </li> <li>Requires NVIDIA GPU with Docker GPU support</li> <li>Or Apple Silicon Mac (uses Metal automatically)</li> <li>Check logs for \"GPU detected\" message</li> </ol>"},{"location":"TROUBLESHOOTING/#docker-desktop-wont-start-after-memory-increase","title":"Docker Desktop Won't Start After Memory Increase","text":"<p>Symptoms: - Ran <code>increase-docker-memory.sh</code> - Docker Desktop GUI opens but daemon never becomes ready - Stuck at \"Docker Desktop is starting...\"</p> <p>Possible Causes: - Requested more RAM than system has available - Other applications using too much memory - Docker settings corrupted</p> <p>Solutions:</p> <ol> <li> <p>Check System RAM Availability: <pre><code># macOS:\nvm_stat | head -2\n# Look at \"Pages free\"\n</code></pre></p> </li> <li> <p>Restore Backup Settings: <pre><code># increase-docker-memory.sh creates backups\ncd ~/Library/Group\\ Containers/group.com.docker/\nls -lt settings.json.backup.*\n\n# Restore most recent backup:\ncp settings.json.backup.20260205_143022 settings.json\n</code></pre></p> </li> <li> <p>Manually Reduce Memory: <pre><code># Edit settings file:\nvim ~/Library/Group\\ Containers/group.com.docker/settings.json\n\n# Find \"memoryMiB\" and set to safe value:\n{\n  \"memoryMiB\": 6144,  // 6GB - usually safe\n  ...\n}\n</code></pre></p> </li> <li> <p>Restart Docker: <pre><code># Quit Docker Desktop\nosascript -e 'quit app \"Docker\"'\nsleep 5\n\n# Relaunch\nopen -a Docker\n\n# Wait for daemon\nfor i in {1..60}; do\n  docker info &gt;/dev/null 2&gt;&amp;1 &amp;&amp; echo \"Ready!\" &amp;&amp; break\n  sleep 1\ndone\n</code></pre></p> </li> <li> <p>Reset Docker Desktop (Last Resort):</p> </li> <li>Open Docker Desktop</li> <li>Go to Troubleshoot \u2192 Reset to factory defaults</li> <li>WARNING: This deletes all containers and images</li> <li> <p>After reset, run <code>./start.sh</code> to recreate everything</p> </li> <li> <p>Close Other Memory-Intensive Apps:</p> </li> <li>Quit Chrome, Slack, IDEs, etc.</li> <li>Check Activity Monitor for memory hogs</li> <li>Try increasing Docker memory again with more free RAM</li> </ol>"},{"location":"TROUBLESHOOTING/#switch-between-gemini-and-ollama","title":"Switch Between Gemini and Ollama","text":"<p>How to change router backend after initial setup:</p> <p>Switch to Ollama: <pre><code># 1. Edit .env\nsed -i '' 's/ROUTER_BACKEND=gemini/ROUTER_BACKEND=ollama/' .env\n\n# 2. Run assessment (if not done before)\nrm .ollama_assessed  # Force re-assessment\n./start.sh\n</code></pre></p> <p>Switch to Gemini: <pre><code># 1. Edit .env\nsed -i '' 's/ROUTER_BACKEND=ollama/ROUTER_BACKEND=gemini/' .env\n\n# 2. Restart bot\n./stop.sh &amp;&amp; ./start.sh\n</code></pre></p> <p>Or manually edit <code>.env</code>: <pre><code># Change this line:\nROUTER_BACKEND=gemini  # or ollama\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#getting-help","title":"Getting Help","text":""},{"location":"TROUBLESHOOTING/#collecting-debug-information","title":"Collecting Debug Information","text":"<p>Before asking for help, gather this information:</p> <pre><code># 1. Check status\n./status.sh\n\n# 2. Get bot logs (last 50 lines)\ndocker logs secureclaw-qdrant --tail 50\n\n# 3. Check Python version\npython3 --version\n\n# 4. Check Docker version\ndocker --version\n\n# 5. Test Qdrant\ncurl http://localhost:6333/healthz\n\n# 6. Check disk space\ndf -h .\n</code></pre>"},{"location":"TROUBLESHOOTING/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># In .env:\nLOG_LEVEL=DEBUG\n\n# Restart:\n./stop.sh &amp;&amp; ./start.sh\n</code></pre>"},{"location":"TROUBLESHOOTING/#report-an-issue","title":"Report an Issue","text":"<p>Include: - OS version (macOS/Linux) - Python version - Full error message (last 20 lines) - Steps to reproduce - What you've already tried</p>"},{"location":"TROUBLESHOOTING/#quick-reference","title":"Quick Reference","text":""},{"location":"TROUBLESHOOTING/#common-commands","title":"Common Commands","text":"<pre><code># Start bot\n./start.sh\n\n# Check status\n./status.sh\n\n# Stop bot\n./stop.sh\n\n# View logs\ntail -f logs/secureclaw.log  # if logging to file\n\n# Restart bot\n./stop.sh &amp;&amp; ./start.sh\n\n# Check Qdrant health\ncurl http://localhost:6333/healthz\n\n# List Docker containers\ndocker ps -a\n\n# View bot process\nps aux | grep secureclaw\n</code></pre>"},{"location":"TROUBLESHOOTING/#configuration-checklist","title":"Configuration Checklist","text":"<ul> <li>[ ] Discord Token in <code>.env</code></li> <li>[ ] Gemini API Key in <code>.env</code></li> <li>[ ] Message Content Intent enabled in Discord</li> <li>[ ] Bot invited with <code>applications.commands</code> scope</li> <li>[ ] Router backend selected (<code>ROUTER_BACKEND</code> in <code>.env</code>)</li> <li>[ ] Qdrant running on correct host/port</li> <li>[ ] Ollama container running (if using Ollama backend)</li> <li>[ ] Docker Desktop has sufficient memory (check <code>docker info</code>)</li> <li>[ ] Python 3.12+ installed</li> <li>[ ] Docker Desktop running</li> <li>[ ] Correct <code>QDRANT_HOST</code> for your setup</li> <li>[ ] Correct <code>OLLAMA_HOST</code> for your setup (if using Ollama)</li> </ul>"},{"location":"TROUBLESHOOTING/#still-having-issues","title":"Still Having Issues?","text":"<ol> <li>Check the README.md for setup instructions</li> <li>Enable debug logging: <code>LOG_LEVEL=DEBUG</code> in <code>.env</code></li> <li>Search existing GitHub issues</li> <li>Create new issue with debug information</li> </ol>"}]}